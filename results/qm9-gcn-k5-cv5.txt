nohup: ignoring input
Creating k-hop graphs:   0%|          | 0/130831 [00:00<?, ?graphs/s]Creating k-hop graphs:   0%|          | 255/130831 [00:00<00:51, 2536.70graphs/s]Creating k-hop graphs:   0%|          | 509/130831 [00:00<01:03, 2037.63graphs/s]Creating k-hop graphs:   1%|          | 719/130831 [00:00<01:06, 1945.26graphs/s]Creating k-hop graphs:   1%|          | 940/130831 [00:00<01:03, 2036.67graphs/s]Creating k-hop graphs:   1%|          | 1147/130831 [00:00<01:09, 1858.40graphs/s]Creating k-hop graphs:   1%|          | 1337/130831 [00:00<01:21, 1584.81graphs/s]Creating k-hop graphs:   1%|          | 1503/130831 [00:00<01:23, 1540.59graphs/s]Creating k-hop graphs:   1%|▏         | 1662/130831 [00:01<01:32, 1398.33graphs/s]Creating k-hop graphs:   1%|▏         | 1810/130831 [00:01<01:31, 1417.47graphs/s]Creating k-hop graphs:   1%|▏         | 1955/130831 [00:01<01:32, 1395.89graphs/s]Creating k-hop graphs:   2%|▏         | 2109/130831 [00:01<01:29, 1434.85graphs/s]Creating k-hop graphs:   2%|▏         | 2255/130831 [00:01<01:31, 1407.56graphs/s]Creating k-hop graphs:   2%|▏         | 2397/130831 [00:01<01:33, 1378.51graphs/s]Creating k-hop graphs:   2%|▏         | 2562/130831 [00:01<01:28, 1453.41graphs/s]Creating k-hop graphs:   2%|▏         | 2709/130831 [00:01<01:33, 1371.11graphs/s]Creating k-hop graphs:   2%|▏         | 2864/130831 [00:01<01:30, 1418.15graphs/s]Creating k-hop graphs:   2%|▏         | 3008/130831 [00:01<01:31, 1389.73graphs/s]Creating k-hop graphs:   2%|▏         | 3148/130831 [00:02<01:32, 1381.87graphs/s]Creating k-hop graphs:   3%|▎         | 3311/130831 [00:02<01:27, 1452.54graphs/s]Creating k-hop graphs:   3%|▎         | 3488/130831 [00:02<01:22, 1543.15graphs/s]Creating k-hop graphs:   3%|▎         | 3670/130831 [00:02<01:18, 1623.13graphs/s]Creating k-hop graphs:   3%|▎         | 3899/130831 [00:02<01:09, 1815.88graphs/s]Creating k-hop graphs:   3%|▎         | 4082/130831 [00:02<01:23, 1520.70graphs/s]Creating k-hop graphs:   3%|▎         | 4263/130831 [00:02<01:19, 1596.19graphs/s]Creating k-hop graphs:   3%|▎         | 4430/130831 [00:02<01:20, 1570.97graphs/s]Creating k-hop graphs:   4%|▎         | 4600/130831 [00:02<01:18, 1604.16graphs/s]Creating k-hop graphs:   4%|▎         | 4765/130831 [00:03<01:27, 1441.44graphs/s]Creating k-hop graphs:   4%|▍         | 4915/130831 [00:03<01:26, 1447.62graphs/s]Creating k-hop graphs:   4%|▍         | 5064/130831 [00:03<01:27, 1439.18graphs/s]Creating k-hop graphs:   4%|▍         | 5211/130831 [00:03<01:31, 1376.46graphs/s]Creating k-hop graphs:   4%|▍         | 5366/130831 [00:03<01:28, 1422.54graphs/s]Creating k-hop graphs:   4%|▍         | 5511/130831 [00:03<01:33, 1341.85graphs/s]Creating k-hop graphs:   4%|▍         | 5648/130831 [00:03<01:34, 1327.11graphs/s]Creating k-hop graphs:   4%|▍         | 5782/130831 [00:03<01:52, 1115.27graphs/s]Creating k-hop graphs:   5%|▍         | 5900/130831 [00:04<02:04, 1003.75graphs/s]Creating k-hop graphs:   5%|▍         | 6006/130831 [00:04<02:12, 938.60graphs/s] Creating k-hop graphs:   5%|▍         | 6104/130831 [00:04<02:13, 936.51graphs/s]Creating k-hop graphs:   5%|▍         | 6201/130831 [00:04<02:18, 898.18graphs/s]Creating k-hop graphs:   5%|▍         | 6293/130831 [00:04<02:19, 895.27graphs/s]Creating k-hop graphs:   5%|▍         | 6384/130831 [00:04<02:24, 859.96graphs/s]Creating k-hop graphs:   5%|▍         | 6487/130831 [00:04<02:17, 904.28graphs/s]Creating k-hop graphs:   5%|▌         | 6579/130831 [00:04<02:27, 841.35graphs/s]Creating k-hop graphs:   5%|▌         | 6665/130831 [00:04<02:29, 832.32graphs/s]Creating k-hop graphs:   5%|▌         | 6750/130831 [00:05<02:28, 834.71graphs/s]Creating k-hop graphs:   5%|▌         | 6861/130831 [00:05<02:16, 911.11graphs/s]Creating k-hop graphs:   5%|▌         | 6954/130831 [00:05<02:19, 887.51graphs/s]Creating k-hop graphs:   5%|▌         | 7044/130831 [00:05<02:23, 863.57graphs/s]Creating k-hop graphs:   5%|▌         | 7131/130831 [00:05<02:24, 855.47graphs/s]Creating k-hop graphs:   6%|▌         | 7217/130831 [00:05<02:33, 803.94graphs/s]Creating k-hop graphs:   6%|▌         | 7300/130831 [00:05<02:32, 808.97graphs/s]Creating k-hop graphs:   6%|▌         | 7386/130831 [00:05<02:30, 821.84graphs/s]Creating k-hop graphs:   6%|▌         | 7505/130831 [00:05<02:13, 924.82graphs/s]Creating k-hop graphs:   6%|▌         | 7599/130831 [00:06<02:17, 896.32graphs/s]Creating k-hop graphs:   6%|▌         | 7728/130831 [00:06<02:02, 1007.18graphs/s]Creating k-hop graphs:   6%|▌         | 7837/130831 [00:06<01:59, 1028.81graphs/s]Creating k-hop graphs:   6%|▌         | 7946/130831 [00:06<01:57, 1046.13graphs/s]Creating k-hop graphs:   6%|▌         | 8052/130831 [00:06<02:02, 1001.82graphs/s]Creating k-hop graphs:   6%|▌         | 8153/130831 [00:06<02:04, 987.47graphs/s] Creating k-hop graphs:   6%|▋         | 8264/130831 [00:06<02:00, 1019.72graphs/s]Creating k-hop graphs:   6%|▋         | 8401/130831 [00:06<01:49, 1117.17graphs/s]Creating k-hop graphs:   7%|▋         | 8519/130831 [00:06<01:47, 1135.06graphs/s]Creating k-hop graphs:   7%|▋         | 8633/130831 [00:06<01:51, 1098.05graphs/s]Creating k-hop graphs:   7%|▋         | 8744/130831 [00:07<01:51, 1095.13graphs/s]Creating k-hop graphs:   7%|▋         | 8867/130831 [00:07<01:47, 1134.05graphs/s]Creating k-hop graphs:   7%|▋         | 8981/130831 [00:07<01:53, 1076.12graphs/s]Creating k-hop graphs:   7%|▋         | 9090/130831 [00:07<02:03, 982.28graphs/s] Creating k-hop graphs:   7%|▋         | 9191/130831 [00:07<02:11, 926.17graphs/s]Creating k-hop graphs:   7%|▋         | 9308/130831 [00:07<02:02, 989.89graphs/s]Creating k-hop graphs:   7%|▋         | 9414/130831 [00:07<02:00, 1008.16graphs/s]Creating k-hop graphs:   7%|▋         | 9517/130831 [00:07<02:03, 983.48graphs/s] Creating k-hop graphs:   7%|▋         | 9617/130831 [00:07<02:03, 982.33graphs/s]Creating k-hop graphs:   7%|▋         | 9716/130831 [00:08<02:05, 964.33graphs/s]Creating k-hop graphs:   8%|▊         | 9817/130831 [00:08<02:04, 975.39graphs/s]Creating k-hop graphs:   8%|▊         | 9915/130831 [00:08<02:10, 928.61graphs/s]Creating k-hop graphs:   8%|▊         | 10009/130831 [00:08<02:15, 894.48graphs/s]Creating k-hop graphs:   8%|▊         | 10100/130831 [00:08<02:16, 884.00graphs/s]Creating k-hop graphs:   8%|▊         | 10213/130831 [00:08<02:06, 952.81graphs/s]Creating k-hop graphs:   8%|▊         | 10316/130831 [00:08<02:03, 974.26graphs/s]Creating k-hop graphs:   8%|▊         | 10416/130831 [00:08<02:02, 979.75graphs/s]Creating k-hop graphs:   8%|▊         | 10515/130831 [00:08<02:03, 971.35graphs/s]Creating k-hop graphs:   8%|▊         | 10626/130831 [00:09<01:58, 1011.20graphs/s]Creating k-hop graphs:   8%|▊         | 10742/130831 [00:09<01:53, 1054.05graphs/s]Creating k-hop graphs:   8%|▊         | 10848/130831 [00:09<01:53, 1053.52graphs/s]Creating k-hop graphs:   8%|▊         | 11000/130831 [00:09<01:40, 1188.53graphs/s]Creating k-hop graphs:   8%|▊         | 11120/130831 [00:09<01:45, 1132.17graphs/s]Creating k-hop graphs:   9%|▊         | 11234/130831 [00:09<01:53, 1051.72graphs/s]Creating k-hop graphs:   9%|▊         | 11341/130831 [00:09<02:05, 949.61graphs/s] Creating k-hop graphs:   9%|▉         | 11465/130831 [00:09<01:56, 1024.40graphs/s]Creating k-hop graphs:   9%|▉         | 11588/130831 [00:09<01:50, 1079.17graphs/s]Creating k-hop graphs:   9%|▉         | 11701/130831 [00:10<01:49, 1092.58graphs/s]Creating k-hop graphs:   9%|▉         | 11813/130831 [00:10<01:50, 1080.49graphs/s]Creating k-hop graphs:   9%|▉         | 11938/130831 [00:10<01:45, 1126.40graphs/s]Creating k-hop graphs:   9%|▉         | 12052/130831 [00:10<01:46, 1118.78graphs/s]Creating k-hop graphs:   9%|▉         | 12171/130831 [00:10<01:44, 1138.42graphs/s]Creating k-hop graphs:   9%|▉         | 12286/130831 [00:10<01:47, 1101.84graphs/s]Creating k-hop graphs:   9%|▉         | 12410/130831 [00:10<01:43, 1138.82graphs/s]Creating k-hop graphs:  10%|▉         | 12525/130831 [00:10<01:45, 1124.05graphs/s]Creating k-hop graphs:  10%|▉         | 12639/130831 [00:10<01:44, 1126.64graphs/s]Creating k-hop graphs:  10%|▉         | 12768/130831 [00:10<01:40, 1172.60graphs/s]Creating k-hop graphs:  10%|▉         | 12886/130831 [00:11<01:49, 1080.22graphs/s]Creating k-hop graphs:  10%|▉         | 12996/130831 [00:11<01:57, 1001.34graphs/s]Creating k-hop graphs:  10%|█         | 13099/130831 [00:11<01:58, 996.05graphs/s] Creating k-hop graphs:  10%|█         | 13200/130831 [00:11<02:07, 920.15graphs/s]Creating k-hop graphs:  10%|█         | 13295/130831 [00:11<02:06, 925.52graphs/s]Creating k-hop graphs:  10%|█         | 13389/130831 [00:11<02:10, 900.67graphs/s]Creating k-hop graphs:  10%|█         | 13480/130831 [00:11<02:13, 876.22graphs/s]Creating k-hop graphs:  10%|█         | 13569/130831 [00:11<02:16, 856.19graphs/s]Creating k-hop graphs:  10%|█         | 13672/130831 [00:11<02:09, 902.88graphs/s]Creating k-hop graphs:  11%|█         | 13778/130831 [00:12<02:03, 946.15graphs/s]Creating k-hop graphs:  11%|█         | 13885/130831 [00:12<01:59, 979.00graphs/s]Creating k-hop graphs:  11%|█         | 14005/130831 [00:12<01:52, 1042.68graphs/s]Creating k-hop graphs:  11%|█         | 14132/130831 [00:12<01:45, 1108.72graphs/s]Creating k-hop graphs:  11%|█         | 14251/130831 [00:12<01:43, 1128.29graphs/s]Creating k-hop graphs:  11%|█         | 14365/130831 [00:12<01:45, 1107.13graphs/s]Creating k-hop graphs:  11%|█         | 14477/130831 [00:12<02:08, 904.82graphs/s] Creating k-hop graphs:  11%|█         | 14576/130831 [00:12<02:05, 925.71graphs/s]Creating k-hop graphs:  11%|█         | 14682/130831 [00:12<02:01, 957.82graphs/s]Creating k-hop graphs:  11%|█▏        | 14783/130831 [00:13<01:59, 971.53graphs/s]Creating k-hop graphs:  11%|█▏        | 14883/130831 [00:13<02:08, 902.36graphs/s]Creating k-hop graphs:  11%|█▏        | 14999/130831 [00:13<01:59, 970.52graphs/s]Creating k-hop graphs:  12%|█▏        | 15099/130831 [00:13<01:59, 971.63graphs/s]Creating k-hop graphs:  12%|█▏        | 15213/130831 [00:13<01:53, 1017.51graphs/s]Creating k-hop graphs:  12%|█▏        | 15323/130831 [00:13<01:51, 1040.57graphs/s]Creating k-hop graphs:  12%|█▏        | 15429/130831 [00:13<01:53, 1016.88graphs/s]Creating k-hop graphs:  12%|█▏        | 15532/130831 [00:13<01:56, 987.80graphs/s] Creating k-hop graphs:  12%|█▏        | 15644/130831 [00:13<01:52, 1024.83graphs/s]Creating k-hop graphs:  12%|█▏        | 15762/130831 [00:14<01:47, 1068.57graphs/s]Creating k-hop graphs:  12%|█▏        | 15904/130831 [00:14<01:38, 1169.96graphs/s]Creating k-hop graphs:  12%|█▏        | 16033/130831 [00:14<01:35, 1203.42graphs/s]Creating k-hop graphs:  12%|█▏        | 16154/130831 [00:14<01:38, 1168.87graphs/s]Creating k-hop graphs:  12%|█▏        | 16277/130831 [00:14<01:36, 1185.76graphs/s]Creating k-hop graphs:  13%|█▎        | 16411/130831 [00:14<01:32, 1230.96graphs/s]Creating k-hop graphs:  13%|█▎        | 16549/130831 [00:14<01:29, 1273.89graphs/s]Creating k-hop graphs:  13%|█▎        | 16677/130831 [00:14<01:29, 1268.62graphs/s]Creating k-hop graphs:  13%|█▎        | 16805/130831 [00:14<01:31, 1240.62graphs/s]Creating k-hop graphs:  13%|█▎        | 16934/130831 [00:14<01:30, 1253.53graphs/s]Creating k-hop graphs:  13%|█▎        | 17060/130831 [00:15<01:37, 1161.28graphs/s]Creating k-hop graphs:  13%|█▎        | 17178/130831 [00:15<01:37, 1164.62graphs/s]Creating k-hop graphs:  13%|█▎        | 17296/130831 [00:15<01:38, 1148.40graphs/s]Creating k-hop graphs:  13%|█▎        | 17412/130831 [00:15<01:41, 1116.57graphs/s]Creating k-hop graphs:  13%|█▎        | 17525/130831 [00:15<01:45, 1071.40graphs/s]Creating k-hop graphs:  13%|█▎        | 17646/130831 [00:15<01:42, 1108.24graphs/s]Creating k-hop graphs:  14%|█▎        | 17758/130831 [00:15<01:44, 1086.80graphs/s]Creating k-hop graphs:  14%|█▎        | 17885/130831 [00:15<01:39, 1138.14graphs/s]Creating k-hop graphs:  14%|█▍        | 18011/130831 [00:15<01:36, 1168.62graphs/s]Creating k-hop graphs:  14%|█▍        | 18142/130831 [00:16<01:33, 1207.01graphs/s]Creating k-hop graphs:  14%|█▍        | 18264/130831 [00:16<01:36, 1163.15graphs/s]Creating k-hop graphs:  14%|█▍        | 18395/130831 [00:16<01:33, 1202.41graphs/s]Creating k-hop graphs:  14%|█▍        | 18533/130831 [00:16<01:29, 1252.59graphs/s]Creating k-hop graphs:  14%|█▍        | 18680/130831 [00:16<01:25, 1316.14graphs/s]Creating k-hop graphs:  14%|█▍        | 18813/130831 [00:16<01:25, 1315.09graphs/s]Creating k-hop graphs:  14%|█▍        | 18945/130831 [00:16<01:26, 1298.68graphs/s]Creating k-hop graphs:  15%|█▍        | 19076/130831 [00:16<01:29, 1248.91graphs/s]Creating k-hop graphs:  15%|█▍        | 19202/130831 [00:16<01:30, 1236.93graphs/s]Creating k-hop graphs:  15%|█▍        | 19351/130831 [00:16<01:25, 1308.68graphs/s]Creating k-hop graphs:  15%|█▍        | 19497/130831 [00:17<01:22, 1351.65graphs/s]Creating k-hop graphs:  15%|█▌        | 19633/130831 [00:17<01:22, 1352.16graphs/s]Creating k-hop graphs:  15%|█▌        | 19769/130831 [00:17<01:35, 1161.88graphs/s]Creating k-hop graphs:  15%|█▌        | 19907/130831 [00:17<01:31, 1218.44graphs/s]Creating k-hop graphs:  15%|█▌        | 20061/130831 [00:17<01:24, 1305.55graphs/s]Creating k-hop graphs:  15%|█▌        | 20217/130831 [00:17<01:20, 1375.31graphs/s]Creating k-hop graphs:  16%|█▌        | 20371/130831 [00:17<01:17, 1421.05graphs/s]Creating k-hop graphs:  16%|█▌        | 20516/130831 [00:17<01:21, 1352.89graphs/s]Creating k-hop graphs:  16%|█▌        | 20654/130831 [00:17<01:27, 1255.66graphs/s]Creating k-hop graphs:  16%|█▌        | 20786/130831 [00:18<01:26, 1272.02graphs/s]Creating k-hop graphs:  16%|█▌        | 20916/130831 [00:18<01:28, 1246.35graphs/s]Creating k-hop graphs:  16%|█▌        | 21115/130831 [00:18<01:15, 1454.23graphs/s]Creating k-hop graphs:  16%|█▋        | 21307/130831 [00:18<01:09, 1586.63graphs/s]Creating k-hop graphs:  16%|█▋        | 21502/130831 [00:18<01:04, 1691.66graphs/s]Creating k-hop graphs:  17%|█▋        | 21674/130831 [00:18<01:18, 1397.97graphs/s]Creating k-hop graphs:  17%|█▋        | 21824/130831 [00:18<01:37, 1122.19graphs/s]Creating k-hop graphs:  17%|█▋        | 21951/130831 [00:19<01:43, 1054.34graphs/s]Creating k-hop graphs:  17%|█▋        | 22067/130831 [00:19<01:52, 967.79graphs/s] Creating k-hop graphs:  17%|█▋        | 22171/130831 [00:19<01:53, 955.99graphs/s]Creating k-hop graphs:  17%|█▋        | 22272/130831 [00:19<01:53, 960.42graphs/s]Creating k-hop graphs:  17%|█▋        | 22373/130831 [00:19<01:51, 970.49graphs/s]Creating k-hop graphs:  17%|█▋        | 22475/130831 [00:19<01:50, 980.89graphs/s]Creating k-hop graphs:  17%|█▋        | 22576/130831 [00:19<01:59, 903.37graphs/s]Creating k-hop graphs:  17%|█▋        | 22670/130831 [00:19<01:58, 910.17graphs/s]Creating k-hop graphs:  17%|█▋        | 22771/130831 [00:19<01:55, 935.79graphs/s]Creating k-hop graphs:  17%|█▋        | 22876/130831 [00:20<01:51, 966.99graphs/s]Creating k-hop graphs:  18%|█▊        | 22974/130831 [00:20<01:52, 955.08graphs/s]Creating k-hop graphs:  18%|█▊        | 23080/130831 [00:20<01:49, 982.30graphs/s]Creating k-hop graphs:  18%|█▊        | 23241/130831 [00:20<01:32, 1163.00graphs/s]Creating k-hop graphs:  18%|█▊        | 23455/130831 [00:20<01:14, 1447.43graphs/s]Creating k-hop graphs:  18%|█▊        | 23602/130831 [00:20<01:19, 1356.18graphs/s]Creating k-hop graphs:  18%|█▊        | 23740/130831 [00:20<01:24, 1268.43graphs/s]Creating k-hop graphs:  18%|█▊        | 23870/130831 [00:20<01:25, 1245.50graphs/s]Creating k-hop graphs:  18%|█▊        | 24011/130831 [00:20<01:22, 1289.24graphs/s]Creating k-hop graphs:  18%|█▊        | 24142/130831 [00:21<01:28, 1203.00graphs/s]Creating k-hop graphs:  19%|█▊        | 24274/130831 [00:21<01:26, 1234.39graphs/s]Creating k-hop graphs:  19%|█▊        | 24453/130831 [00:21<01:16, 1386.43graphs/s]Creating k-hop graphs:  19%|█▉        | 24629/130831 [00:21<01:11, 1491.54graphs/s]Creating k-hop graphs:  19%|█▉        | 24800/130831 [00:21<01:08, 1553.61graphs/s]Creating k-hop graphs:  19%|█▉        | 24957/130831 [00:21<01:10, 1502.04graphs/s]Creating k-hop graphs:  19%|█▉        | 25109/130831 [00:21<01:22, 1279.01graphs/s]Creating k-hop graphs:  19%|█▉        | 25244/130831 [00:21<01:26, 1225.76graphs/s]Creating k-hop graphs:  19%|█▉        | 25372/130831 [00:21<01:29, 1178.93graphs/s]Creating k-hop graphs:  19%|█▉        | 25493/130831 [00:22<01:38, 1066.22graphs/s]Creating k-hop graphs:  20%|█▉        | 25603/130831 [00:22<01:50, 950.15graphs/s] Creating k-hop graphs:  20%|█▉        | 25702/130831 [00:22<02:00, 869.54graphs/s]Creating k-hop graphs:  20%|█▉        | 25798/130831 [00:22<01:58, 889.90graphs/s]Creating k-hop graphs:  20%|█▉        | 25917/130831 [00:22<01:48, 964.77graphs/s]Creating k-hop graphs:  20%|█▉        | 26020/130831 [00:22<01:46, 982.00graphs/s]Creating k-hop graphs:  20%|█▉        | 26148/130831 [00:22<01:38, 1061.68graphs/s]Creating k-hop graphs:  20%|██        | 26261/130831 [00:22<01:36, 1078.29graphs/s]Creating k-hop graphs:  20%|██        | 26389/130831 [00:22<01:32, 1133.30graphs/s]Creating k-hop graphs:  20%|██        | 26504/130831 [00:23<01:32, 1128.01graphs/s]Creating k-hop graphs:  20%|██        | 26618/130831 [00:23<01:33, 1119.82graphs/s]Creating k-hop graphs:  20%|██        | 26761/130831 [00:23<01:26, 1209.18graphs/s]Creating k-hop graphs:  21%|██        | 26883/130831 [00:23<01:27, 1189.18graphs/s]Creating k-hop graphs:  21%|██        | 27003/130831 [00:23<01:27, 1189.90graphs/s]Creating k-hop graphs:  21%|██        | 27123/130831 [00:23<01:28, 1166.16graphs/s]Creating k-hop graphs:  21%|██        | 27245/130831 [00:23<01:27, 1180.93graphs/s]Creating k-hop graphs:  21%|██        | 27364/130831 [00:23<01:28, 1164.44graphs/s]Creating k-hop graphs:  21%|██        | 27485/130831 [00:23<01:27, 1175.37graphs/s]Creating k-hop graphs:  21%|██        | 27603/130831 [00:24<01:29, 1153.27graphs/s]Creating k-hop graphs:  21%|██        | 27719/130831 [00:24<01:36, 1065.08graphs/s]Creating k-hop graphs:  21%|██▏       | 27827/130831 [00:24<01:37, 1057.56graphs/s]Creating k-hop graphs:  21%|██▏       | 27945/130831 [00:24<01:34, 1089.15graphs/s]Creating k-hop graphs:  21%|██▏       | 28065/130831 [00:24<01:31, 1119.85graphs/s]Creating k-hop graphs:  22%|██▏       | 28178/130831 [00:24<01:34, 1080.59graphs/s]Creating k-hop graphs:  22%|██▏       | 28316/130831 [00:24<01:28, 1163.95graphs/s]Creating k-hop graphs:  22%|██▏       | 28443/130831 [00:24<01:25, 1193.20graphs/s]Creating k-hop graphs:  22%|██▏       | 28564/130831 [00:24<01:28, 1154.93graphs/s]Creating k-hop graphs:  22%|██▏       | 28681/130831 [00:24<01:28, 1157.67graphs/s]Creating k-hop graphs:  22%|██▏       | 28798/130831 [00:25<01:31, 1117.21graphs/s]Creating k-hop graphs:  22%|██▏       | 28911/130831 [00:25<01:33, 1087.23graphs/s]Creating k-hop graphs:  22%|██▏       | 29021/130831 [00:25<01:35, 1065.81graphs/s]Creating k-hop graphs:  22%|██▏       | 29128/130831 [00:25<01:36, 1053.40graphs/s]Creating k-hop graphs:  22%|██▏       | 29234/130831 [00:25<01:38, 1032.03graphs/s]Creating k-hop graphs:  22%|██▏       | 29338/130831 [00:25<01:43, 984.60graphs/s] Creating k-hop graphs:  23%|██▎       | 29442/130831 [00:25<01:41, 998.24graphs/s]Creating k-hop graphs:  23%|██▎       | 29545/130831 [00:25<01:40, 1004.34graphs/s]Creating k-hop graphs:  23%|██▎       | 29646/130831 [00:25<01:42, 985.32graphs/s] Creating k-hop graphs:  23%|██▎       | 29745/130831 [00:26<01:45, 961.93graphs/s]Creating k-hop graphs:  23%|██▎       | 29842/130831 [00:26<01:52, 896.17graphs/s]Creating k-hop graphs:  23%|██▎       | 29933/130831 [00:26<01:59, 843.42graphs/s]Creating k-hop graphs:  23%|██▎       | 30019/130831 [00:26<02:01, 830.21graphs/s]Creating k-hop graphs:  23%|██▎       | 30108/130831 [00:26<01:59, 844.96graphs/s]Creating k-hop graphs:  23%|██▎       | 30194/130831 [00:26<01:59, 840.82graphs/s]Creating k-hop graphs:  23%|██▎       | 30280/130831 [00:26<01:59, 844.96graphs/s]Creating k-hop graphs:  23%|██▎       | 30365/130831 [00:26<02:02, 818.85graphs/s]Creating k-hop graphs:  23%|██▎       | 30472/130831 [00:26<01:52, 889.70graphs/s]Creating k-hop graphs:  23%|██▎       | 30565/130831 [00:27<01:51, 898.67graphs/s]Creating k-hop graphs:  23%|██▎       | 30656/130831 [00:27<01:56, 862.44graphs/s]Creating k-hop graphs:  23%|██▎       | 30743/130831 [00:27<01:59, 837.25graphs/s]Creating k-hop graphs:  24%|██▎       | 30828/130831 [00:27<02:05, 797.10graphs/s]Creating k-hop graphs:  24%|██▎       | 30909/130831 [00:27<02:04, 799.90graphs/s]Creating k-hop graphs:  24%|██▎       | 31008/130831 [00:27<01:57, 851.24graphs/s]Creating k-hop graphs:  24%|██▍       | 31103/130831 [00:27<01:53, 878.26graphs/s]Creating k-hop graphs:  24%|██▍       | 31192/130831 [00:27<01:55, 859.49graphs/s]Creating k-hop graphs:  24%|██▍       | 31279/130831 [00:27<01:55, 861.26graphs/s]Creating k-hop graphs:  24%|██▍       | 31386/130831 [00:27<01:48, 919.28graphs/s]Creating k-hop graphs:  24%|██▍       | 31479/130831 [00:28<01:52, 884.24graphs/s]Creating k-hop graphs:  24%|██▍       | 31568/130831 [00:28<01:53, 873.97graphs/s]Creating k-hop graphs:  24%|██▍       | 31656/130831 [00:28<01:58, 835.87graphs/s]Creating k-hop graphs:  24%|██▍       | 31741/130831 [00:28<02:04, 797.88graphs/s]Creating k-hop graphs:  24%|██▍       | 31822/130831 [00:28<02:08, 769.29graphs/s]Creating k-hop graphs:  24%|██▍       | 31900/130831 [00:28<02:11, 754.56graphs/s]Creating k-hop graphs:  24%|██▍       | 31976/130831 [00:28<02:11, 751.84graphs/s]Creating k-hop graphs:  24%|██▍       | 32053/130831 [00:28<02:10, 756.61graphs/s]Creating k-hop graphs:  25%|██▍       | 32129/130831 [00:28<02:15, 725.94graphs/s]Creating k-hop graphs:  25%|██▍       | 32202/130831 [00:29<02:20, 704.27graphs/s]Creating k-hop graphs:  25%|██▍       | 32312/130831 [00:29<02:01, 814.10graphs/s]Creating k-hop graphs:  25%|██▍       | 32416/130831 [00:29<01:52, 876.04graphs/s]Creating k-hop graphs:  25%|██▍       | 32522/130831 [00:29<01:45, 929.03graphs/s]Creating k-hop graphs:  25%|██▍       | 32673/130831 [00:29<01:29, 1097.64graphs/s]Creating k-hop graphs:  25%|██▌       | 32800/130831 [00:29<01:25, 1147.75graphs/s]Creating k-hop graphs:  25%|██▌       | 32932/130831 [00:29<01:21, 1197.07graphs/s]Creating k-hop graphs:  25%|██▌       | 33057/130831 [00:29<01:20, 1212.13graphs/s]Creating k-hop graphs:  25%|██▌       | 33200/130831 [00:29<01:16, 1276.77graphs/s]Creating k-hop graphs:  25%|██▌       | 33341/130831 [00:29<01:14, 1315.06graphs/s]Creating k-hop graphs:  26%|██▌       | 33479/130831 [00:30<01:13, 1333.51graphs/s]Creating k-hop graphs:  26%|██▌       | 33613/130831 [00:30<01:15, 1287.78graphs/s]Creating k-hop graphs:  26%|██▌       | 33745/130831 [00:30<01:14, 1295.07graphs/s]Creating k-hop graphs:  26%|██▌       | 33875/130831 [00:30<01:16, 1273.55graphs/s]Creating k-hop graphs:  26%|██▌       | 34010/130831 [00:30<01:14, 1294.67graphs/s]Creating k-hop graphs:  26%|██▌       | 34140/130831 [00:30<01:15, 1279.90graphs/s]Creating k-hop graphs:  26%|██▌       | 34269/130831 [00:30<01:20, 1197.37graphs/s]Creating k-hop graphs:  26%|██▋       | 34390/130831 [00:30<01:20, 1199.59graphs/s]Creating k-hop graphs:  26%|██▋       | 34523/130831 [00:30<01:17, 1235.31graphs/s]Creating k-hop graphs:  26%|██▋       | 34651/130831 [00:31<01:17, 1244.71graphs/s]Creating k-hop graphs:  27%|██▋       | 34776/130831 [00:31<01:22, 1170.33graphs/s]Creating k-hop graphs:  27%|██▋       | 34895/130831 [00:31<01:22, 1165.72graphs/s]Creating k-hop graphs:  27%|██▋       | 35013/130831 [00:31<01:27, 1095.45graphs/s]Creating k-hop graphs:  27%|██▋       | 35128/130831 [00:31<01:26, 1109.29graphs/s]Creating k-hop graphs:  27%|██▋       | 35240/130831 [00:31<01:28, 1076.54graphs/s]Creating k-hop graphs:  27%|██▋       | 35349/130831 [00:31<01:33, 1021.35graphs/s]Creating k-hop graphs:  27%|██▋       | 35452/130831 [00:31<01:35, 999.91graphs/s] Creating k-hop graphs:  27%|██▋       | 35553/130831 [00:31<01:38, 967.34graphs/s]Creating k-hop graphs:  27%|██▋       | 35651/130831 [00:32<01:42, 928.40graphs/s]Creating k-hop graphs:  27%|██▋       | 35745/130831 [00:32<01:46, 890.30graphs/s]Creating k-hop graphs:  27%|██▋       | 35835/130831 [00:32<01:58, 804.96graphs/s]Creating k-hop graphs:  27%|██▋       | 35917/130831 [00:32<02:13, 711.11graphs/s]Creating k-hop graphs:  28%|██▊       | 35991/130831 [00:32<02:14, 703.57graphs/s]Creating k-hop graphs:  28%|██▊       | 36098/130831 [00:32<01:58, 797.17graphs/s]Creating k-hop graphs:  28%|██▊       | 36215/130831 [00:32<01:45, 896.54graphs/s]Creating k-hop graphs:  28%|██▊       | 36335/130831 [00:32<01:36, 980.11graphs/s]Creating k-hop graphs:  28%|██▊       | 36448/130831 [00:32<01:32, 1021.22graphs/s]Creating k-hop graphs:  28%|██▊       | 36579/130831 [00:33<01:25, 1103.25graphs/s]Creating k-hop graphs:  28%|██▊       | 36713/130831 [00:33<01:20, 1168.89graphs/s]Creating k-hop graphs:  28%|██▊       | 36839/130831 [00:33<01:18, 1194.06graphs/s]Creating k-hop graphs:  28%|██▊       | 36960/130831 [00:33<01:21, 1155.03graphs/s]Creating k-hop graphs:  28%|██▊       | 37077/130831 [00:33<01:22, 1133.01graphs/s]Creating k-hop graphs:  28%|██▊       | 37192/130831 [00:33<01:25, 1094.93graphs/s]Creating k-hop graphs:  29%|██▊       | 37303/130831 [00:33<01:31, 1018.31graphs/s]Creating k-hop graphs:  29%|██▊       | 37407/130831 [00:33<01:33, 1001.89graphs/s]Creating k-hop graphs:  29%|██▊       | 37520/130831 [00:33<01:30, 1036.12graphs/s]Creating k-hop graphs:  29%|██▉       | 37634/130831 [00:34<01:27, 1061.88graphs/s]Creating k-hop graphs:  29%|██▉       | 37744/130831 [00:34<01:26, 1071.71graphs/s]Creating k-hop graphs:  29%|██▉       | 37852/130831 [00:34<01:28, 1046.31graphs/s]Creating k-hop graphs:  29%|██▉       | 37959/130831 [00:34<01:28, 1052.11graphs/s]Creating k-hop graphs:  29%|██▉       | 38065/130831 [00:34<01:30, 1020.07graphs/s]Creating k-hop graphs:  29%|██▉       | 38177/130831 [00:34<01:28, 1045.27graphs/s]Creating k-hop graphs:  29%|██▉       | 38282/130831 [00:34<01:32, 1000.40graphs/s]Creating k-hop graphs:  29%|██▉       | 38383/130831 [00:34<01:35, 971.51graphs/s] Creating k-hop graphs:  29%|██▉       | 38487/130831 [00:34<01:33, 989.42graphs/s]Creating k-hop graphs:  29%|██▉       | 38587/130831 [00:35<01:44, 885.22graphs/s]Creating k-hop graphs:  30%|██▉       | 38696/130831 [00:35<01:38, 938.84graphs/s]Creating k-hop graphs:  30%|██▉       | 38799/130831 [00:35<01:35, 962.73graphs/s]Creating k-hop graphs:  30%|██▉       | 38897/130831 [00:35<01:37, 939.37graphs/s]Creating k-hop graphs:  30%|██▉       | 38993/130831 [00:35<01:38, 929.82graphs/s]Creating k-hop graphs:  30%|██▉       | 39087/130831 [00:35<01:39, 918.61graphs/s]Creating k-hop graphs:  30%|██▉       | 39180/130831 [00:35<01:42, 892.39graphs/s]Creating k-hop graphs:  30%|███       | 39270/130831 [00:35<01:44, 874.49graphs/s]Creating k-hop graphs:  30%|███       | 39361/130831 [00:35<01:43, 882.18graphs/s]Creating k-hop graphs:  30%|███       | 39450/130831 [00:35<01:43, 880.32graphs/s]Creating k-hop graphs:  30%|███       | 39539/130831 [00:36<01:46, 853.58graphs/s]Creating k-hop graphs:  30%|███       | 39625/130831 [00:36<01:53, 800.41graphs/s]Creating k-hop graphs:  30%|███       | 39706/130831 [00:36<01:57, 776.54graphs/s]Creating k-hop graphs:  30%|███       | 39788/130831 [00:36<01:55, 787.13graphs/s]Creating k-hop graphs:  30%|███       | 39870/130831 [00:36<01:54, 795.44graphs/s]Creating k-hop graphs:  31%|███       | 39985/130831 [00:36<01:41, 895.82graphs/s]Creating k-hop graphs:  31%|███       | 40094/130831 [00:36<01:35, 951.02graphs/s]Creating k-hop graphs:  31%|███       | 40206/130831 [00:36<01:30, 1000.07graphs/s]Creating k-hop graphs:  31%|███       | 40315/130831 [00:36<01:28, 1026.10graphs/s]Creating k-hop graphs:  31%|███       | 40419/130831 [00:37<01:30, 1000.32graphs/s]Creating k-hop graphs:  31%|███       | 40520/130831 [00:37<01:30, 995.26graphs/s] Creating k-hop graphs:  31%|███       | 40624/130831 [00:37<01:29, 1007.22graphs/s]Creating k-hop graphs:  31%|███       | 40725/130831 [00:37<01:29, 1003.37graphs/s]Creating k-hop graphs:  31%|███       | 40826/130831 [00:37<01:31, 983.39graphs/s] Creating k-hop graphs:  31%|███▏      | 40925/130831 [00:37<01:35, 941.45graphs/s]Creating k-hop graphs:  31%|███▏      | 41020/130831 [00:37<01:43, 865.48graphs/s]Creating k-hop graphs:  31%|███▏      | 41165/130831 [00:37<01:27, 1024.31graphs/s]Creating k-hop graphs:  32%|███▏      | 41270/130831 [00:37<01:27, 1024.43graphs/s]Creating k-hop graphs:  32%|███▏      | 41375/130831 [00:38<01:27, 1023.00graphs/s]Creating k-hop graphs:  32%|███▏      | 41550/130831 [00:38<01:12, 1230.70graphs/s]Creating k-hop graphs:  32%|███▏      | 41718/130831 [00:38<01:05, 1360.94graphs/s]Creating k-hop graphs:  32%|███▏      | 41856/130831 [00:38<01:05, 1356.43graphs/s]Creating k-hop graphs:  32%|███▏      | 42012/130831 [00:38<01:02, 1413.17graphs/s]Creating k-hop graphs:  32%|███▏      | 42160/130831 [00:38<01:01, 1430.62graphs/s]Creating k-hop graphs:  32%|███▏      | 42304/130831 [00:38<01:02, 1415.07graphs/s]Creating k-hop graphs:  32%|███▏      | 42469/130831 [00:38<00:59, 1484.07graphs/s]Creating k-hop graphs:  33%|███▎      | 42618/130831 [00:38<01:05, 1340.32graphs/s]Creating k-hop graphs:  33%|███▎      | 42755/130831 [00:38<01:06, 1316.56graphs/s]Creating k-hop graphs:  33%|███▎      | 42903/130831 [00:39<01:04, 1360.26graphs/s]Creating k-hop graphs:  33%|███▎      | 43041/130831 [00:39<01:04, 1359.38graphs/s]Creating k-hop graphs:  33%|███▎      | 43193/130831 [00:39<01:02, 1404.04graphs/s]Creating k-hop graphs:  33%|███▎      | 43343/130831 [00:39<01:01, 1429.88graphs/s]Creating k-hop graphs:  33%|███▎      | 43487/130831 [00:39<01:01, 1415.76graphs/s]Creating k-hop graphs:  33%|███▎      | 43636/130831 [00:39<01:00, 1434.94graphs/s]Creating k-hop graphs:  33%|███▎      | 43782/130831 [00:39<01:00, 1442.09graphs/s]Creating k-hop graphs:  34%|███▎      | 43928/130831 [00:39<01:00, 1444.78graphs/s]Creating k-hop graphs:  34%|███▎      | 44073/130831 [00:39<01:01, 1417.36graphs/s]Creating k-hop graphs:  34%|███▍      | 44215/130831 [00:39<01:01, 1397.66graphs/s]Creating k-hop graphs:  34%|███▍      | 44361/130831 [00:40<01:01, 1414.28graphs/s]Creating k-hop graphs:  34%|███▍      | 44503/130831 [00:40<01:04, 1347.67graphs/s]Creating k-hop graphs:  34%|███▍      | 44639/130831 [00:40<01:04, 1331.14graphs/s]Creating k-hop graphs:  34%|███▍      | 44773/130831 [00:40<01:05, 1304.47graphs/s]Creating k-hop graphs:  34%|███▍      | 44908/130831 [00:40<01:05, 1315.23graphs/s]Creating k-hop graphs:  34%|███▍      | 45040/130831 [00:40<01:07, 1267.93graphs/s]Creating k-hop graphs:  35%|███▍      | 45168/130831 [00:40<01:09, 1234.38graphs/s]Creating k-hop graphs:  35%|███▍      | 45292/130831 [00:40<01:15, 1127.87graphs/s]Creating k-hop graphs:  35%|███▍      | 45419/130831 [00:40<01:13, 1165.46graphs/s]Creating k-hop graphs:  35%|███▍      | 45549/130831 [00:41<01:10, 1201.84graphs/s]Creating k-hop graphs:  35%|███▍      | 45673/130831 [00:41<01:10, 1212.13graphs/s]Creating k-hop graphs:  35%|███▌      | 45796/130831 [00:41<01:11, 1195.70graphs/s]Creating k-hop graphs:  35%|███▌      | 45917/130831 [00:41<01:12, 1169.55graphs/s]Creating k-hop graphs:  35%|███▌      | 46035/130831 [00:41<01:12, 1165.46graphs/s]Creating k-hop graphs:  35%|███▌      | 46169/130831 [00:41<01:09, 1214.48graphs/s]Creating k-hop graphs:  35%|███▌      | 46295/130831 [00:41<01:09, 1223.76graphs/s]Creating k-hop graphs:  35%|███▌      | 46418/130831 [00:41<01:11, 1177.59graphs/s]Creating k-hop graphs:  36%|███▌      | 46537/130831 [00:41<01:13, 1147.34graphs/s]Creating k-hop graphs:  36%|███▌      | 46653/130831 [00:42<01:13, 1139.37graphs/s]Creating k-hop graphs:  36%|███▌      | 46768/130831 [00:42<01:15, 1107.91graphs/s]Creating k-hop graphs:  36%|███▌      | 46880/130831 [00:42<01:18, 1073.52graphs/s]Creating k-hop graphs:  36%|███▌      | 47007/130831 [00:42<01:14, 1127.82graphs/s]Creating k-hop graphs:  36%|███▌      | 47121/130831 [00:42<01:14, 1119.37graphs/s]Creating k-hop graphs:  36%|███▌      | 47252/130831 [00:42<01:11, 1172.27graphs/s]Creating k-hop graphs:  36%|███▌      | 47384/130831 [00:42<01:08, 1215.28graphs/s]Creating k-hop graphs:  36%|███▋      | 47527/130831 [00:42<01:05, 1276.98graphs/s]Creating k-hop graphs:  36%|███▋      | 47662/130831 [00:42<01:04, 1297.91graphs/s]Creating k-hop graphs:  37%|███▋      | 47800/130831 [00:42<01:02, 1321.97graphs/s]Creating k-hop graphs:  37%|███▋      | 47933/130831 [00:43<01:02, 1316.79graphs/s]Creating k-hop graphs:  37%|███▋      | 48065/130831 [00:43<01:03, 1310.52graphs/s]Creating k-hop graphs:  37%|███▋      | 48197/130831 [00:43<01:04, 1287.55graphs/s]Creating k-hop graphs:  37%|███▋      | 48332/130831 [00:43<01:03, 1304.16graphs/s]Creating k-hop graphs:  37%|███▋      | 48463/130831 [00:43<01:04, 1280.70graphs/s]Creating k-hop graphs:  37%|███▋      | 48592/130831 [00:43<01:06, 1245.74graphs/s]Creating k-hop graphs:  37%|███▋      | 48731/130831 [00:43<01:03, 1285.69graphs/s]Creating k-hop graphs:  37%|███▋      | 48865/130831 [00:43<01:03, 1300.85graphs/s]Creating k-hop graphs:  37%|███▋      | 48996/130831 [00:43<01:06, 1226.06graphs/s]Creating k-hop graphs:  38%|███▊      | 49131/130831 [00:44<01:04, 1260.04graphs/s]Creating k-hop graphs:  38%|███▊      | 49258/130831 [00:44<01:06, 1221.41graphs/s]Creating k-hop graphs:  38%|███▊      | 49381/130831 [00:44<01:06, 1222.41graphs/s]Creating k-hop graphs:  38%|███▊      | 49504/130831 [00:44<01:07, 1200.94graphs/s]Creating k-hop graphs:  38%|███▊      | 49625/130831 [00:44<01:11, 1138.60graphs/s]Creating k-hop graphs:  38%|███▊      | 49740/130831 [00:44<01:14, 1094.48graphs/s]Creating k-hop graphs:  38%|███▊      | 49851/130831 [00:44<01:14, 1090.10graphs/s]Creating k-hop graphs:  38%|███▊      | 49966/130831 [00:44<01:13, 1105.88graphs/s]Creating k-hop graphs:  38%|███▊      | 50078/130831 [00:44<01:14, 1085.40graphs/s]Creating k-hop graphs:  38%|███▊      | 50187/130831 [00:44<01:16, 1059.42graphs/s]Creating k-hop graphs:  38%|███▊      | 50296/130831 [00:45<01:15, 1068.03graphs/s]Creating k-hop graphs:  39%|███▊      | 50404/130831 [00:45<01:16, 1049.00graphs/s]Creating k-hop graphs:  39%|███▊      | 50510/130831 [00:45<01:20, 994.86graphs/s] Creating k-hop graphs:  39%|███▊      | 50613/130831 [00:45<01:19, 1002.74graphs/s]Creating k-hop graphs:  39%|███▉      | 50714/130831 [00:45<01:22, 975.48graphs/s] Creating k-hop graphs:  39%|███▉      | 50812/130831 [00:45<01:25, 938.88graphs/s]Creating k-hop graphs:  39%|███▉      | 50922/130831 [00:45<01:21, 981.97graphs/s]Creating k-hop graphs:  39%|███▉      | 51021/130831 [00:45<01:26, 918.74graphs/s]Creating k-hop graphs:  39%|███▉      | 51114/130831 [00:45<01:27, 913.70graphs/s]Creating k-hop graphs:  39%|███▉      | 51207/130831 [00:46<01:27, 905.17graphs/s]Creating k-hop graphs:  39%|███▉      | 51298/130831 [00:46<01:35, 836.60graphs/s]Creating k-hop graphs:  39%|███▉      | 51383/130831 [00:46<01:38, 805.86graphs/s]Creating k-hop graphs:  39%|███▉      | 51465/130831 [00:46<01:40, 791.16graphs/s]Creating k-hop graphs:  39%|███▉      | 51545/130831 [00:46<01:49, 721.61graphs/s]Creating k-hop graphs:  39%|███▉      | 51619/130831 [00:46<01:49, 721.82graphs/s]Creating k-hop graphs:  40%|███▉      | 51693/130831 [00:46<01:50, 716.47graphs/s]Creating k-hop graphs:  40%|███▉      | 51766/130831 [00:46<01:50, 717.01graphs/s]Creating k-hop graphs:  40%|███▉      | 51843/130831 [00:46<01:48, 729.55graphs/s]Creating k-hop graphs:  40%|███▉      | 51919/130831 [00:47<01:47, 737.26graphs/s]Creating k-hop graphs:  40%|███▉      | 51993/130831 [00:47<01:48, 728.04graphs/s]Creating k-hop graphs:  40%|███▉      | 52067/130831 [00:47<01:47, 730.12graphs/s]Creating k-hop graphs:  40%|███▉      | 52141/130831 [00:47<01:49, 716.94graphs/s]Creating k-hop graphs:  40%|███▉      | 52214/130831 [00:47<01:49, 719.27graphs/s]Creating k-hop graphs:  40%|███▉      | 52287/130831 [00:47<01:49, 718.54graphs/s]Creating k-hop graphs:  40%|████      | 52359/130831 [00:47<01:53, 691.68graphs/s]Creating k-hop graphs:  40%|████      | 52429/130831 [00:47<01:55, 681.58graphs/s]Creating k-hop graphs:  40%|████      | 52498/130831 [00:47<01:58, 662.63graphs/s]Creating k-hop graphs:  40%|████      | 52565/130831 [00:48<02:00, 650.85graphs/s]Creating k-hop graphs:  40%|████      | 52662/130831 [00:48<01:45, 740.26graphs/s]Creating k-hop graphs:  40%|████      | 52755/130831 [00:48<01:38, 794.23graphs/s]Creating k-hop graphs:  40%|████      | 52856/130831 [00:48<01:30, 856.96graphs/s]Creating k-hop graphs:  40%|████      | 52943/130831 [00:48<01:33, 831.16graphs/s]Creating k-hop graphs:  41%|████      | 53034/130831 [00:48<01:31, 852.97graphs/s]Creating k-hop graphs:  41%|████      | 53143/130831 [00:48<01:24, 920.81graphs/s]Creating k-hop graphs:  41%|████      | 53261/130831 [00:48<01:18, 992.89graphs/s]Creating k-hop graphs:  41%|████      | 53361/130831 [00:48<01:19, 976.03graphs/s]Creating k-hop graphs:  41%|████      | 53459/130831 [00:48<01:19, 974.22graphs/s]Creating k-hop graphs:  41%|████      | 53562/130831 [00:49<01:18, 985.10graphs/s]Creating k-hop graphs:  41%|████      | 53661/130831 [00:49<01:19, 966.36graphs/s]Creating k-hop graphs:  41%|████      | 53758/130831 [00:49<01:23, 921.21graphs/s]Creating k-hop graphs:  41%|████      | 53854/130831 [00:49<01:22, 930.08graphs/s]Creating k-hop graphs:  41%|████      | 53948/130831 [00:49<01:23, 917.62graphs/s]Creating k-hop graphs:  41%|████▏     | 54041/130831 [00:49<01:24, 906.41graphs/s]Creating k-hop graphs:  41%|████▏     | 54132/130831 [00:49<01:25, 897.23graphs/s]Creating k-hop graphs:  41%|████▏     | 54230/130831 [00:49<01:23, 920.66graphs/s]Creating k-hop graphs:  42%|████▏     | 54323/130831 [00:49<01:28, 866.95graphs/s]Creating k-hop graphs:  42%|████▏     | 54411/130831 [00:50<01:35, 797.09graphs/s]Creating k-hop graphs:  42%|████▏     | 54493/130831 [00:50<01:35, 800.84graphs/s]Creating k-hop graphs:  42%|████▏     | 54575/130831 [00:50<01:35, 800.24graphs/s]Creating k-hop graphs:  42%|████▏     | 54662/130831 [00:50<01:33, 817.36graphs/s]Creating k-hop graphs:  42%|████▏     | 54745/130831 [00:50<01:42, 740.12graphs/s]Creating k-hop graphs:  42%|████▏     | 54821/130831 [00:50<01:44, 727.44graphs/s]Creating k-hop graphs:  42%|████▏     | 54921/130831 [00:50<01:34, 801.44graphs/s]Creating k-hop graphs:  42%|████▏     | 55025/130831 [00:50<01:27, 865.50graphs/s]Creating k-hop graphs:  42%|████▏     | 55113/130831 [00:50<01:27, 860.43graphs/s]Creating k-hop graphs:  42%|████▏     | 55217/130831 [00:51<01:23, 909.35graphs/s]Creating k-hop graphs:  42%|████▏     | 55309/130831 [00:51<01:24, 899.06graphs/s]Creating k-hop graphs:  42%|████▏     | 55400/130831 [00:51<01:24, 893.01graphs/s]Creating k-hop graphs:  42%|████▏     | 55505/130831 [00:51<01:20, 938.21graphs/s]Creating k-hop graphs:  42%|████▏     | 55600/130831 [00:51<01:21, 924.59graphs/s]Creating k-hop graphs:  43%|████▎     | 55693/130831 [00:51<01:22, 913.65graphs/s]Creating k-hop graphs:  43%|████▎     | 55785/130831 [00:51<01:28, 851.02graphs/s]Creating k-hop graphs:  43%|████▎     | 55872/130831 [00:51<01:39, 754.45graphs/s]Creating k-hop graphs:  43%|████▎     | 55950/130831 [00:51<01:46, 703.46graphs/s]Creating k-hop graphs:  43%|████▎     | 56023/130831 [00:52<01:57, 639.09graphs/s]Creating k-hop graphs:  43%|████▎     | 56100/130831 [00:52<01:51, 669.57graphs/s]Creating k-hop graphs:  43%|████▎     | 56190/130831 [00:52<01:42, 729.56graphs/s]Creating k-hop graphs:  43%|████▎     | 56266/130831 [00:52<01:49, 680.69graphs/s]Creating k-hop graphs:  43%|████▎     | 56341/130831 [00:52<01:46, 697.69graphs/s]Creating k-hop graphs:  43%|████▎     | 56413/130831 [00:52<01:50, 673.48graphs/s]Creating k-hop graphs:  43%|████▎     | 56482/130831 [00:52<01:50, 674.79graphs/s]Creating k-hop graphs:  43%|████▎     | 56551/130831 [00:52<01:49, 677.31graphs/s]Creating k-hop graphs:  43%|████▎     | 56623/130831 [00:52<01:47, 688.84graphs/s]Creating k-hop graphs:  43%|████▎     | 56693/130831 [00:53<01:56, 634.52graphs/s]Creating k-hop graphs:  43%|████▎     | 56758/130831 [00:53<02:06, 584.62graphs/s]Creating k-hop graphs:  43%|████▎     | 56827/130831 [00:53<02:01, 611.02graphs/s]Creating k-hop graphs:  43%|████▎     | 56890/130831 [00:53<02:00, 613.46graphs/s]Creating k-hop graphs:  44%|████▎     | 56954/130831 [00:53<01:59, 620.77graphs/s]Creating k-hop graphs:  44%|████▎     | 57017/130831 [00:53<02:01, 609.79graphs/s]Creating k-hop graphs:  44%|████▎     | 57080/130831 [00:53<02:00, 613.34graphs/s]Creating k-hop graphs:  44%|████▎     | 57159/130831 [00:53<01:51, 663.61graphs/s]Creating k-hop graphs:  44%|████▎     | 57228/130831 [00:53<01:49, 670.37graphs/s]Creating k-hop graphs:  44%|████▍     | 57299/130831 [00:54<01:48, 679.55graphs/s]Creating k-hop graphs:  44%|████▍     | 57368/130831 [00:54<01:48, 675.17graphs/s]Creating k-hop graphs:  44%|████▍     | 57436/130831 [00:54<01:56, 628.76graphs/s]Creating k-hop graphs:  44%|████▍     | 57500/130831 [00:54<01:58, 616.81graphs/s]Creating k-hop graphs:  44%|████▍     | 57563/130831 [00:54<01:59, 612.49graphs/s]Creating k-hop graphs:  44%|████▍     | 57627/130831 [00:54<01:58, 618.80graphs/s]Creating k-hop graphs:  44%|████▍     | 57691/130831 [00:54<01:57, 624.01graphs/s]Creating k-hop graphs:  44%|████▍     | 57761/130831 [00:54<01:53, 646.01graphs/s]Creating k-hop graphs:  44%|████▍     | 57826/130831 [00:54<01:53, 640.89graphs/s]Creating k-hop graphs:  44%|████▍     | 57891/130831 [00:54<01:54, 635.61graphs/s]Creating k-hop graphs:  44%|████▍     | 57955/130831 [00:55<01:57, 622.33graphs/s]Creating k-hop graphs:  44%|████▍     | 58018/130831 [00:55<01:59, 611.31graphs/s]Creating k-hop graphs:  44%|████▍     | 58080/130831 [00:55<01:58, 613.27graphs/s]Creating k-hop graphs:  44%|████▍     | 58148/130831 [00:55<01:55, 630.25graphs/s]Creating k-hop graphs:  44%|████▍     | 58212/130831 [00:55<01:57, 616.54graphs/s]Creating k-hop graphs:  45%|████▍     | 58274/130831 [00:55<02:00, 600.73graphs/s]Creating k-hop graphs:  45%|████▍     | 58335/130831 [00:55<02:01, 597.07graphs/s]Creating k-hop graphs:  45%|████▍     | 58395/130831 [00:55<02:06, 573.82graphs/s]Creating k-hop graphs:  45%|████▍     | 58453/130831 [00:55<02:12, 548.07graphs/s]Creating k-hop graphs:  45%|████▍     | 58510/130831 [00:56<02:10, 552.41graphs/s]Creating k-hop graphs:  45%|████▍     | 58566/130831 [00:56<02:15, 533.77graphs/s]Creating k-hop graphs:  45%|████▍     | 58622/130831 [00:56<02:13, 539.53graphs/s]Creating k-hop graphs:  45%|████▍     | 58677/130831 [00:56<02:15, 532.68graphs/s]Creating k-hop graphs:  45%|████▍     | 58738/130831 [00:56<02:10, 553.68graphs/s]Creating k-hop graphs:  45%|████▍     | 58794/130831 [00:56<02:17, 524.43graphs/s]Creating k-hop graphs:  45%|████▍     | 58847/130831 [00:56<02:28, 484.98graphs/s]Creating k-hop graphs:  45%|████▌     | 58897/130831 [00:56<02:34, 466.82graphs/s]Creating k-hop graphs:  45%|████▌     | 58969/130831 [00:56<02:14, 532.89graphs/s]Creating k-hop graphs:  45%|████▌     | 59031/130831 [00:57<02:09, 556.49graphs/s]Creating k-hop graphs:  45%|████▌     | 59115/130831 [00:57<01:52, 634.98graphs/s]Creating k-hop graphs:  45%|████▌     | 59200/130831 [00:57<01:42, 696.25graphs/s]Creating k-hop graphs:  45%|████▌     | 59289/130831 [00:57<01:35, 751.13graphs/s]Creating k-hop graphs:  45%|████▌     | 59365/130831 [00:57<01:35, 746.51graphs/s]Creating k-hop graphs:  45%|████▌     | 59455/130831 [00:57<01:30, 789.12graphs/s]Creating k-hop graphs:  46%|████▌     | 59560/130831 [00:57<01:22, 864.11graphs/s]Creating k-hop graphs:  46%|████▌     | 59647/130831 [00:57<01:26, 826.11graphs/s]Creating k-hop graphs:  46%|████▌     | 59731/130831 [00:57<01:26, 825.90graphs/s]Creating k-hop graphs:  46%|████▌     | 59815/130831 [00:57<01:27, 812.60graphs/s]Creating k-hop graphs:  46%|████▌     | 59897/130831 [00:58<01:31, 775.38graphs/s]Creating k-hop graphs:  46%|████▌     | 59976/130831 [00:58<01:39, 714.28graphs/s]Creating k-hop graphs:  46%|████▌     | 60049/130831 [00:58<01:39, 709.32graphs/s]Creating k-hop graphs:  46%|████▌     | 60145/130831 [00:58<01:30, 776.78graphs/s]Creating k-hop graphs:  46%|████▌     | 60224/130831 [00:58<01:39, 706.65graphs/s]Creating k-hop graphs:  46%|████▌     | 60297/130831 [00:58<01:41, 694.72graphs/s]Creating k-hop graphs:  46%|████▌     | 60370/130831 [00:58<01:40, 703.78graphs/s]Creating k-hop graphs:  46%|████▌     | 60442/130831 [00:58<01:42, 689.78graphs/s]Creating k-hop graphs:  46%|████▋     | 60512/130831 [00:58<01:41, 692.59graphs/s]Creating k-hop graphs:  46%|████▋     | 60592/130831 [00:59<01:37, 720.30graphs/s]Creating k-hop graphs:  46%|████▋     | 60715/130831 [00:59<01:20, 866.91graphs/s]Creating k-hop graphs:  47%|████▋     | 60838/130831 [00:59<01:12, 970.85graphs/s]Creating k-hop graphs:  47%|████▋     | 60936/130831 [00:59<01:11, 970.94graphs/s]Creating k-hop graphs:  47%|████▋     | 61034/130831 [00:59<01:17, 895.37graphs/s]Creating k-hop graphs:  47%|████▋     | 61126/130831 [00:59<01:17, 899.33graphs/s]Creating k-hop graphs:  47%|████▋     | 61218/130831 [00:59<01:18, 889.10graphs/s]Creating k-hop graphs:  47%|████▋     | 61308/130831 [00:59<01:20, 859.74graphs/s]Creating k-hop graphs:  47%|████▋     | 61399/130831 [00:59<01:19, 872.44graphs/s]Creating k-hop graphs:  47%|████▋     | 61488/130831 [01:00<01:19, 875.29graphs/s]Creating k-hop graphs:  47%|████▋     | 61576/130831 [01:00<01:21, 848.16graphs/s]Creating k-hop graphs:  47%|████▋     | 61679/130831 [01:00<01:16, 899.69graphs/s]Creating k-hop graphs:  47%|████▋     | 61770/130831 [01:00<01:17, 888.99graphs/s]Creating k-hop graphs:  47%|████▋     | 61860/130831 [01:00<01:20, 854.28graphs/s]Creating k-hop graphs:  47%|████▋     | 61946/130831 [01:00<01:23, 828.43graphs/s]Creating k-hop graphs:  47%|████▋     | 62030/130831 [01:00<01:32, 744.69graphs/s]Creating k-hop graphs:  47%|████▋     | 62111/130831 [01:00<01:30, 760.82graphs/s]Creating k-hop graphs:  48%|████▊     | 62195/130831 [01:00<01:27, 781.23graphs/s]Creating k-hop graphs:  48%|████▊     | 62280/130831 [01:01<01:25, 800.37graphs/s]Creating k-hop graphs:  48%|████▊     | 62361/130831 [01:01<01:28, 769.54graphs/s]Creating k-hop graphs:  48%|████▊     | 62453/130831 [01:01<01:24, 811.24graphs/s]Creating k-hop graphs:  48%|████▊     | 62535/130831 [01:01<01:27, 784.56graphs/s]Creating k-hop graphs:  48%|████▊     | 62615/130831 [01:01<01:33, 732.52graphs/s]Creating k-hop graphs:  48%|████▊     | 62694/130831 [01:01<01:31, 743.63graphs/s]Creating k-hop graphs:  48%|████▊     | 62770/130831 [01:01<01:32, 738.47graphs/s]Creating k-hop graphs:  48%|████▊     | 62845/130831 [01:01<01:33, 724.61graphs/s]Creating k-hop graphs:  48%|████▊     | 62971/130831 [01:01<01:17, 875.35graphs/s]Creating k-hop graphs:  48%|████▊     | 63081/130831 [01:01<01:12, 938.63graphs/s]Creating k-hop graphs:  48%|████▊     | 63182/130831 [01:02<01:10, 956.17graphs/s]Creating k-hop graphs:  48%|████▊     | 63286/130831 [01:02<01:08, 979.19graphs/s]Creating k-hop graphs:  48%|████▊     | 63385/130831 [01:02<01:09, 967.53graphs/s]Creating k-hop graphs:  49%|████▊     | 63483/130831 [01:02<01:14, 909.30graphs/s]Creating k-hop graphs:  49%|████▊     | 63575/130831 [01:02<01:14, 901.33graphs/s]Creating k-hop graphs:  49%|████▊     | 63666/130831 [01:02<01:14, 899.68graphs/s]Creating k-hop graphs:  49%|████▊     | 63757/130831 [01:02<01:15, 892.24graphs/s]Creating k-hop graphs:  49%|████▉     | 63847/130831 [01:02<01:15, 882.82graphs/s]Creating k-hop graphs:  49%|████▉     | 63936/130831 [01:02<01:15, 880.50graphs/s]Creating k-hop graphs:  49%|████▉     | 64025/130831 [01:03<01:16, 869.80graphs/s]Creating k-hop graphs:  49%|████▉     | 64117/130831 [01:03<01:15, 881.82graphs/s]Creating k-hop graphs:  49%|████▉     | 64224/130831 [01:03<01:11, 934.96graphs/s]Creating k-hop graphs:  49%|████▉     | 64318/130831 [01:03<01:13, 900.05graphs/s]Creating k-hop graphs:  49%|████▉     | 64441/130831 [01:03<01:06, 992.02graphs/s]Creating k-hop graphs:  49%|████▉     | 64541/130831 [01:03<01:10, 942.25graphs/s]Creating k-hop graphs:  49%|████▉     | 64637/130831 [01:03<01:10, 940.54graphs/s]Creating k-hop graphs:  49%|████▉     | 64732/130831 [01:03<01:11, 927.02graphs/s]Creating k-hop graphs:  50%|████▉     | 64853/130831 [01:03<01:05, 1007.30graphs/s]Creating k-hop graphs:  50%|████▉     | 64975/130831 [01:03<01:01, 1067.81graphs/s]Creating k-hop graphs:  50%|████▉     | 65123/130831 [01:04<00:55, 1188.16graphs/s]Creating k-hop graphs:  50%|████▉     | 65249/130831 [01:04<00:54, 1207.84graphs/s]Creating k-hop graphs:  50%|████▉     | 65371/130831 [01:04<00:54, 1200.77graphs/s]Creating k-hop graphs:  50%|█████     | 65506/130831 [01:04<00:52, 1244.11graphs/s]Creating k-hop graphs:  50%|█████     | 65631/130831 [01:04<00:53, 1214.15graphs/s]Creating k-hop graphs:  50%|█████     | 65770/130831 [01:04<00:51, 1264.75graphs/s]Creating k-hop graphs:  50%|█████     | 65897/130831 [01:04<00:51, 1249.01graphs/s]Creating k-hop graphs:  50%|█████     | 66023/130831 [01:04<00:52, 1243.73graphs/s]Creating k-hop graphs:  51%|█████     | 66149/130831 [01:04<00:51, 1248.49graphs/s]Creating k-hop graphs:  51%|█████     | 66274/130831 [01:05<00:53, 1216.21graphs/s]Creating k-hop graphs:  51%|█████     | 66396/130831 [01:05<00:55, 1161.71graphs/s]Creating k-hop graphs:  51%|█████     | 66513/130831 [01:05<00:55, 1150.04graphs/s]Creating k-hop graphs:  51%|█████     | 66629/130831 [01:05<00:58, 1089.24graphs/s]Creating k-hop graphs:  51%|█████     | 66739/130831 [01:05<01:02, 1032.37graphs/s]Creating k-hop graphs:  51%|█████     | 66844/130831 [01:05<01:01, 1033.25graphs/s]Creating k-hop graphs:  51%|█████     | 66948/130831 [01:05<01:02, 1021.08graphs/s]Creating k-hop graphs:  51%|█████▏    | 67067/130831 [01:05<00:59, 1068.85graphs/s]Creating k-hop graphs:  51%|█████▏    | 67175/130831 [01:05<01:03, 1000.30graphs/s]Creating k-hop graphs:  51%|█████▏    | 67277/130831 [01:06<01:04, 990.72graphs/s] Creating k-hop graphs:  52%|█████▏    | 67383/130831 [01:06<01:02, 1008.72graphs/s]Creating k-hop graphs:  52%|█████▏    | 67501/130831 [01:06<00:59, 1057.39graphs/s]Creating k-hop graphs:  52%|█████▏    | 67623/130831 [01:06<00:57, 1102.95graphs/s]Creating k-hop graphs:  52%|█████▏    | 67734/130831 [01:06<01:00, 1038.18graphs/s]Creating k-hop graphs:  52%|█████▏    | 67839/130831 [01:06<01:02, 1000.23graphs/s]Creating k-hop graphs:  52%|█████▏    | 67940/130831 [01:06<01:04, 978.29graphs/s] Creating k-hop graphs:  52%|█████▏    | 68046/130831 [01:06<01:02, 1000.10graphs/s]Creating k-hop graphs:  52%|█████▏    | 68147/130831 [01:06<01:02, 1001.97graphs/s]Creating k-hop graphs:  52%|█████▏    | 68258/130831 [01:06<01:00, 1032.67graphs/s]Creating k-hop graphs:  52%|█████▏    | 68362/130831 [01:07<01:01, 1015.06graphs/s]Creating k-hop graphs:  52%|█████▏    | 68469/130831 [01:07<01:00, 1028.96graphs/s]Creating k-hop graphs:  52%|█████▏    | 68574/130831 [01:07<01:00, 1033.39graphs/s]Creating k-hop graphs:  52%|█████▏    | 68678/130831 [01:07<01:04, 967.28graphs/s] Creating k-hop graphs:  53%|█████▎    | 68776/130831 [01:07<01:05, 946.92graphs/s]Creating k-hop graphs:  53%|█████▎    | 68872/130831 [01:07<01:05, 943.28graphs/s]Creating k-hop graphs:  53%|█████▎    | 68967/130831 [01:07<01:06, 927.45graphs/s]Creating k-hop graphs:  53%|█████▎    | 69061/130831 [01:07<01:06, 929.26graphs/s]Creating k-hop graphs:  53%|█████▎    | 69162/130831 [01:07<01:04, 951.35graphs/s]Creating k-hop graphs:  53%|█████▎    | 69264/130831 [01:08<01:03, 970.44graphs/s]Creating k-hop graphs:  53%|█████▎    | 69375/130831 [01:08<01:00, 1010.55graphs/s]Creating k-hop graphs:  53%|█████▎    | 69495/130831 [01:08<00:57, 1066.38graphs/s]Creating k-hop graphs:  53%|█████▎    | 69608/130831 [01:08<00:56, 1082.62graphs/s]Creating k-hop graphs:  53%|█████▎    | 69717/130831 [01:08<00:56, 1081.48graphs/s]Creating k-hop graphs:  53%|█████▎    | 69834/130831 [01:08<00:55, 1105.98graphs/s]Creating k-hop graphs:  53%|█████▎    | 69946/130831 [01:08<00:54, 1109.67graphs/s]Creating k-hop graphs:  54%|█████▎    | 70058/130831 [01:08<00:55, 1103.10graphs/s]Creating k-hop graphs:  54%|█████▎    | 70174/130831 [01:08<00:54, 1118.46graphs/s]Creating k-hop graphs:  54%|█████▎    | 70286/130831 [01:08<00:55, 1094.46graphs/s]Creating k-hop graphs:  54%|█████▍    | 70411/130831 [01:09<00:53, 1139.52graphs/s]Creating k-hop graphs:  54%|█████▍    | 70526/130831 [01:09<00:54, 1115.29graphs/s]Creating k-hop graphs:  54%|█████▍    | 70638/130831 [01:09<00:56, 1071.38graphs/s]Creating k-hop graphs:  54%|█████▍    | 70746/130831 [01:09<00:56, 1060.05graphs/s]Creating k-hop graphs:  54%|█████▍    | 70853/130831 [01:09<00:58, 1033.69graphs/s]Creating k-hop graphs:  54%|█████▍    | 70961/130831 [01:09<00:57, 1044.01graphs/s]Creating k-hop graphs:  54%|█████▍    | 71066/130831 [01:09<00:59, 1010.93graphs/s]Creating k-hop graphs:  54%|█████▍    | 71174/130831 [01:09<00:57, 1029.73graphs/s]Creating k-hop graphs:  54%|█████▍    | 71278/130831 [01:09<00:59, 996.23graphs/s] Creating k-hop graphs:  55%|█████▍    | 71378/130831 [01:09<01:00, 974.73graphs/s]Creating k-hop graphs:  55%|█████▍    | 71479/130831 [01:10<01:00, 982.45graphs/s]Creating k-hop graphs:  55%|█████▍    | 71580/130831 [01:10<00:59, 989.57graphs/s]Creating k-hop graphs:  55%|█████▍    | 71686/130831 [01:10<00:58, 1007.47graphs/s]Creating k-hop graphs:  55%|█████▍    | 71791/130831 [01:10<00:58, 1017.04graphs/s]Creating k-hop graphs:  55%|█████▍    | 71893/130831 [01:10<00:58, 1009.90graphs/s]Creating k-hop graphs:  55%|█████▌    | 71996/130831 [01:10<00:58, 1012.80graphs/s]Creating k-hop graphs:  55%|█████▌    | 72098/130831 [01:10<00:57, 1014.82graphs/s]Creating k-hop graphs:  55%|█████▌    | 72200/130831 [01:10<01:05, 890.18graphs/s] Creating k-hop graphs:  55%|█████▌    | 72300/130831 [01:10<01:03, 917.06graphs/s]Creating k-hop graphs:  55%|█████▌    | 72397/130831 [01:11<01:02, 929.90graphs/s]Creating k-hop graphs:  55%|█████▌    | 72512/130831 [01:11<00:58, 992.04graphs/s]Creating k-hop graphs:  56%|█████▌    | 72613/130831 [01:11<01:00, 966.57graphs/s]Creating k-hop graphs:  56%|█████▌    | 72711/130831 [01:11<01:01, 938.63graphs/s]Creating k-hop graphs:  56%|█████▌    | 72806/130831 [01:11<01:03, 909.62graphs/s]Creating k-hop graphs:  56%|█████▌    | 72906/130831 [01:11<01:02, 933.74graphs/s]Creating k-hop graphs:  56%|█████▌    | 73003/130831 [01:11<01:01, 942.84graphs/s]Creating k-hop graphs:  56%|█████▌    | 73104/130831 [01:11<01:00, 960.70graphs/s]Creating k-hop graphs:  56%|█████▌    | 73201/130831 [01:11<01:01, 938.63graphs/s]Creating k-hop graphs:  56%|█████▌    | 73296/130831 [01:12<01:02, 926.92graphs/s]Creating k-hop graphs:  56%|█████▌    | 73389/130831 [01:12<01:02, 913.68graphs/s]Creating k-hop graphs:  56%|█████▌    | 73489/130831 [01:12<01:01, 936.01graphs/s]Creating k-hop graphs:  56%|█████▌    | 73583/130831 [01:12<01:03, 907.18graphs/s]Creating k-hop graphs:  56%|█████▋    | 73674/130831 [01:12<01:03, 898.52graphs/s]Creating k-hop graphs:  56%|█████▋    | 73765/130831 [01:12<01:05, 872.72graphs/s]Creating k-hop graphs:  56%|█████▋    | 73853/130831 [01:12<01:08, 829.86graphs/s]Creating k-hop graphs:  57%|█████▋    | 73937/130831 [01:12<01:09, 816.47graphs/s]Creating k-hop graphs:  57%|█████▋    | 74061/130831 [01:12<01:00, 932.77graphs/s]Creating k-hop graphs:  57%|█████▋    | 74174/130831 [01:12<00:57, 987.60graphs/s]Creating k-hop graphs:  57%|█████▋    | 74281/130831 [01:13<00:56, 1008.75graphs/s]Creating k-hop graphs:  57%|█████▋    | 74393/130831 [01:13<00:54, 1040.65graphs/s]Creating k-hop graphs:  57%|█████▋    | 74498/130831 [01:13<00:57, 976.97graphs/s] Creating k-hop graphs:  57%|█████▋    | 74597/130831 [01:13<00:58, 956.55graphs/s]Creating k-hop graphs:  57%|█████▋    | 74694/130831 [01:13<01:01, 914.09graphs/s]Creating k-hop graphs:  57%|█████▋    | 74787/130831 [01:13<01:04, 867.05graphs/s]Creating k-hop graphs:  57%|█████▋    | 74875/130831 [01:13<01:07, 832.26graphs/s]Creating k-hop graphs:  57%|█████▋    | 74959/130831 [01:13<01:12, 766.66graphs/s]Creating k-hop graphs:  57%|█████▋    | 75037/130831 [01:14<01:17, 720.13graphs/s]Creating k-hop graphs:  57%|█████▋    | 75116/130831 [01:14<01:15, 735.92graphs/s]Creating k-hop graphs:  57%|█████▋    | 75201/130831 [01:14<01:12, 764.99graphs/s]Creating k-hop graphs:  58%|█████▊    | 75282/130831 [01:14<01:11, 775.20graphs/s]Creating k-hop graphs:  58%|█████▊    | 75374/130831 [01:14<01:07, 816.14graphs/s]Creating k-hop graphs:  58%|█████▊    | 75460/130831 [01:14<01:06, 826.85graphs/s]Creating k-hop graphs:  58%|█████▊    | 75563/130831 [01:14<01:02, 884.19graphs/s]Creating k-hop graphs:  58%|█████▊    | 75671/130831 [01:14<00:58, 938.98graphs/s]Creating k-hop graphs:  58%|█████▊    | 75766/130831 [01:14<01:00, 913.22graphs/s]Creating k-hop graphs:  58%|█████▊    | 75858/130831 [01:14<01:00, 903.22graphs/s]Creating k-hop graphs:  58%|█████▊    | 75961/130831 [01:15<00:58, 939.49graphs/s]Creating k-hop graphs:  58%|█████▊    | 76056/130831 [01:15<00:59, 917.57graphs/s]Creating k-hop graphs:  58%|█████▊    | 76176/130831 [01:15<00:54, 998.21graphs/s]Creating k-hop graphs:  58%|█████▊    | 76277/130831 [01:15<00:59, 910.29graphs/s]Creating k-hop graphs:  58%|█████▊    | 76370/130831 [01:15<01:01, 890.44graphs/s]Creating k-hop graphs:  58%|█████▊    | 76474/130831 [01:15<00:58, 928.01graphs/s]Creating k-hop graphs:  59%|█████▊    | 76568/130831 [01:15<01:03, 850.33graphs/s]Creating k-hop graphs:  59%|█████▊    | 76655/130831 [01:15<01:07, 805.31graphs/s]Creating k-hop graphs:  59%|█████▊    | 76742/130831 [01:15<01:05, 821.84graphs/s]Creating k-hop graphs:  59%|█████▊    | 76826/130831 [01:16<01:05, 822.59graphs/s]Creating k-hop graphs:  59%|█████▉    | 76916/130831 [01:16<01:04, 842.08graphs/s]Creating k-hop graphs:  59%|█████▉    | 77001/130831 [01:16<01:06, 811.80graphs/s]Creating k-hop graphs:  59%|█████▉    | 77096/130831 [01:16<01:03, 848.15graphs/s]Creating k-hop graphs:  59%|█████▉    | 77209/130831 [01:16<00:57, 926.59graphs/s]Creating k-hop graphs:  59%|█████▉    | 77312/130831 [01:16<00:56, 955.34graphs/s]Creating k-hop graphs:  59%|█████▉    | 77410/130831 [01:16<00:55, 960.79graphs/s]Creating k-hop graphs:  59%|█████▉    | 77507/130831 [01:16<00:55, 957.48graphs/s]Creating k-hop graphs:  59%|█████▉    | 77624/130831 [01:16<00:52, 1018.48graphs/s]Creating k-hop graphs:  59%|█████▉    | 77727/130831 [01:16<00:52, 1008.88graphs/s]Creating k-hop graphs:  59%|█████▉    | 77831/130831 [01:17<00:52, 1016.75graphs/s]Creating k-hop graphs:  60%|█████▉    | 77933/130831 [01:17<00:53, 994.45graphs/s] Creating k-hop graphs:  60%|█████▉    | 78036/130831 [01:17<00:52, 1002.41graphs/s]Creating k-hop graphs:  60%|█████▉    | 78137/130831 [01:17<00:52, 997.26graphs/s] Creating k-hop graphs:  60%|█████▉    | 78237/130831 [01:17<00:55, 954.27graphs/s]Creating k-hop graphs:  60%|█████▉    | 78333/130831 [01:17<00:55, 950.35graphs/s]Creating k-hop graphs:  60%|█████▉    | 78439/130831 [01:17<00:53, 980.11graphs/s]Creating k-hop graphs:  60%|██████    | 78563/130831 [01:17<00:49, 1054.94graphs/s]Creating k-hop graphs:  60%|██████    | 78669/130831 [01:17<00:49, 1046.39graphs/s]Creating k-hop graphs:  60%|██████    | 78774/130831 [01:18<00:55, 939.78graphs/s] Creating k-hop graphs:  60%|██████    | 78871/130831 [01:18<00:58, 891.69graphs/s]Creating k-hop graphs:  60%|██████    | 78967/130831 [01:18<00:57, 908.05graphs/s]Creating k-hop graphs:  60%|██████    | 79074/130831 [01:18<00:54, 949.65graphs/s]Creating k-hop graphs:  61%|██████    | 79171/130831 [01:18<00:54, 942.86graphs/s]Creating k-hop graphs:  61%|██████    | 79267/130831 [01:18<00:56, 910.33graphs/s]Creating k-hop graphs:  61%|██████    | 79359/130831 [01:18<00:59, 869.29graphs/s]Creating k-hop graphs:  61%|██████    | 79467/130831 [01:18<00:55, 926.32graphs/s]Creating k-hop graphs:  61%|██████    | 79564/130831 [01:18<00:54, 934.91graphs/s]Creating k-hop graphs:  61%|██████    | 79659/130831 [01:19<00:56, 908.95graphs/s]Creating k-hop graphs:  61%|██████    | 79751/130831 [01:19<00:56, 909.44graphs/s]Creating k-hop graphs:  61%|██████    | 79847/130831 [01:19<00:55, 922.58graphs/s]Creating k-hop graphs:  61%|██████    | 79940/130831 [01:19<00:57, 892.17graphs/s]Creating k-hop graphs:  61%|██████    | 80045/130831 [01:19<00:54, 932.50graphs/s]Creating k-hop graphs:  61%|██████▏   | 80139/130831 [01:19<00:56, 901.78graphs/s]Creating k-hop graphs:  61%|██████▏   | 80234/130831 [01:19<00:55, 913.78graphs/s]Creating k-hop graphs:  61%|██████▏   | 80326/130831 [01:20<01:36, 522.14graphs/s]Creating k-hop graphs:  61%|██████▏   | 80417/130831 [01:20<01:24, 595.00graphs/s]Creating k-hop graphs:  62%|██████▏   | 80511/130831 [01:20<01:15, 667.96graphs/s]Creating k-hop graphs:  62%|██████▏   | 80613/130831 [01:20<01:06, 749.57graphs/s]Creating k-hop graphs:  62%|██████▏   | 80717/130831 [01:20<01:01, 820.87graphs/s]Creating k-hop graphs:  62%|██████▏   | 80810/130831 [01:20<01:01, 819.17graphs/s]Creating k-hop graphs:  62%|██████▏   | 80900/130831 [01:20<01:00, 819.25graphs/s]Creating k-hop graphs:  62%|██████▏   | 81015/130831 [01:20<00:54, 905.95graphs/s]Creating k-hop graphs:  62%|██████▏   | 81111/130831 [01:20<00:54, 904.77graphs/s]Creating k-hop graphs:  62%|██████▏   | 81209/130831 [01:20<00:53, 923.65graphs/s]Creating k-hop graphs:  62%|██████▏   | 81304/130831 [01:21<00:54, 907.28graphs/s]Creating k-hop graphs:  62%|██████▏   | 81410/130831 [01:21<00:51, 950.50graphs/s]Creating k-hop graphs:  62%|██████▏   | 81511/130831 [01:21<00:51, 965.52graphs/s]Creating k-hop graphs:  62%|██████▏   | 81609/130831 [01:21<00:52, 930.65graphs/s]Creating k-hop graphs:  62%|██████▏   | 81703/130831 [01:21<00:52, 928.91graphs/s]Creating k-hop graphs:  63%|██████▎   | 81797/130831 [01:21<00:53, 916.21graphs/s]Creating k-hop graphs:  63%|██████▎   | 81894/130831 [01:21<00:52, 930.58graphs/s]Creating k-hop graphs:  63%|██████▎   | 81989/130831 [01:21<00:52, 934.46graphs/s]Creating k-hop graphs:  63%|██████▎   | 82083/130831 [01:21<00:53, 905.32graphs/s]Creating k-hop graphs:  63%|██████▎   | 82174/130831 [01:21<00:54, 888.68graphs/s]Creating k-hop graphs:  63%|██████▎   | 82268/130831 [01:22<00:53, 900.88graphs/s]Creating k-hop graphs:  63%|██████▎   | 82359/130831 [01:22<00:56, 850.85graphs/s]Creating k-hop graphs:  63%|██████▎   | 82445/130831 [01:22<00:58, 827.00graphs/s]Creating k-hop graphs:  63%|██████▎   | 82561/130831 [01:22<00:52, 918.69graphs/s]Creating k-hop graphs:  63%|██████▎   | 82660/130831 [01:22<00:51, 938.18graphs/s]Creating k-hop graphs:  63%|██████▎   | 82758/130831 [01:22<00:50, 948.42graphs/s]Creating k-hop graphs:  63%|██████▎   | 82855/130831 [01:22<00:50, 953.55graphs/s]Creating k-hop graphs:  63%|██████▎   | 82962/130831 [01:22<00:48, 987.04graphs/s]Creating k-hop graphs:  63%|██████▎   | 83063/130831 [01:22<00:48, 992.12graphs/s]Creating k-hop graphs:  64%|██████▎   | 83163/130831 [01:23<00:51, 918.39graphs/s]Creating k-hop graphs:  64%|██████▎   | 83257/130831 [01:23<00:51, 921.15graphs/s]Creating k-hop graphs:  64%|██████▎   | 83350/130831 [01:23<00:52, 898.63graphs/s]Creating k-hop graphs:  64%|██████▍   | 83449/130831 [01:23<00:51, 924.25graphs/s]Creating k-hop graphs:  64%|██████▍   | 83547/130831 [01:23<00:50, 939.57graphs/s]Creating k-hop graphs:  64%|██████▍   | 83650/130831 [01:23<00:48, 964.89graphs/s]Creating k-hop graphs:  64%|██████▍   | 83752/130831 [01:23<00:48, 979.59graphs/s]Creating k-hop graphs:  64%|██████▍   | 83859/130831 [01:23<00:46, 1005.10graphs/s]Creating k-hop graphs:  64%|██████▍   | 83964/130831 [01:23<00:46, 1016.46graphs/s]Creating k-hop graphs:  64%|██████▍   | 84066/130831 [01:23<00:46, 1013.16graphs/s]Creating k-hop graphs:  64%|██████▍   | 84168/130831 [01:24<00:51, 908.47graphs/s] Creating k-hop graphs:  64%|██████▍   | 84261/130831 [01:24<00:54, 853.32graphs/s]Creating k-hop graphs:  64%|██████▍   | 84349/130831 [01:24<00:56, 821.34graphs/s]Creating k-hop graphs:  65%|██████▍   | 84436/130831 [01:24<00:55, 832.46graphs/s]Creating k-hop graphs:  65%|██████▍   | 84521/130831 [01:24<00:59, 780.97graphs/s]Creating k-hop graphs:  65%|██████▍   | 84601/130831 [01:24<01:00, 761.08graphs/s]Creating k-hop graphs:  65%|██████▍   | 84678/130831 [01:24<01:02, 733.84graphs/s]Creating k-hop graphs:  65%|██████▍   | 84756/130831 [01:24<01:01, 744.62graphs/s]Creating k-hop graphs:  65%|██████▍   | 84831/130831 [01:25<01:03, 719.75graphs/s]Creating k-hop graphs:  65%|██████▍   | 84907/130831 [01:25<01:02, 730.64graphs/s]Creating k-hop graphs:  65%|██████▍   | 85002/130831 [01:25<00:57, 792.31graphs/s]Creating k-hop graphs:  65%|██████▌   | 85085/130831 [01:25<00:57, 801.99graphs/s]Creating k-hop graphs:  65%|██████▌   | 85172/130831 [01:25<00:55, 821.73graphs/s]Creating k-hop graphs:  65%|██████▌   | 85255/130831 [01:25<00:57, 795.40graphs/s]Creating k-hop graphs:  65%|██████▌   | 85351/130831 [01:25<00:54, 834.32graphs/s]Creating k-hop graphs:  65%|██████▌   | 85435/130831 [01:25<01:00, 750.39graphs/s]Creating k-hop graphs:  65%|██████▌   | 85512/130831 [01:25<01:02, 727.92graphs/s]Creating k-hop graphs:  65%|██████▌   | 85614/130831 [01:25<00:56, 807.03graphs/s]Creating k-hop graphs:  66%|██████▌   | 85697/130831 [01:26<00:55, 806.97graphs/s]Creating k-hop graphs:  66%|██████▌   | 85786/130831 [01:26<00:54, 826.45graphs/s]Creating k-hop graphs:  66%|██████▌   | 85876/130831 [01:26<00:53, 846.92graphs/s]Creating k-hop graphs:  66%|██████▌   | 85962/130831 [01:26<00:54, 830.85graphs/s]Creating k-hop graphs:  66%|██████▌   | 86046/130831 [01:26<00:54, 821.69graphs/s]Creating k-hop graphs:  66%|██████▌   | 86129/130831 [01:26<00:54, 820.16graphs/s]Creating k-hop graphs:  66%|██████▌   | 86212/130831 [01:26<00:54, 817.35graphs/s]Creating k-hop graphs:  66%|██████▌   | 86294/130831 [01:26<00:54, 811.13graphs/s]Creating k-hop graphs:  66%|██████▌   | 86377/130831 [01:26<00:54, 815.89graphs/s]Creating k-hop graphs:  66%|██████▌   | 86459/130831 [01:27<00:57, 769.77graphs/s]Creating k-hop graphs:  66%|██████▌   | 86537/130831 [01:27<00:57, 766.56graphs/s]Creating k-hop graphs:  66%|██████▌   | 86616/130831 [01:27<00:57, 772.43graphs/s]Creating k-hop graphs:  66%|██████▋   | 86694/130831 [01:27<00:59, 737.99graphs/s]Creating k-hop graphs:  66%|██████▋   | 86773/130831 [01:27<00:58, 749.64graphs/s]Creating k-hop graphs:  66%|██████▋   | 86849/130831 [01:27<01:03, 692.46graphs/s]Creating k-hop graphs:  66%|██████▋   | 86920/130831 [01:27<01:06, 662.28graphs/s]Creating k-hop graphs:  66%|██████▋   | 86993/130831 [01:27<01:04, 679.81graphs/s]Creating k-hop graphs:  67%|██████▋   | 87062/130831 [01:27<01:05, 668.78graphs/s]Creating k-hop graphs:  67%|██████▋   | 87139/130831 [01:28<01:02, 695.75graphs/s]Creating k-hop graphs:  67%|██████▋   | 87210/130831 [01:28<01:09, 631.69graphs/s]Creating k-hop graphs:  67%|██████▋   | 87275/130831 [01:28<01:11, 608.14graphs/s]Creating k-hop graphs:  67%|██████▋   | 87337/130831 [01:28<01:11, 604.14graphs/s]Creating k-hop graphs:  67%|██████▋   | 87422/130831 [01:28<01:04, 671.51graphs/s]Creating k-hop graphs:  67%|██████▋   | 87507/130831 [01:28<01:00, 718.76graphs/s]Creating k-hop graphs:  67%|██████▋   | 87597/130831 [01:28<00:56, 770.54graphs/s]Creating k-hop graphs:  67%|██████▋   | 87676/130831 [01:28<00:55, 774.48graphs/s]Creating k-hop graphs:  67%|██████▋   | 87755/130831 [01:28<00:56, 760.25graphs/s]Creating k-hop graphs:  67%|██████▋   | 87836/130831 [01:28<00:55, 772.25graphs/s]Creating k-hop graphs:  67%|██████▋   | 87929/130831 [01:29<00:52, 815.55graphs/s]Creating k-hop graphs:  67%|██████▋   | 88017/130831 [01:29<00:51, 834.47graphs/s]Creating k-hop graphs:  67%|██████▋   | 88101/130831 [01:29<00:52, 819.89graphs/s]Creating k-hop graphs:  67%|██████▋   | 88189/130831 [01:29<00:51, 834.68graphs/s]Creating k-hop graphs:  67%|██████▋   | 88273/130831 [01:29<00:52, 815.78graphs/s]Creating k-hop graphs:  68%|██████▊   | 88359/130831 [01:29<00:51, 825.43graphs/s]Creating k-hop graphs:  68%|██████▊   | 88456/130831 [01:29<00:48, 865.08graphs/s]Creating k-hop graphs:  68%|██████▊   | 88543/130831 [01:29<00:49, 852.65graphs/s]Creating k-hop graphs:  68%|██████▊   | 88631/130831 [01:29<00:49, 857.87graphs/s]Creating k-hop graphs:  68%|██████▊   | 88717/130831 [01:30<00:51, 811.54graphs/s]Creating k-hop graphs:  68%|██████▊   | 88807/130831 [01:30<00:50, 836.47graphs/s]Creating k-hop graphs:  68%|██████▊   | 88896/130831 [01:30<00:49, 850.52graphs/s]Creating k-hop graphs:  68%|██████▊   | 88982/130831 [01:30<00:50, 833.51graphs/s]Creating k-hop graphs:  68%|██████▊   | 89085/130831 [01:30<00:46, 889.49graphs/s]Creating k-hop graphs:  68%|██████▊   | 89180/130831 [01:30<00:45, 906.72graphs/s]Creating k-hop graphs:  68%|██████▊   | 89272/130831 [01:30<00:46, 888.91graphs/s]Creating k-hop graphs:  68%|██████▊   | 89362/130831 [01:30<00:46, 890.20graphs/s]Creating k-hop graphs:  68%|██████▊   | 89458/130831 [01:30<00:45, 909.33graphs/s]Creating k-hop graphs:  68%|██████▊   | 89550/130831 [01:30<00:47, 876.53graphs/s]Creating k-hop graphs:  69%|██████▊   | 89639/130831 [01:31<00:48, 853.22graphs/s]Creating k-hop graphs:  69%|██████▊   | 89731/130831 [01:31<00:47, 869.15graphs/s]Creating k-hop graphs:  69%|██████▊   | 89819/130831 [01:31<00:47, 868.03graphs/s]Creating k-hop graphs:  69%|██████▊   | 89911/130831 [01:31<00:46, 880.89graphs/s]Creating k-hop graphs:  69%|██████▉   | 90000/130831 [01:31<00:47, 862.48graphs/s]Creating k-hop graphs:  69%|██████▉   | 90091/130831 [01:31<00:46, 875.58graphs/s]Creating k-hop graphs:  69%|██████▉   | 90179/130831 [01:31<00:47, 860.81graphs/s]Creating k-hop graphs:  69%|██████▉   | 90277/130831 [01:31<00:45, 892.73graphs/s]Creating k-hop graphs:  69%|██████▉   | 90367/130831 [01:31<00:45, 884.02graphs/s]Creating k-hop graphs:  69%|██████▉   | 90456/130831 [01:32<00:46, 872.62graphs/s]Creating k-hop graphs:  69%|██████▉   | 90544/130831 [01:32<00:47, 848.13graphs/s]Creating k-hop graphs:  69%|██████▉   | 90638/130831 [01:32<00:46, 873.71graphs/s]Creating k-hop graphs:  69%|██████▉   | 90726/130831 [01:32<00:47, 847.58graphs/s]Creating k-hop graphs:  69%|██████▉   | 90812/130831 [01:32<00:49, 813.52graphs/s]Creating k-hop graphs:  69%|██████▉   | 90894/130831 [01:32<00:50, 796.46graphs/s]Creating k-hop graphs:  70%|██████▉   | 90974/130831 [01:32<00:50, 791.10graphs/s]Creating k-hop graphs:  70%|██████▉   | 91067/130831 [01:32<00:47, 829.93graphs/s]Creating k-hop graphs:  70%|██████▉   | 91155/130831 [01:32<00:47, 842.15graphs/s]Creating k-hop graphs:  70%|██████▉   | 91241/130831 [01:32<00:46, 844.08graphs/s]Creating k-hop graphs:  70%|██████▉   | 91326/130831 [01:33<01:19, 499.35graphs/s]Creating k-hop graphs:  70%|██████▉   | 91418/130831 [01:33<01:07, 581.19graphs/s]Creating k-hop graphs:  70%|██████▉   | 91513/130831 [01:33<00:59, 662.27graphs/s]Creating k-hop graphs:  70%|███████   | 91617/130831 [01:33<00:52, 752.24graphs/s]Creating k-hop graphs:  70%|███████   | 91713/130831 [01:33<00:48, 805.04graphs/s]Creating k-hop graphs:  70%|███████   | 91803/130831 [01:33<00:47, 826.73graphs/s]Creating k-hop graphs:  70%|███████   | 91893/130831 [01:33<00:49, 785.81graphs/s]Creating k-hop graphs:  70%|███████   | 91977/130831 [01:34<00:50, 772.61graphs/s]Creating k-hop graphs:  70%|███████   | 92058/130831 [01:34<00:52, 733.79graphs/s]Creating k-hop graphs:  70%|███████   | 92135/130831 [01:34<00:53, 725.09graphs/s]Creating k-hop graphs:  70%|███████   | 92224/130831 [01:34<00:50, 769.11graphs/s]Creating k-hop graphs:  71%|███████   | 92310/130831 [01:34<00:48, 792.58graphs/s]Creating k-hop graphs:  71%|███████   | 92392/130831 [01:34<00:48, 798.54graphs/s]Creating k-hop graphs:  71%|███████   | 92480/130831 [01:34<00:46, 820.36graphs/s]Creating k-hop graphs:  71%|███████   | 92563/130831 [01:34<00:46, 818.82graphs/s]Creating k-hop graphs:  71%|███████   | 92646/130831 [01:34<00:46, 820.32graphs/s]Creating k-hop graphs:  71%|███████   | 92729/130831 [01:34<00:47, 809.13graphs/s]Creating k-hop graphs:  71%|███████   | 92811/130831 [01:35<00:50, 750.60graphs/s]Creating k-hop graphs:  71%|███████   | 92888/130831 [01:35<00:53, 708.99graphs/s]Creating k-hop graphs:  71%|███████   | 92970/130831 [01:35<00:51, 737.69graphs/s]Creating k-hop graphs:  71%|███████   | 93048/130831 [01:35<00:50, 749.39graphs/s]Creating k-hop graphs:  71%|███████   | 93136/130831 [01:35<00:48, 783.08graphs/s]Creating k-hop graphs:  71%|███████▏  | 93229/130831 [01:35<00:45, 822.64graphs/s]Creating k-hop graphs:  71%|███████▏  | 93325/130831 [01:35<00:43, 859.56graphs/s]Creating k-hop graphs:  71%|███████▏  | 93412/130831 [01:35<00:45, 819.42graphs/s]Creating k-hop graphs:  71%|███████▏  | 93495/130831 [01:35<00:45, 811.74graphs/s]Creating k-hop graphs:  72%|███████▏  | 93577/130831 [01:36<00:47, 786.83graphs/s]Creating k-hop graphs:  72%|███████▏  | 93659/130831 [01:36<00:46, 794.12graphs/s]Creating k-hop graphs:  72%|███████▏  | 93739/130831 [01:36<00:46, 794.13graphs/s]Creating k-hop graphs:  72%|███████▏  | 93826/130831 [01:36<00:45, 813.96graphs/s]Creating k-hop graphs:  72%|███████▏  | 93915/130831 [01:36<00:44, 830.82graphs/s]Creating k-hop graphs:  72%|███████▏  | 93999/130831 [01:36<00:48, 753.53graphs/s]Creating k-hop graphs:  72%|███████▏  | 94089/130831 [01:36<00:46, 792.97graphs/s]Creating k-hop graphs:  72%|███████▏  | 94170/130831 [01:36<00:46, 782.98graphs/s]Creating k-hop graphs:  72%|███████▏  | 94250/130831 [01:36<00:46, 778.89graphs/s]Creating k-hop graphs:  72%|███████▏  | 94329/130831 [01:37<00:47, 770.90graphs/s]Creating k-hop graphs:  72%|███████▏  | 94407/130831 [01:37<00:48, 745.07graphs/s]Creating k-hop graphs:  72%|███████▏  | 94482/130831 [01:37<00:49, 741.79graphs/s]Creating k-hop graphs:  72%|███████▏  | 94557/130831 [01:37<00:50, 718.36graphs/s]Creating k-hop graphs:  72%|███████▏  | 94633/130831 [01:37<00:49, 728.07graphs/s]Creating k-hop graphs:  72%|███████▏  | 94707/130831 [01:37<00:50, 715.42graphs/s]Creating k-hop graphs:  72%|███████▏  | 94779/130831 [01:37<00:51, 699.24graphs/s]Creating k-hop graphs:  72%|███████▏  | 94850/130831 [01:37<00:52, 687.46graphs/s]Creating k-hop graphs:  73%|███████▎  | 94936/130831 [01:37<00:48, 734.48graphs/s]Creating k-hop graphs:  73%|███████▎  | 95015/130831 [01:37<00:47, 747.28graphs/s]Creating k-hop graphs:  73%|███████▎  | 95092/130831 [01:38<00:47, 752.92graphs/s]Creating k-hop graphs:  73%|███████▎  | 95177/130831 [01:38<00:45, 780.62graphs/s]Creating k-hop graphs:  73%|███████▎  | 95260/130831 [01:38<00:45, 790.09graphs/s]Creating k-hop graphs:  73%|███████▎  | 95340/130831 [01:38<00:45, 783.69graphs/s]Creating k-hop graphs:  73%|███████▎  | 95419/130831 [01:38<00:45, 785.35graphs/s]Creating k-hop graphs:  73%|███████▎  | 95498/130831 [01:38<00:45, 774.82graphs/s]Creating k-hop graphs:  73%|███████▎  | 95576/130831 [01:38<00:47, 739.16graphs/s]Creating k-hop graphs:  73%|███████▎  | 95651/130831 [01:38<00:47, 739.99graphs/s]Creating k-hop graphs:  73%|███████▎  | 95726/130831 [01:38<00:51, 684.25graphs/s]Creating k-hop graphs:  73%|███████▎  | 95796/130831 [01:39<00:54, 644.85graphs/s]Creating k-hop graphs:  73%|███████▎  | 95866/130831 [01:39<00:53, 658.87graphs/s]Creating k-hop graphs:  73%|███████▎  | 95933/130831 [01:39<00:53, 649.88graphs/s]Creating k-hop graphs:  73%|███████▎  | 96002/130831 [01:39<00:52, 660.43graphs/s]Creating k-hop graphs:  73%|███████▎  | 96069/130831 [01:39<00:55, 621.12graphs/s]Creating k-hop graphs:  73%|███████▎  | 96132/130831 [01:39<00:55, 619.93graphs/s]Creating k-hop graphs:  74%|███████▎  | 96218/130831 [01:39<00:50, 686.96graphs/s]Creating k-hop graphs:  74%|███████▎  | 96300/130831 [01:39<00:47, 724.79graphs/s]Creating k-hop graphs:  74%|███████▎  | 96374/130831 [01:39<00:49, 696.74graphs/s]Creating k-hop graphs:  74%|███████▎  | 96445/130831 [01:40<00:49, 688.52graphs/s]Creating k-hop graphs:  74%|███████▍  | 96528/130831 [01:40<00:47, 727.20graphs/s]Creating k-hop graphs:  74%|███████▍  | 96602/130831 [01:40<00:47, 724.78graphs/s]Creating k-hop graphs:  74%|███████▍  | 96688/130831 [01:40<00:44, 763.35graphs/s]Creating k-hop graphs:  74%|███████▍  | 96765/130831 [01:40<00:45, 756.58graphs/s]Creating k-hop graphs:  74%|███████▍  | 96848/130831 [01:40<00:43, 776.79graphs/s]Creating k-hop graphs:  74%|███████▍  | 96928/130831 [01:40<00:43, 779.86graphs/s]Creating k-hop graphs:  74%|███████▍  | 97007/130831 [01:40<00:44, 751.69graphs/s]Creating k-hop graphs:  74%|███████▍  | 97090/130831 [01:40<00:43, 771.47graphs/s]Creating k-hop graphs:  74%|███████▍  | 97168/130831 [01:40<00:45, 736.37graphs/s]Creating k-hop graphs:  74%|███████▍  | 97243/130831 [01:41<00:47, 712.73graphs/s]Creating k-hop graphs:  74%|███████▍  | 97315/130831 [01:41<00:47, 702.64graphs/s]Creating k-hop graphs:  74%|███████▍  | 97386/130831 [01:41<00:50, 666.73graphs/s]Creating k-hop graphs:  74%|███████▍  | 97456/130831 [01:41<00:49, 674.60graphs/s]Creating k-hop graphs:  75%|███████▍  | 97547/130831 [01:41<00:44, 740.56graphs/s]Creating k-hop graphs:  75%|███████▍  | 97623/130831 [01:41<00:44, 744.73graphs/s]Creating k-hop graphs:  75%|███████▍  | 97709/130831 [01:41<00:42, 777.49graphs/s]Creating k-hop graphs:  75%|███████▍  | 97788/130831 [01:41<00:46, 706.33graphs/s]Creating k-hop graphs:  75%|███████▍  | 97861/130831 [01:42<00:51, 634.47graphs/s]Creating k-hop graphs:  75%|███████▍  | 97936/130831 [01:42<00:49, 664.23graphs/s]Creating k-hop graphs:  75%|███████▍  | 98011/130831 [01:42<00:47, 685.65graphs/s]Creating k-hop graphs:  75%|███████▍  | 98082/130831 [01:42<00:50, 642.15graphs/s]Creating k-hop graphs:  75%|███████▌  | 98148/130831 [01:42<00:55, 586.04graphs/s]Creating k-hop graphs:  75%|███████▌  | 98209/130831 [01:42<00:58, 559.86graphs/s]Creating k-hop graphs:  75%|███████▌  | 98279/130831 [01:42<00:54, 594.83graphs/s]Creating k-hop graphs:  75%|███████▌  | 98347/130831 [01:42<00:52, 615.91graphs/s]Creating k-hop graphs:  75%|███████▌  | 98412/130831 [01:42<00:51, 624.05graphs/s]Creating k-hop graphs:  75%|███████▌  | 98476/130831 [01:42<00:51, 627.01graphs/s]Creating k-hop graphs:  75%|███████▌  | 98540/130831 [01:43<00:52, 609.35graphs/s]Creating k-hop graphs:  75%|███████▌  | 98602/130831 [01:43<00:53, 607.06graphs/s]Creating k-hop graphs:  75%|███████▌  | 98681/130831 [01:43<00:48, 657.22graphs/s]Creating k-hop graphs:  75%|███████▌  | 98748/130831 [01:43<00:53, 601.89graphs/s]Creating k-hop graphs:  76%|███████▌  | 98810/130831 [01:43<00:57, 558.18graphs/s]Creating k-hop graphs:  76%|███████▌  | 98870/130831 [01:43<00:56, 568.77graphs/s]Creating k-hop graphs:  76%|███████▌  | 98929/130831 [01:43<00:55, 573.81graphs/s]Creating k-hop graphs:  76%|███████▌  | 98988/130831 [01:43<01:00, 529.81graphs/s]Creating k-hop graphs:  76%|███████▌  | 99043/130831 [01:44<01:01, 520.16graphs/s]Creating k-hop graphs:  76%|███████▌  | 99112/130831 [01:44<00:56, 565.79graphs/s]Creating k-hop graphs:  76%|███████▌  | 99170/130831 [01:44<00:56, 561.03graphs/s]Creating k-hop graphs:  76%|███████▌  | 99227/130831 [01:44<00:56, 555.25graphs/s]Creating k-hop graphs:  76%|███████▌  | 99283/130831 [01:44<00:58, 542.16graphs/s]Creating k-hop graphs:  76%|███████▌  | 99343/130831 [01:44<00:56, 555.46graphs/s]Creating k-hop graphs:  76%|███████▌  | 99400/130831 [01:44<00:56, 559.13graphs/s]Creating k-hop graphs:  76%|███████▌  | 99457/130831 [01:44<00:56, 553.04graphs/s]Creating k-hop graphs:  76%|███████▌  | 99520/130831 [01:44<00:54, 574.00graphs/s]Creating k-hop graphs:  76%|███████▌  | 99584/130831 [01:44<00:52, 592.31graphs/s]Creating k-hop graphs:  76%|███████▌  | 99644/130831 [01:45<00:56, 552.51graphs/s]Creating k-hop graphs:  76%|███████▌  | 99700/130831 [01:45<01:00, 510.75graphs/s]Creating k-hop graphs:  76%|███████▌  | 99752/130831 [01:45<01:04, 483.46graphs/s]Creating k-hop graphs:  76%|███████▋  | 99806/130831 [01:45<01:02, 496.45graphs/s]Creating k-hop graphs:  76%|███████▋  | 99857/130831 [01:45<01:07, 461.56graphs/s]Creating k-hop graphs:  76%|███████▋  | 99916/130831 [01:45<01:02, 494.57graphs/s]Creating k-hop graphs:  76%|███████▋  | 100001/130831 [01:45<00:52, 591.17graphs/s]Creating k-hop graphs:  76%|███████▋  | 100074/130831 [01:45<00:48, 629.27graphs/s]Creating k-hop graphs:  77%|███████▋  | 100139/130831 [01:45<00:48, 635.14graphs/s]Creating k-hop graphs:  77%|███████▋  | 100204/130831 [01:46<00:48, 635.01graphs/s]Creating k-hop graphs:  77%|███████▋  | 100275/130831 [01:46<00:46, 655.89graphs/s]Creating k-hop graphs:  77%|███████▋  | 100343/130831 [01:46<00:46, 661.66graphs/s]Creating k-hop graphs:  77%|███████▋  | 100410/130831 [01:46<00:46, 659.08graphs/s]Creating k-hop graphs:  77%|███████▋  | 100477/130831 [01:46<00:47, 638.68graphs/s]Creating k-hop graphs:  77%|███████▋  | 100542/130831 [01:46<00:49, 612.74graphs/s]Creating k-hop graphs:  77%|███████▋  | 100604/130831 [01:46<00:53, 560.18graphs/s]Creating k-hop graphs:  77%|███████▋  | 100661/130831 [01:46<00:57, 525.60graphs/s]Creating k-hop graphs:  77%|███████▋  | 100721/130831 [01:46<00:55, 542.86graphs/s]Creating k-hop graphs:  77%|███████▋  | 100783/130831 [01:47<00:53, 562.25graphs/s]Creating k-hop graphs:  77%|███████▋  | 100856/130831 [01:47<00:49, 607.49graphs/s]Creating k-hop graphs:  77%|███████▋  | 100933/130831 [01:47<00:45, 651.56graphs/s]Creating k-hop graphs:  77%|███████▋  | 101019/130831 [01:47<00:41, 711.55graphs/s]Creating k-hop graphs:  77%|███████▋  | 101091/130831 [01:47<00:41, 710.89graphs/s]Creating k-hop graphs:  77%|███████▋  | 101163/130831 [01:47<00:42, 705.42graphs/s]Creating k-hop graphs:  77%|███████▋  | 101234/130831 [01:47<00:41, 705.70graphs/s]Creating k-hop graphs:  77%|███████▋  | 101306/130831 [01:47<00:41, 709.35graphs/s]Creating k-hop graphs:  77%|███████▋  | 101383/130831 [01:47<00:40, 724.46graphs/s]Creating k-hop graphs:  78%|███████▊  | 101456/130831 [01:47<00:41, 710.45graphs/s]Creating k-hop graphs:  78%|███████▊  | 101535/130831 [01:48<00:40, 731.35graphs/s]Creating k-hop graphs:  78%|███████▊  | 101609/130831 [01:48<00:42, 689.76graphs/s]Creating k-hop graphs:  78%|███████▊  | 101687/130831 [01:48<00:40, 714.46graphs/s]Creating k-hop graphs:  78%|███████▊  | 101759/130831 [01:48<00:41, 693.69graphs/s]Creating k-hop graphs:  78%|███████▊  | 101829/130831 [01:48<00:43, 665.74graphs/s]Creating k-hop graphs:  78%|███████▊  | 101897/130831 [01:48<00:43, 666.73graphs/s]Creating k-hop graphs:  78%|███████▊  | 101964/130831 [01:48<00:44, 650.36graphs/s]Creating k-hop graphs:  78%|███████▊  | 102030/130831 [01:48<00:44, 649.32graphs/s]Creating k-hop graphs:  78%|███████▊  | 102112/130831 [01:48<00:41, 696.09graphs/s]Creating k-hop graphs:  78%|███████▊  | 102182/130831 [01:49<00:44, 643.84graphs/s]Creating k-hop graphs:  78%|███████▊  | 102259/130831 [01:49<00:42, 676.68graphs/s]Creating k-hop graphs:  78%|███████▊  | 102329/130831 [01:49<00:41, 681.99graphs/s]Creating k-hop graphs:  78%|███████▊  | 102398/130831 [01:49<00:42, 668.72graphs/s]Creating k-hop graphs:  78%|███████▊  | 102466/130831 [01:49<00:42, 669.46graphs/s]Creating k-hop graphs:  78%|███████▊  | 102547/130831 [01:49<00:39, 708.65graphs/s]Creating k-hop graphs:  78%|███████▊  | 102619/130831 [01:49<00:42, 664.56graphs/s]Creating k-hop graphs:  78%|███████▊  | 102687/130831 [01:49<00:43, 644.32graphs/s]Creating k-hop graphs:  79%|███████▊  | 102757/130831 [01:49<00:42, 659.50graphs/s]Creating k-hop graphs:  79%|███████▊  | 102827/130831 [01:50<00:41, 669.69graphs/s]Creating k-hop graphs:  79%|███████▊  | 102895/130831 [01:50<00:41, 672.23graphs/s]Creating k-hop graphs:  79%|███████▊  | 102983/130831 [01:50<00:38, 731.69graphs/s]Creating k-hop graphs:  79%|███████▉  | 103057/130831 [01:50<00:39, 709.13graphs/s]Creating k-hop graphs:  79%|███████▉  | 103140/130831 [01:50<00:37, 743.25graphs/s]Creating k-hop graphs:  79%|███████▉  | 103215/130831 [01:50<00:39, 695.74graphs/s]Creating k-hop graphs:  79%|███████▉  | 103308/130831 [01:50<00:36, 760.02graphs/s]Creating k-hop graphs:  79%|███████▉  | 103386/130831 [01:50<00:37, 740.19graphs/s]Creating k-hop graphs:  79%|███████▉  | 103461/130831 [01:50<00:37, 724.32graphs/s]Creating k-hop graphs:  79%|███████▉  | 103552/130831 [01:50<00:35, 774.01graphs/s]Creating k-hop graphs:  79%|███████▉  | 103631/130831 [01:51<00:35, 763.56graphs/s]Creating k-hop graphs:  79%|███████▉  | 103721/130831 [01:51<00:33, 800.28graphs/s]Creating k-hop graphs:  79%|███████▉  | 103803/130831 [01:51<00:33, 805.27graphs/s]Creating k-hop graphs:  79%|███████▉  | 103884/130831 [01:51<00:34, 776.37graphs/s]Creating k-hop graphs:  79%|███████▉  | 103977/130831 [01:51<00:32, 819.80graphs/s]Creating k-hop graphs:  80%|███████▉  | 104061/130831 [01:51<00:32, 823.60graphs/s]Creating k-hop graphs:  80%|███████▉  | 104149/130831 [01:51<00:31, 838.49graphs/s]Creating k-hop graphs:  80%|███████▉  | 104234/130831 [01:51<00:31, 838.46graphs/s]Creating k-hop graphs:  80%|███████▉  | 104319/130831 [01:51<00:33, 801.41graphs/s]Creating k-hop graphs:  80%|███████▉  | 104402/130831 [01:52<00:32, 809.46graphs/s]Creating k-hop graphs:  80%|███████▉  | 104484/130831 [01:52<00:32, 812.13graphs/s]Creating k-hop graphs:  80%|███████▉  | 104566/130831 [01:52<00:34, 763.56graphs/s]Creating k-hop graphs:  80%|███████▉  | 104644/130831 [01:52<00:35, 730.19graphs/s]Creating k-hop graphs:  80%|████████  | 104718/130831 [01:52<00:35, 732.67graphs/s]Creating k-hop graphs:  80%|████████  | 104792/130831 [01:52<00:35, 731.75graphs/s]Creating k-hop graphs:  80%|████████  | 104888/130831 [01:52<00:32, 796.83graphs/s]Creating k-hop graphs:  80%|████████  | 104969/130831 [01:52<00:33, 782.09graphs/s]Creating k-hop graphs:  80%|████████  | 105048/130831 [01:52<00:33, 761.19graphs/s]Creating k-hop graphs:  80%|████████  | 105125/130831 [01:52<00:34, 755.24graphs/s]Creating k-hop graphs:  80%|████████  | 105206/130831 [01:53<00:33, 768.38graphs/s]Creating k-hop graphs:  80%|████████  | 105290/130831 [01:53<00:32, 785.52graphs/s]Creating k-hop graphs:  81%|████████  | 105369/130831 [01:53<00:32, 780.94graphs/s]Creating k-hop graphs:  81%|████████  | 105448/130831 [01:53<00:33, 764.32graphs/s]Creating k-hop graphs:  81%|████████  | 105531/130831 [01:53<00:32, 781.42graphs/s]Creating k-hop graphs:  81%|████████  | 105610/130831 [01:53<00:32, 767.95graphs/s]Creating k-hop graphs:  81%|████████  | 105689/130831 [01:53<00:32, 772.59graphs/s]Creating k-hop graphs:  81%|████████  | 105773/130831 [01:53<00:31, 791.99graphs/s]Creating k-hop graphs:  81%|████████  | 105856/130831 [01:53<00:31, 799.02graphs/s]Creating k-hop graphs:  81%|████████  | 105936/130831 [01:54<00:31, 790.07graphs/s]Creating k-hop graphs:  81%|████████  | 106025/130831 [01:54<00:30, 818.77graphs/s]Creating k-hop graphs:  81%|████████  | 106116/130831 [01:54<00:29, 845.55graphs/s]Creating k-hop graphs:  81%|████████  | 106201/130831 [01:54<00:30, 814.24graphs/s]Creating k-hop graphs:  81%|████████  | 106283/130831 [01:54<00:30, 799.04graphs/s]Creating k-hop graphs:  81%|████████▏ | 106365/130831 [01:54<00:30, 803.34graphs/s]Creating k-hop graphs:  81%|████████▏ | 106446/130831 [01:54<00:30, 791.65graphs/s]Creating k-hop graphs:  81%|████████▏ | 106526/130831 [01:54<00:31, 762.75graphs/s]Creating k-hop graphs:  81%|████████▏ | 106603/130831 [01:54<00:32, 737.73graphs/s]Creating k-hop graphs:  82%|████████▏ | 106682/130831 [01:54<00:32, 751.88graphs/s]Creating k-hop graphs:  82%|████████▏ | 106758/130831 [01:55<00:31, 753.56graphs/s]Creating k-hop graphs:  82%|████████▏ | 106834/130831 [01:55<00:32, 733.25graphs/s]Creating k-hop graphs:  82%|████████▏ | 106908/130831 [01:55<00:32, 732.52graphs/s]Creating k-hop graphs:  82%|████████▏ | 106985/130831 [01:55<00:32, 740.87graphs/s]Creating k-hop graphs:  82%|████████▏ | 107060/130831 [01:55<00:32, 741.08graphs/s]Creating k-hop graphs:  82%|████████▏ | 107135/130831 [01:55<00:32, 728.51graphs/s]Creating k-hop graphs:  82%|████████▏ | 107208/130831 [01:55<00:32, 727.49graphs/s]Creating k-hop graphs:  82%|████████▏ | 107281/130831 [01:55<00:32, 718.53graphs/s]Creating k-hop graphs:  82%|████████▏ | 107353/130831 [01:55<00:32, 717.47graphs/s]Creating k-hop graphs:  82%|████████▏ | 107442/130831 [01:56<00:30, 766.76graphs/s]Creating k-hop graphs:  82%|████████▏ | 107519/130831 [01:56<00:31, 735.10graphs/s]Creating k-hop graphs:  82%|████████▏ | 107593/130831 [01:56<00:31, 731.01graphs/s]Creating k-hop graphs:  82%|████████▏ | 107667/130831 [01:56<00:34, 665.25graphs/s]Creating k-hop graphs:  82%|████████▏ | 107735/130831 [01:56<00:36, 624.50graphs/s]Creating k-hop graphs:  82%|████████▏ | 107799/130831 [01:56<00:36, 623.80graphs/s]Creating k-hop graphs:  82%|████████▏ | 107863/130831 [01:56<00:37, 617.99graphs/s]Creating k-hop graphs:  82%|████████▏ | 107928/130831 [01:56<00:36, 626.66graphs/s]Creating k-hop graphs:  83%|████████▎ | 107994/130831 [01:56<00:35, 635.08graphs/s]Creating k-hop graphs:  83%|████████▎ | 108064/130831 [01:56<00:34, 651.60graphs/s]Creating k-hop graphs:  83%|████████▎ | 108152/130831 [01:57<00:31, 717.46graphs/s]Creating k-hop graphs:  83%|████████▎ | 108226/130831 [01:57<00:31, 722.71graphs/s]Creating k-hop graphs:  83%|████████▎ | 108299/130831 [01:57<00:31, 711.91graphs/s]Creating k-hop graphs:  83%|████████▎ | 108379/130831 [01:57<00:30, 736.20graphs/s]Creating k-hop graphs:  83%|████████▎ | 108458/130831 [01:57<00:29, 751.28graphs/s]Creating k-hop graphs:  83%|████████▎ | 108534/130831 [01:57<00:30, 735.54graphs/s]Creating k-hop graphs:  83%|████████▎ | 108615/130831 [01:57<00:29, 755.92graphs/s]Creating k-hop graphs:  83%|████████▎ | 108705/130831 [01:57<00:27, 797.68graphs/s]Creating k-hop graphs:  83%|████████▎ | 108785/130831 [01:57<00:28, 774.10graphs/s]Creating k-hop graphs:  83%|████████▎ | 108863/130831 [01:58<00:30, 725.66graphs/s]Creating k-hop graphs:  83%|████████▎ | 108937/130831 [01:58<00:30, 712.57graphs/s]Creating k-hop graphs:  83%|████████▎ | 109014/130831 [01:58<00:30, 726.59graphs/s]Creating k-hop graphs:  83%|████████▎ | 109088/130831 [01:58<00:30, 714.13graphs/s]Creating k-hop graphs:  83%|████████▎ | 109163/130831 [01:58<00:29, 722.75graphs/s]Creating k-hop graphs:  83%|████████▎ | 109236/130831 [01:58<00:30, 712.63graphs/s]Creating k-hop graphs:  84%|████████▎ | 109316/130831 [01:58<00:29, 737.66graphs/s]Creating k-hop graphs:  84%|████████▎ | 109390/130831 [01:58<00:29, 726.97graphs/s]Creating k-hop graphs:  84%|████████▎ | 109469/130831 [01:58<00:28, 743.04graphs/s]Creating k-hop graphs:  84%|████████▎ | 109552/130831 [01:58<00:27, 766.26graphs/s]Creating k-hop graphs:  84%|████████▍ | 109629/130831 [01:59<00:28, 754.64graphs/s]Creating k-hop graphs:  84%|████████▍ | 109705/130831 [01:59<00:28, 744.90graphs/s]Creating k-hop graphs:  84%|████████▍ | 109780/130831 [01:59<00:28, 729.80graphs/s]Creating k-hop graphs:  84%|████████▍ | 109854/130831 [01:59<00:29, 707.47graphs/s]Creating k-hop graphs:  84%|████████▍ | 109930/130831 [01:59<00:28, 721.94graphs/s]Creating k-hop graphs:  84%|████████▍ | 110007/130831 [01:59<00:28, 735.74graphs/s]Creating k-hop graphs:  84%|████████▍ | 110083/130831 [01:59<00:27, 742.64graphs/s]Creating k-hop graphs:  84%|████████▍ | 110175/130831 [01:59<00:26, 792.91graphs/s]Creating k-hop graphs:  84%|████████▍ | 110259/130831 [01:59<00:25, 805.82graphs/s]Creating k-hop graphs:  84%|████████▍ | 110357/130831 [02:00<00:23, 855.01graphs/s]Creating k-hop graphs:  84%|████████▍ | 110443/130831 [02:00<00:24, 843.48graphs/s]Creating k-hop graphs:  84%|████████▍ | 110528/130831 [02:00<00:26, 777.26graphs/s]Creating k-hop graphs:  85%|████████▍ | 110607/130831 [02:00<00:27, 725.51graphs/s]Creating k-hop graphs:  85%|████████▍ | 110681/130831 [02:00<00:30, 666.75graphs/s]Creating k-hop graphs:  85%|████████▍ | 110750/130831 [02:00<00:31, 643.47graphs/s]Creating k-hop graphs:  85%|████████▍ | 110816/130831 [02:00<00:31, 641.64graphs/s]Creating k-hop graphs:  85%|████████▍ | 110881/130831 [02:00<00:33, 604.09graphs/s]Creating k-hop graphs:  85%|████████▍ | 110952/130831 [02:00<00:31, 630.91graphs/s]Creating k-hop graphs:  85%|████████▍ | 111016/130831 [02:01<00:31, 628.14graphs/s]Creating k-hop graphs:  85%|████████▍ | 111095/130831 [02:01<00:29, 670.75graphs/s]Creating k-hop graphs:  85%|████████▍ | 111163/130831 [02:01<00:30, 653.07graphs/s]Creating k-hop graphs:  85%|████████▌ | 111238/130831 [02:01<00:28, 679.13graphs/s]Creating k-hop graphs:  85%|████████▌ | 111307/130831 [02:01<00:29, 651.53graphs/s]Creating k-hop graphs:  85%|████████▌ | 111373/130831 [02:01<00:29, 649.34graphs/s]Creating k-hop graphs:  85%|████████▌ | 111454/130831 [02:01<00:28, 691.82graphs/s]Creating k-hop graphs:  85%|████████▌ | 111529/130831 [02:01<00:27, 707.07graphs/s]Creating k-hop graphs:  85%|████████▌ | 111605/130831 [02:01<00:26, 719.54graphs/s]Creating k-hop graphs:  85%|████████▌ | 111678/130831 [02:02<00:27, 698.23graphs/s]Creating k-hop graphs:  85%|████████▌ | 111749/130831 [02:02<00:30, 632.43graphs/s]Creating k-hop graphs:  85%|████████▌ | 111814/130831 [02:02<00:31, 608.09graphs/s]Creating k-hop graphs:  86%|████████▌ | 111876/130831 [02:02<00:33, 567.64graphs/s]Creating k-hop graphs:  86%|████████▌ | 111939/130831 [02:02<00:32, 582.92graphs/s]Creating k-hop graphs:  86%|████████▌ | 112007/130831 [02:02<00:30, 607.92graphs/s]Creating k-hop graphs:  86%|████████▌ | 112080/130831 [02:02<00:29, 640.67graphs/s]Creating k-hop graphs:  86%|████████▌ | 112145/130831 [02:02<00:29, 636.21graphs/s]Creating k-hop graphs:  86%|████████▌ | 112217/130831 [02:02<00:28, 660.11graphs/s]Creating k-hop graphs:  86%|████████▌ | 112284/130831 [02:03<00:28, 645.79graphs/s]Creating k-hop graphs:  86%|████████▌ | 112365/130831 [02:03<00:26, 690.31graphs/s]Creating k-hop graphs:  86%|████████▌ | 112435/130831 [02:03<00:26, 687.96graphs/s]Creating k-hop graphs:  86%|████████▌ | 112517/130831 [02:03<00:25, 723.51graphs/s]Creating k-hop graphs:  86%|████████▌ | 112590/130831 [02:03<00:25, 710.00graphs/s]Creating k-hop graphs:  86%|████████▌ | 112662/130831 [02:03<00:25, 703.32graphs/s]Creating k-hop graphs:  86%|████████▌ | 112733/130831 [02:03<00:26, 679.75graphs/s]Creating k-hop graphs:  86%|████████▌ | 112806/130831 [02:03<00:26, 692.65graphs/s]Creating k-hop graphs:  86%|████████▋ | 112887/130831 [02:03<00:24, 723.81graphs/s]Creating k-hop graphs:  86%|████████▋ | 112965/130831 [02:03<00:24, 739.95graphs/s]Creating k-hop graphs:  86%|████████▋ | 113052/130831 [02:04<00:22, 775.99graphs/s]Creating k-hop graphs:  86%|████████▋ | 113130/130831 [02:04<00:23, 768.06graphs/s]Creating k-hop graphs:  87%|████████▋ | 113207/130831 [02:04<00:24, 731.35graphs/s]Creating k-hop graphs:  87%|████████▋ | 113281/130831 [02:04<00:25, 676.95graphs/s]Creating k-hop graphs:  87%|████████▋ | 113356/130831 [02:04<00:25, 696.23graphs/s]Creating k-hop graphs:  87%|████████▋ | 113427/130831 [02:04<00:25, 670.68graphs/s]Creating k-hop graphs:  87%|████████▋ | 113497/130831 [02:04<00:25, 677.58graphs/s]Creating k-hop graphs:  87%|████████▋ | 113566/130831 [02:04<00:26, 659.84graphs/s]Creating k-hop graphs:  87%|████████▋ | 113633/130831 [02:04<00:27, 614.52graphs/s]Creating k-hop graphs:  87%|████████▋ | 113701/130831 [02:05<00:27, 631.60graphs/s]Creating k-hop graphs:  87%|████████▋ | 113767/130831 [02:05<00:26, 637.68graphs/s]Creating k-hop graphs:  87%|████████▋ | 113832/130831 [02:05<00:26, 639.94graphs/s]Creating k-hop graphs:  87%|████████▋ | 113903/130831 [02:05<00:25, 658.32graphs/s]Creating k-hop graphs:  87%|████████▋ | 113973/130831 [02:05<00:25, 668.18graphs/s]Creating k-hop graphs:  87%|████████▋ | 114042/130831 [02:05<00:24, 671.75graphs/s]Creating k-hop graphs:  87%|████████▋ | 114110/130831 [02:05<00:25, 650.26graphs/s]Creating k-hop graphs:  87%|████████▋ | 114183/130831 [02:05<00:24, 671.92graphs/s]Creating k-hop graphs:  87%|████████▋ | 114251/130831 [02:05<00:25, 645.00graphs/s]Creating k-hop graphs:  87%|████████▋ | 114329/130831 [02:05<00:24, 679.73graphs/s]Creating k-hop graphs:  87%|████████▋ | 114398/130831 [02:06<00:26, 631.82graphs/s]Creating k-hop graphs:  87%|████████▋ | 114463/130831 [02:06<00:26, 619.41graphs/s]Creating k-hop graphs:  88%|████████▊ | 114526/130831 [02:06<00:26, 607.83graphs/s]Creating k-hop graphs:  88%|████████▊ | 114588/130831 [02:06<00:26, 601.74graphs/s]Creating k-hop graphs:  88%|████████▊ | 114650/130831 [02:06<00:26, 605.22graphs/s]Creating k-hop graphs:  88%|████████▊ | 114711/130831 [02:06<00:27, 583.93graphs/s]Creating k-hop graphs:  88%|████████▊ | 114772/130831 [02:06<00:27, 589.10graphs/s]Creating k-hop graphs:  88%|████████▊ | 114832/130831 [02:06<00:28, 562.03graphs/s]Creating k-hop graphs:  88%|████████▊ | 114908/130831 [02:06<00:25, 616.84graphs/s]Creating k-hop graphs:  88%|████████▊ | 114977/130831 [02:07<00:24, 637.21graphs/s]Creating k-hop graphs:  88%|████████▊ | 115042/130831 [02:07<00:24, 640.32graphs/s]Creating k-hop graphs:  88%|████████▊ | 115107/130831 [02:07<00:25, 607.72graphs/s]Creating k-hop graphs:  88%|████████▊ | 115169/130831 [02:07<00:26, 595.75graphs/s]Creating k-hop graphs:  88%|████████▊ | 115229/130831 [02:07<00:26, 587.02graphs/s]Creating k-hop graphs:  88%|████████▊ | 115288/130831 [02:07<00:26, 575.98graphs/s]Creating k-hop graphs:  88%|████████▊ | 115361/130831 [02:07<00:25, 617.45graphs/s]Creating k-hop graphs:  88%|████████▊ | 115424/130831 [02:07<00:25, 604.35graphs/s]Creating k-hop graphs:  88%|████████▊ | 115499/130831 [02:07<00:23, 645.78graphs/s]Creating k-hop graphs:  88%|████████▊ | 115564/130831 [02:08<00:25, 592.80graphs/s]Creating k-hop graphs:  88%|████████▊ | 115625/130831 [02:08<00:26, 577.20graphs/s]Creating k-hop graphs:  88%|████████▊ | 115684/130831 [02:08<00:26, 580.13graphs/s]Creating k-hop graphs:  88%|████████▊ | 115743/130831 [02:08<00:26, 565.50graphs/s]Creating k-hop graphs:  89%|████████▊ | 115804/130831 [02:08<00:26, 577.74graphs/s]Creating k-hop graphs:  89%|████████▊ | 115863/130831 [02:08<00:26, 559.01graphs/s]Creating k-hop graphs:  89%|████████▊ | 115921/130831 [02:08<00:26, 560.41graphs/s]Creating k-hop graphs:  89%|████████▊ | 115978/130831 [02:08<00:27, 533.34graphs/s]Creating k-hop graphs:  89%|████████▊ | 116032/130831 [02:08<00:28, 510.82graphs/s]Creating k-hop graphs:  89%|████████▊ | 116084/130831 [02:09<00:29, 494.08graphs/s]Creating k-hop graphs:  89%|████████▉ | 116134/130831 [02:09<00:29, 493.00graphs/s]Creating k-hop graphs:  89%|████████▉ | 116192/130831 [02:09<00:28, 517.06graphs/s]Creating k-hop graphs:  89%|████████▉ | 116257/130831 [02:09<00:26, 553.73graphs/s]Creating k-hop graphs:  89%|████████▉ | 116313/130831 [02:09<00:28, 515.67graphs/s]Creating k-hop graphs:  89%|████████▉ | 116366/130831 [02:09<00:28, 502.17graphs/s]Creating k-hop graphs:  89%|████████▉ | 116417/130831 [02:09<00:29, 487.59graphs/s]Creating k-hop graphs:  89%|████████▉ | 116482/130831 [02:09<00:27, 530.70graphs/s]Creating k-hop graphs:  89%|████████▉ | 116536/130831 [02:09<00:27, 515.57graphs/s]Creating k-hop graphs:  89%|████████▉ | 116588/130831 [02:10<00:27, 516.48graphs/s]Creating k-hop graphs:  89%|████████▉ | 116640/130831 [02:10<00:27, 514.16graphs/s]Creating k-hop graphs:  89%|████████▉ | 116692/130831 [02:10<00:27, 509.72graphs/s]Creating k-hop graphs:  89%|████████▉ | 116752/130831 [02:10<00:26, 534.33graphs/s]Creating k-hop graphs:  89%|████████▉ | 116813/130831 [02:10<00:25, 553.24graphs/s]Creating k-hop graphs:  89%|████████▉ | 116871/130831 [02:10<00:24, 560.39graphs/s]Creating k-hop graphs:  89%|████████▉ | 116928/130831 [02:10<00:26, 519.87graphs/s]Creating k-hop graphs:  89%|████████▉ | 116982/130831 [02:10<00:26, 524.07graphs/s]Creating k-hop graphs:  89%|████████▉ | 117038/130831 [02:10<00:25, 532.64graphs/s]Creating k-hop graphs:  90%|████████▉ | 117100/130831 [02:10<00:24, 557.46graphs/s]Creating k-hop graphs:  90%|████████▉ | 117170/130831 [02:11<00:22, 597.08graphs/s]Creating k-hop graphs:  90%|████████▉ | 117232/130831 [02:11<00:22, 603.09graphs/s]Creating k-hop graphs:  90%|████████▉ | 117294/130831 [02:11<00:22, 606.60graphs/s]Creating k-hop graphs:  90%|████████▉ | 117361/130831 [02:11<00:21, 623.36graphs/s]Creating k-hop graphs:  90%|████████▉ | 117431/130831 [02:11<00:20, 644.88graphs/s]Creating k-hop graphs:  90%|████████▉ | 117496/130831 [02:11<00:20, 644.29graphs/s]Creating k-hop graphs:  90%|████████▉ | 117561/130831 [02:11<00:20, 639.40graphs/s]Creating k-hop graphs:  90%|████████▉ | 117625/130831 [02:11<00:20, 639.49graphs/s]Creating k-hop graphs:  90%|████████▉ | 117697/130831 [02:11<00:19, 662.94graphs/s]Creating k-hop graphs:  90%|█████████ | 117764/130831 [02:11<00:21, 618.49graphs/s]Creating k-hop graphs:  90%|█████████ | 117827/130831 [02:12<00:22, 581.51graphs/s]Creating k-hop graphs:  90%|█████████ | 117886/130831 [02:12<00:22, 573.60graphs/s]Creating k-hop graphs:  90%|█████████ | 117955/130831 [02:12<00:21, 604.17graphs/s]Creating k-hop graphs:  90%|█████████ | 118016/130831 [02:12<00:21, 593.13graphs/s]Creating k-hop graphs:  90%|█████████ | 118081/130831 [02:12<00:20, 608.35graphs/s]Creating k-hop graphs:  90%|█████████ | 118144/130831 [02:12<00:20, 614.32graphs/s]Creating k-hop graphs:  90%|█████████ | 118212/130831 [02:12<00:19, 633.09graphs/s]Creating k-hop graphs:  90%|█████████ | 118276/130831 [02:12<00:19, 629.03graphs/s]Creating k-hop graphs:  90%|█████████ | 118340/130831 [02:12<00:20, 602.60graphs/s]Creating k-hop graphs:  90%|█████████ | 118401/130831 [02:13<00:21, 582.98graphs/s]Creating k-hop graphs:  91%|█████████ | 118460/130831 [02:13<00:21, 571.68graphs/s]Creating k-hop graphs:  91%|█████████ | 118518/130831 [02:13<00:22, 550.22graphs/s]Creating k-hop graphs:  91%|█████████ | 118574/130831 [02:13<00:23, 531.11graphs/s]Creating k-hop graphs:  91%|█████████ | 118629/130831 [02:13<00:22, 535.51graphs/s]Creating k-hop graphs:  91%|█████████ | 118683/130831 [02:13<00:23, 512.36graphs/s]Creating k-hop graphs:  91%|█████████ | 118735/130831 [02:13<00:23, 512.25graphs/s]Creating k-hop graphs:  91%|█████████ | 118790/130831 [02:13<00:23, 520.32graphs/s]Creating k-hop graphs:  91%|█████████ | 118846/130831 [02:13<00:22, 529.02graphs/s]Creating k-hop graphs:  91%|█████████ | 118916/130831 [02:14<00:20, 576.70graphs/s]Creating k-hop graphs:  91%|█████████ | 118974/130831 [02:14<00:21, 550.27graphs/s]Creating k-hop graphs:  91%|█████████ | 119038/130831 [02:14<00:20, 573.63graphs/s]Creating k-hop graphs:  91%|█████████ | 119096/130831 [02:14<00:20, 568.69graphs/s]Creating k-hop graphs:  91%|█████████ | 119158/130831 [02:14<00:20, 580.86graphs/s]Creating k-hop graphs:  91%|█████████ | 119217/130831 [02:14<00:20, 559.71graphs/s]Creating k-hop graphs:  91%|█████████ | 119274/130831 [02:14<00:20, 554.04graphs/s]Creating k-hop graphs:  91%|█████████ | 119331/130831 [02:14<00:20, 556.89graphs/s]Creating k-hop graphs:  91%|█████████▏| 119387/130831 [02:14<00:20, 549.89graphs/s]Creating k-hop graphs:  91%|█████████▏| 119443/130831 [02:14<00:20, 548.39graphs/s]Creating k-hop graphs:  91%|█████████▏| 119506/130831 [02:15<00:19, 571.06graphs/s]Creating k-hop graphs:  91%|█████████▏| 119564/130831 [02:15<00:20, 545.52graphs/s]Creating k-hop graphs:  91%|█████████▏| 119625/130831 [02:15<00:19, 563.43graphs/s]Creating k-hop graphs:  91%|█████████▏| 119682/130831 [02:15<00:21, 525.20graphs/s]Creating k-hop graphs:  92%|█████████▏| 119736/130831 [02:15<00:22, 482.60graphs/s]Creating k-hop graphs:  92%|█████████▏| 119786/130831 [02:15<00:23, 475.85graphs/s]Creating k-hop graphs:  92%|█████████▏| 119835/130831 [02:15<00:24, 454.31graphs/s]Creating k-hop graphs:  92%|█████████▏| 119895/130831 [02:15<00:22, 491.00graphs/s]Creating k-hop graphs:  92%|█████████▏| 119945/130831 [02:16<00:23, 465.12graphs/s]Creating k-hop graphs:  92%|█████████▏| 119993/130831 [02:16<00:23, 459.81graphs/s]Creating k-hop graphs:  92%|█████████▏| 120052/130831 [02:16<00:21, 495.34graphs/s]Creating k-hop graphs:  92%|█████████▏| 120103/130831 [02:16<00:21, 499.27graphs/s]Creating k-hop graphs:  92%|█████████▏| 120154/130831 [02:16<00:22, 483.31graphs/s]Creating k-hop graphs:  92%|█████████▏| 120205/130831 [02:16<00:21, 488.30graphs/s]Creating k-hop graphs:  92%|█████████▏| 120255/130831 [02:16<00:21, 481.25graphs/s]Creating k-hop graphs:  92%|█████████▏| 120305/130831 [02:16<00:21, 486.20graphs/s]Creating k-hop graphs:  92%|█████████▏| 120354/130831 [02:16<00:21, 486.03graphs/s]Creating k-hop graphs:  92%|█████████▏| 120413/130831 [02:16<00:20, 514.46graphs/s]Creating k-hop graphs:  92%|█████████▏| 120465/130831 [02:17<00:20, 505.83graphs/s]Creating k-hop graphs:  92%|█████████▏| 120516/130831 [02:17<00:20, 504.86graphs/s]Creating k-hop graphs:  92%|█████████▏| 120581/130831 [02:17<00:18, 546.44graphs/s]Creating k-hop graphs:  92%|█████████▏| 120636/130831 [02:17<00:19, 526.21graphs/s]Creating k-hop graphs:  92%|█████████▏| 120689/130831 [02:17<00:20, 501.82graphs/s]Creating k-hop graphs:  92%|█████████▏| 120740/130831 [02:17<00:20, 489.27graphs/s]Creating k-hop graphs:  92%|█████████▏| 120790/130831 [02:17<00:22, 450.88graphs/s]Creating k-hop graphs:  92%|█████████▏| 120836/130831 [02:17<00:23, 422.45graphs/s]Creating k-hop graphs:  92%|█████████▏| 120881/130831 [02:17<00:23, 429.36graphs/s]Creating k-hop graphs:  92%|█████████▏| 120925/130831 [02:18<00:23, 416.15graphs/s]Creating k-hop graphs:  92%|█████████▏| 120969/130831 [02:18<00:23, 422.62graphs/s]Creating k-hop graphs:  93%|█████████▎| 121019/130831 [02:18<00:22, 443.35graphs/s]Creating k-hop graphs:  93%|█████████▎| 121117/130831 [02:18<00:16, 595.48graphs/s]Creating k-hop graphs:  93%|█████████▎| 121222/130831 [02:18<00:13, 726.68graphs/s]Creating k-hop graphs:  93%|█████████▎| 121362/130831 [02:18<00:10, 923.43graphs/s]Creating k-hop graphs:  93%|█████████▎| 121503/130831 [02:18<00:08, 1063.87graphs/s]Creating k-hop graphs:  93%|█████████▎| 121611/130831 [02:18<00:08, 1067.86graphs/s]Creating k-hop graphs:  93%|█████████▎| 121748/130831 [02:18<00:07, 1157.01graphs/s]Creating k-hop graphs:  93%|█████████▎| 121882/130831 [02:18<00:07, 1210.16graphs/s]Creating k-hop graphs:  93%|█████████▎| 122004/130831 [02:19<00:07, 1144.97graphs/s]Creating k-hop graphs:  93%|█████████▎| 122124/130831 [02:19<00:07, 1158.71graphs/s]Creating k-hop graphs:  93%|█████████▎| 122241/130831 [02:19<00:07, 1091.44graphs/s]Creating k-hop graphs:  94%|█████████▎| 122352/130831 [02:19<00:08, 957.63graphs/s] Creating k-hop graphs:  94%|█████████▎| 122452/130831 [02:19<00:09, 924.61graphs/s]Creating k-hop graphs:  94%|█████████▎| 122547/130831 [02:19<00:08, 926.15graphs/s]Creating k-hop graphs:  94%|█████████▎| 122653/130831 [02:19<00:08, 960.74graphs/s]Creating k-hop graphs:  94%|█████████▍| 122760/130831 [02:19<00:08, 990.59graphs/s]Creating k-hop graphs:  94%|█████████▍| 122872/130831 [02:19<00:07, 1027.05graphs/s]Creating k-hop graphs:  94%|█████████▍| 122992/130831 [02:20<00:07, 1074.47graphs/s]Creating k-hop graphs:  94%|█████████▍| 123103/130831 [02:20<00:07, 1083.31graphs/s]Creating k-hop graphs:  94%|█████████▍| 123217/130831 [02:20<00:06, 1098.13graphs/s]Creating k-hop graphs:  94%|█████████▍| 123328/130831 [02:20<00:06, 1083.69graphs/s]Creating k-hop graphs:  94%|█████████▍| 123443/130831 [02:20<00:06, 1100.81graphs/s]Creating k-hop graphs:  94%|█████████▍| 123555/130831 [02:20<00:06, 1103.94graphs/s]Creating k-hop graphs:  95%|█████████▍| 123666/130831 [02:20<00:06, 1083.37graphs/s]Creating k-hop graphs:  95%|█████████▍| 123780/130831 [02:20<00:06, 1099.85graphs/s]Creating k-hop graphs:  95%|█████████▍| 123891/130831 [02:20<00:07, 986.84graphs/s] Creating k-hop graphs:  95%|█████████▍| 123992/130831 [02:21<00:07, 929.42graphs/s]Creating k-hop graphs:  95%|█████████▍| 124087/130831 [02:21<00:07, 888.38graphs/s]Creating k-hop graphs:  95%|█████████▍| 124178/130831 [02:21<00:07, 854.13graphs/s]Creating k-hop graphs:  95%|█████████▍| 124265/130831 [02:21<00:08, 797.74graphs/s]Creating k-hop graphs:  95%|█████████▌| 124346/130831 [02:21<00:08, 763.62graphs/s]Creating k-hop graphs:  95%|█████████▌| 124424/130831 [02:21<00:08, 761.85graphs/s]Creating k-hop graphs:  95%|█████████▌| 124502/130831 [02:21<00:08, 764.80graphs/s]Creating k-hop graphs:  95%|█████████▌| 124582/130831 [02:21<00:08, 772.62graphs/s]Creating k-hop graphs:  95%|█████████▌| 124661/130831 [02:21<00:07, 775.79graphs/s]Creating k-hop graphs:  95%|█████████▌| 124740/130831 [02:22<00:07, 775.29graphs/s]Creating k-hop graphs:  95%|█████████▌| 124849/130831 [02:22<00:06, 864.95graphs/s]Creating k-hop graphs:  96%|█████████▌| 124959/130831 [02:22<00:06, 933.78graphs/s]Creating k-hop graphs:  96%|█████████▌| 125062/130831 [02:22<00:06, 961.32graphs/s]Creating k-hop graphs:  96%|█████████▌| 125178/130831 [02:22<00:05, 1019.21graphs/s]Creating k-hop graphs:  96%|█████████▌| 125297/130831 [02:22<00:05, 1069.48graphs/s]Creating k-hop graphs:  96%|█████████▌| 125415/130831 [02:22<00:04, 1099.95graphs/s]Creating k-hop graphs:  96%|█████████▌| 125526/130831 [02:22<00:04, 1083.79graphs/s]Creating k-hop graphs:  96%|█████████▌| 125635/130831 [02:22<00:04, 1056.26graphs/s]Creating k-hop graphs:  96%|█████████▌| 125741/130831 [02:22<00:05, 1017.65graphs/s]Creating k-hop graphs:  96%|█████████▌| 125844/130831 [02:23<00:04, 1013.37graphs/s]Creating k-hop graphs:  96%|█████████▋| 125946/130831 [02:23<00:04, 995.49graphs/s] Creating k-hop graphs:  96%|█████████▋| 126046/130831 [02:23<00:04, 996.39graphs/s]Creating k-hop graphs:  96%|█████████▋| 126150/130831 [02:23<00:04, 1006.37graphs/s]Creating k-hop graphs:  97%|█████████▋| 126255/130831 [02:23<00:04, 1019.05graphs/s]Creating k-hop graphs:  97%|█████████▋| 126358/130831 [02:23<00:04, 986.89graphs/s] Creating k-hop graphs:  97%|█████████▋| 126503/130831 [02:23<00:03, 1120.35graphs/s]Creating k-hop graphs:  97%|█████████▋| 126687/130831 [02:23<00:03, 1329.64graphs/s]Creating k-hop graphs:  97%|█████████▋| 126830/130831 [02:23<00:02, 1357.49graphs/s]Creating k-hop graphs:  97%|█████████▋| 126967/130831 [02:24<00:02, 1316.86graphs/s]Creating k-hop graphs:  97%|█████████▋| 127102/130831 [02:24<00:02, 1325.54graphs/s]Creating k-hop graphs:  97%|█████████▋| 127236/130831 [02:24<00:02, 1313.26graphs/s]Creating k-hop graphs:  97%|█████████▋| 127374/130831 [02:24<00:02, 1330.43graphs/s]Creating k-hop graphs:  97%|█████████▋| 127508/130831 [02:24<00:02, 1296.53graphs/s]Creating k-hop graphs:  98%|█████████▊| 127649/130831 [02:24<00:02, 1327.50graphs/s]Creating k-hop graphs:  98%|█████████▊| 127814/130831 [02:24<00:02, 1420.57graphs/s]Creating k-hop graphs:  98%|█████████▊| 128019/130831 [02:24<00:01, 1605.50graphs/s]Creating k-hop graphs:  98%|█████████▊| 128187/130831 [02:24<00:01, 1623.16graphs/s]Creating k-hop graphs:  98%|█████████▊| 128350/130831 [02:24<00:01, 1589.45graphs/s]Creating k-hop graphs:  98%|█████████▊| 128510/130831 [02:25<00:01, 1536.56graphs/s]Creating k-hop graphs:  98%|█████████▊| 128665/130831 [02:25<00:01, 1509.07graphs/s]Creating k-hop graphs:  98%|█████████▊| 128817/130831 [02:25<00:01, 1426.92graphs/s]Creating k-hop graphs:  99%|█████████▊| 128961/130831 [02:25<00:01, 1415.62graphs/s]Creating k-hop graphs:  99%|█████████▊| 129104/130831 [02:25<00:01, 1305.56graphs/s]Creating k-hop graphs:  99%|█████████▉| 129284/130831 [02:25<00:01, 1438.53graphs/s]Creating k-hop graphs:  99%|█████████▉| 129463/130831 [02:25<00:00, 1534.95graphs/s]Creating k-hop graphs:  99%|█████████▉| 129625/130831 [02:25<00:00, 1555.24graphs/s]Creating k-hop graphs:  99%|█████████▉| 129783/130831 [02:25<00:00, 1508.83graphs/s]Creating k-hop graphs:  99%|█████████▉| 129944/130831 [02:26<00:00, 1536.37graphs/s]Creating k-hop graphs:  99%|█████████▉| 130099/130831 [02:26<00:00, 1534.23graphs/s]Creating k-hop graphs: 100%|█████████▉| 130254/130831 [02:26<00:00, 1482.32graphs/s]Creating k-hop graphs: 100%|█████████▉| 130441/130831 [02:26<00:00, 1592.27graphs/s]Creating k-hop graphs: 100%|█████████▉| 130620/130831 [02:26<00:00, 1645.44graphs/s]Creating k-hop graphs: 100%|█████████▉| 130786/130831 [02:26<00:00, 1483.92graphs/s]Creating k-hop graphs: 100%|██████████| 130831/130831 [02:26<00:00, 892.20graphs/s] 
Starting experiment
task: Task.QM9
type: GNN_TYPE.GCN
dim: 32
depth: 3
num_layers: 5
train_fraction: 0.8
max_epochs: 30000
eval_every: 100
batch_size: 2048
accum_grad: 1
patience: 50000
stop: STOP.TRAIN
loader_workers: 0
last_layer: LAST_LAYER.K_HOP
k_hop: 5
no_layer_norm: False
no_activation: False
no_residual: False
unroll: False
max_samples: 150000
learning_rate: 0.001
weight_decay: 0.0
k_fold: 5

Number of observations: 130831
Starting training
Epoch 100 @ 1, LR: [0.001]: Train loss: 1510.0976185, Test loss: 167.7570490 (new best train)
Epoch 200 @ 1, LR: [0.001]: Train loss: 142.4408410, Test loss: 125.7238914 (new best train)
Epoch 300 @ 1, LR: [0.001]: Train loss: 99.7572315, Test loss: 92.4393333 (new best train)
Epoch 400 @ 1, LR: [0.001]: Train loss: 88.6229407, Test loss: 87.4630682 (new best train)
Epoch 500 @ 1, LR: [0.001]: Train loss: 82.1619664, Test loss: 79.2066386 (new best train)
Epoch 600 @ 1, LR: [0.001]: Train loss: 78.2763235, Test loss: 76.5125084 (new best train)
Epoch 700 @ 1, LR: [0.001]: Train loss: 76.4202835, Test loss: 74.7929326 (new best train)
Epoch 800 @ 1, LR: [0.001]: Train loss: 75.1419832, Test loss: 83.8521222 (new best train)
Epoch 900 @ 1, LR: [0.001]: Train loss: 74.2454081, Test loss: 73.3787620 (new best train)
Epoch 1000 @ 1, LR: [0.001]: Train loss: 73.4331863, Test loss: 75.2981214 (new best train)
Epoch 1100 @ 1, LR: [0.001]: Train loss: 72.9196648, Test loss: 71.3304445 (new best train)
Epoch 1200 @ 1, LR: [0.001]: Train loss: 72.3714798, Test loss: 72.3635970 (new best train)
Epoch 1300 @ 1, LR: [0.001]: Train loss: 71.7891354, Test loss: 71.0886393 (new best train)
Epoch 1400 @ 1, LR: [0.001]: Train loss: 71.3134902, Test loss: 70.2271879 (new best train)
Epoch 1500 @ 1, LR: [0.001]: Train loss: 70.8413857, Test loss: 70.8405464 (new best train)
Epoch 1600 @ 1, LR: [0.001]: Train loss: 70.5327064, Test loss: 74.1642254 (new best train)
Epoch 1700 @ 1, LR: [0.001]: Train loss: 70.1549591, Test loss: 69.7016781 (new best train)
Epoch 1800 @ 1, LR: [0.001]: Train loss: 69.9586790, Test loss: 74.2558714 (new best train)
Epoch 1900 @ 1, LR: [0.001]: Train loss: 69.5637770, Test loss: 73.1978157 (new best train)
Epoch 2000 @ 1, LR: [0.001]: Train loss: 69.1617035, Test loss: 72.3281131 (new best train)
Epoch 2100 @ 1, LR: [0.001]: Train loss: 69.0010198, Test loss: 68.4931320 (new best train)
Epoch 2200 @ 1, LR: [0.001]: Train loss: 68.7700599, Test loss: 68.8093448 (new best train)
Epoch 2300 @ 1, LR: [0.001]: Train loss: 68.4074695, Test loss: 67.9043419 (new best train)
Epoch 2400 @ 1, LR: [0.001]: Train loss: 68.3595784, Test loss: 69.2041665 (new best train)
Epoch 2500 @ 1, LR: [0.001]: Train loss: 68.1428872, Test loss: 68.8624021 (new best train)
Epoch 2600 @ 1, LR: [0.001]: Train loss: 67.8750879, Test loss: 72.6587136 (new best train)
Epoch 2700 @ 1, LR: [0.001]: Train loss: 67.9012057, Test loss: 68.9886891
Epoch 2800 @ 1, LR: [0.001]: Train loss: 67.7227461, Test loss: 67.5699757 (new best train)
Epoch 2900 @ 1, LR: [0.001]: Train loss: 67.5267712, Test loss: 68.9754699 (new best train)
Epoch 3000 @ 1, LR: [0.001]: Train loss: 67.3726472, Test loss: 67.1437245 (new best train)
Epoch 3100 @ 1, LR: [0.001]: Train loss: 67.2148514, Test loss: 67.3807811 (new best train)
Epoch 3200 @ 1, LR: [0.001]: Train loss: 67.0709929, Test loss: 67.9867089 (new best train)
Epoch 3300 @ 1, LR: [0.001]: Train loss: 66.8938705, Test loss: 68.0217083 (new best train)
Epoch 3400 @ 1, LR: [0.001]: Train loss: 66.7797122, Test loss: 67.2585990 (new best train)
Epoch 3500 @ 1, LR: [0.001]: Train loss: 66.6625581, Test loss: 67.3957087 (new best train)
Epoch 3600 @ 1, LR: [0.001]: Train loss: 66.4517574, Test loss: 68.8747189 (new best train)
Epoch 3700 @ 1, LR: [0.001]: Train loss: 66.3119137, Test loss: 68.0942902 (new best train)
Epoch 3800 @ 1, LR: [0.001]: Train loss: 66.2649089, Test loss: 66.7986695 (new best train)
Epoch 3900 @ 1, LR: [0.001]: Train loss: 66.0719824, Test loss: 66.4051042 (new best train)
Epoch 4000 @ 1, LR: [0.001]: Train loss: 66.0000442, Test loss: 65.8915272 (new best train)
Epoch 4100 @ 1, LR: [0.001]: Train loss: 65.8663610, Test loss: 65.7438376 (new best train)
Epoch 4200 @ 1, LR: [0.001]: Train loss: 65.6812846, Test loss: 66.0699649 (new best train)
Epoch 4300 @ 1, LR: [0.001]: Train loss: 65.6182762, Test loss: 65.8540704 (new best train)
Epoch 4400 @ 1, LR: [0.001]: Train loss: 65.4336193, Test loss: 65.8683827 (new best train)
Epoch 4500 @ 1, LR: [0.001]: Train loss: 65.3565995, Test loss: 66.0526770 (new best train)
Epoch 4600 @ 1, LR: [0.001]: Train loss: 65.1996368, Test loss: 65.2728487 (new best train)
Epoch 4700 @ 1, LR: [0.001]: Train loss: 65.1464843, Test loss: 65.2051847 (new best train)
Epoch 4800 @ 1, LR: [0.001]: Train loss: 64.9763809, Test loss: 65.9575901 (new best train)
Epoch 4900 @ 1, LR: [0.001]: Train loss: 64.8794235, Test loss: 65.8667350 (new best train)
Epoch 5000 @ 1, LR: [0.001]: Train loss: 64.6915002, Test loss: 69.1449836 (new best train)
Epoch 5100 @ 1, LR: [0.001]: Train loss: 64.5757270, Test loss: 67.3626636 (new best train)
Epoch 5200 @ 1, LR: [0.001]: Train loss: 64.4028885, Test loss: 64.9110278 (new best train)
Epoch 5300 @ 1, LR: [0.001]: Train loss: 64.2672850, Test loss: 63.9359581 (new best train)
Epoch 5400 @ 1, LR: [0.001]: Train loss: 64.0282232, Test loss: 64.4880538 (new best train)
Epoch 5500 @ 1, LR: [0.001]: Train loss: 63.7696259, Test loss: 66.7510158 (new best train)
Epoch 5600 @ 1, LR: [0.001]: Train loss: 63.4145048, Test loss: 63.4093153 (new best train)
Epoch 5700 @ 1, LR: [0.001]: Train loss: 63.3155866, Test loss: 63.3933713 (new best train)
Epoch 5800 @ 1, LR: [0.001]: Train loss: 62.9821792, Test loss: 63.6097653 (new best train)
Epoch 5900 @ 1, LR: [0.001]: Train loss: 62.8699590, Test loss: 63.9352217 (new best train)
Epoch 6000 @ 1, LR: [0.001]: Train loss: 62.6161224, Test loss: 64.2342146 (new best train)
Epoch 6100 @ 1, LR: [0.001]: Train loss: 62.3819001, Test loss: 62.1070128 (new best train)
Epoch 6200 @ 1, LR: [0.001]: Train loss: 62.2030640, Test loss: 63.5963627 (new best train)
Epoch 6300 @ 1, LR: [0.001]: Train loss: 62.0770755, Test loss: 67.2134015 (new best train)
Epoch 6400 @ 1, LR: [0.001]: Train loss: 61.8823762, Test loss: 62.0715262 (new best train)
Epoch 6500 @ 1, LR: [0.001]: Train loss: 61.6600618, Test loss: 62.9819474 (new best train)
Epoch 6600 @ 1, LR: [0.001]: Train loss: 61.4960421, Test loss: 63.2635960 (new best train)
Epoch 6700 @ 1, LR: [0.001]: Train loss: 61.3743107, Test loss: 61.8098091 (new best train)
Epoch 6800 @ 1, LR: [0.001]: Train loss: 61.2446860, Test loss: 62.9386213 (new best train)
Epoch 6900 @ 1, LR: [0.001]: Train loss: 61.1174147, Test loss: 63.5334462 (new best train)
Epoch 7000 @ 1, LR: [0.001]: Train loss: 60.9984190, Test loss: 62.0720384 (new best train)
Epoch 7100 @ 1, LR: [0.001]: Train loss: 60.9146543, Test loss: 61.2341613 (new best train)
Epoch 7200 @ 1, LR: [0.001]: Train loss: 60.7644817, Test loss: 61.3530051 (new best train)
Epoch 7300 @ 1, LR: [0.001]: Train loss: 60.6490455, Test loss: 61.0306419 (new best train)
Epoch 7400 @ 1, LR: [0.001]: Train loss: 60.5653953, Test loss: 60.5500998 (new best train)
Epoch 7500 @ 1, LR: [0.001]: Train loss: 60.4349960, Test loss: 62.7180777 (new best train)
Epoch 7600 @ 1, LR: [0.001]: Train loss: 60.2900417, Test loss: 63.0748509 (new best train)
Epoch 7700 @ 1, LR: [0.001]: Train loss: 60.1368028, Test loss: 60.9269113 (new best train)
Epoch 7800 @ 1, LR: [0.001]: Train loss: 60.0310639, Test loss: 60.7156218 (new best train)
Epoch 7900 @ 1, LR: [0.001]: Train loss: 59.8952304, Test loss: 60.2611243 (new best train)
Epoch 8000 @ 1, LR: [0.001]: Train loss: 59.7419066, Test loss: 61.3110551 (new best train)
Epoch 8100 @ 1, LR: [0.001]: Train loss: 59.6780581, Test loss: 62.7658632 (new best train)
Epoch 8200 @ 1, LR: [0.001]: Train loss: 59.6093580, Test loss: 59.7826873 (new best train)
Epoch 8300 @ 1, LR: [0.001]: Train loss: 59.5577713, Test loss: 59.8061674 (new best train)
Epoch 8400 @ 1, LR: [0.001]: Train loss: 59.3753442, Test loss: 64.0500167 (new best train)
Epoch 8500 @ 1, LR: [0.001]: Train loss: 59.2954592, Test loss: 60.1164904 (new best train)
Epoch 8600 @ 1, LR: [0.001]: Train loss: 59.1775835, Test loss: 61.6765557 (new best train)
Epoch 8700 @ 1, LR: [0.001]: Train loss: 59.0814461, Test loss: 59.2006694 (new best train)
Epoch 8800 @ 1, LR: [0.001]: Train loss: 58.9914168, Test loss: 60.4973796 (new best train)
Epoch 8900 @ 1, LR: [0.001]: Train loss: 58.9207114, Test loss: 59.0830638 (new best train)
Epoch 9000 @ 1, LR: [0.001]: Train loss: 58.8386247, Test loss: 58.9973305 (new best train)
Epoch 9100 @ 1, LR: [0.001]: Train loss: 58.7158235, Test loss: 61.0430669 (new best train)
Epoch 9200 @ 1, LR: [0.001]: Train loss: 58.6810024, Test loss: 61.8801863 (new best train)
Epoch 9300 @ 1, LR: [0.001]: Train loss: 58.5766503, Test loss: 59.3616848 (new best train)
Epoch 9400 @ 1, LR: [0.001]: Train loss: 58.4898330, Test loss: 58.5091936 (new best train)
Epoch 9500 @ 1, LR: [0.001]: Train loss: 58.3793147, Test loss: 59.3103853 (new best train)
Epoch 9600 @ 1, LR: [0.001]: Train loss: 58.3390217, Test loss: 60.5300190 (new best train)
Epoch 9700 @ 1, LR: [0.001]: Train loss: 58.2490674, Test loss: 58.4558290 (new best train)
Epoch 9800 @ 1, LR: [0.001]: Train loss: 58.1780532, Test loss: 59.2459801 (new best train)
Epoch 9900 @ 1, LR: [0.001]: Train loss: 58.1117436, Test loss: 58.7574955 (new best train)
Epoch 10000 @ 1, LR: [0.001]: Train loss: 58.0225938, Test loss: 59.4600126 (new best train)
Epoch 10100 @ 1, LR: [0.001]: Train loss: 57.9501635, Test loss: 58.7939295 (new best train)
Epoch 10200 @ 1, LR: [0.001]: Train loss: 57.8594002, Test loss: 59.1045970 (new best train)
Epoch 10300 @ 1, LR: [0.001]: Train loss: 57.8098536, Test loss: 58.8446410 (new best train)
Epoch 10400 @ 1, LR: [0.001]: Train loss: 57.7834155, Test loss: 57.9616644 (new best train)
Epoch 10500 @ 1, LR: [0.001]: Train loss: 57.6968241, Test loss: 58.3512690 (new best train)
Epoch 10600 @ 1, LR: [0.001]: Train loss: 57.6832542, Test loss: 59.3572887 (new best train)
Epoch 10700 @ 1, LR: [0.001]: Train loss: 57.5968978, Test loss: 60.4681752 (new best train)
Epoch 10800 @ 1, LR: [0.001]: Train loss: 57.5297674, Test loss: 58.1771010 (new best train)
Epoch 10900 @ 1, LR: [0.001]: Train loss: 57.4006990, Test loss: 58.7677998 (new best train)
Epoch 11000 @ 1, LR: [0.001]: Train loss: 57.3858604, Test loss: 58.5715450 (new best train)
Epoch 11100 @ 1, LR: [0.001]: Train loss: 57.3041702, Test loss: 60.9013033 (new best train)
Epoch 11200 @ 1, LR: [0.001]: Train loss: 57.2857583, Test loss: 58.2533588 (new best train)
Epoch 11300 @ 1, LR: [0.001]: Train loss: 57.2160103, Test loss: 59.8157222 (new best train)
Epoch 11400 @ 1, LR: [0.001]: Train loss: 57.1724074, Test loss: 57.8876808 (new best train)
Epoch 11500 @ 1, LR: [0.001]: Train loss: 57.0801193, Test loss: 57.5066223 (new best train)
Epoch 11600 @ 1, LR: [0.001]: Train loss: 57.0459789, Test loss: 59.1238234 (new best train)
Epoch 11700 @ 1, LR: [0.001]: Train loss: 57.0089199, Test loss: 57.9485153 (new best train)
Epoch 11800 @ 1, LR: [0.001]: Train loss: 56.9047495, Test loss: 58.3159682 (new best train)
Epoch 11900 @ 1, LR: [0.001]: Train loss: 56.8733106, Test loss: 58.7914992 (new best train)
Epoch 12000 @ 1, LR: [0.001]: Train loss: 56.8712224, Test loss: 58.6622742 (new best train)
Epoch 12100 @ 1, LR: [0.001]: Train loss: 56.7983083, Test loss: 58.2021552 (new best train)
Epoch 12200 @ 1, LR: [0.001]: Train loss: 56.7521769, Test loss: 58.4649104 (new best train)
Epoch 12300 @ 1, LR: [0.001]: Train loss: 56.7167839, Test loss: 57.1975909 (new best train)
Epoch 12400 @ 1, LR: [0.001]: Train loss: 56.6838351, Test loss: 59.3248177 (new best train)
Epoch 12500 @ 1, LR: [0.001]: Train loss: 56.5880999, Test loss: 58.8771087 (new best train)
Epoch 12600 @ 1, LR: [0.001]: Train loss: 56.5306904, Test loss: 57.4179670 (new best train)
Epoch 12700 @ 1, LR: [0.001]: Train loss: 56.5176139, Test loss: 57.5059355 (new best train)
Epoch 12800 @ 1, LR: [0.001]: Train loss: 56.4191653, Test loss: 58.2043775 (new best train)
Epoch 12900 @ 1, LR: [0.001]: Train loss: 56.3354291, Test loss: 57.2353619 (new best train)
Epoch 13000 @ 1, LR: [0.001]: Train loss: 56.3665319, Test loss: 56.8972523
Epoch 13100 @ 1, LR: [0.001]: Train loss: 56.2747161, Test loss: 58.2009520 (new best train)
Epoch 13200 @ 1, LR: [0.001]: Train loss: 56.2321887, Test loss: 57.1244515 (new best train)
Epoch 13300 @ 1, LR: [0.001]: Train loss: 56.2031558, Test loss: 57.8128365 (new best train)
Epoch 13400 @ 1, LR: [0.001]: Train loss: 56.1567789, Test loss: 57.5767787 (new best train)
Epoch 13500 @ 1, LR: [0.001]: Train loss: 56.1130037, Test loss: 57.2510729 (new best train)
Epoch 13600 @ 1, LR: [0.001]: Train loss: 56.0038393, Test loss: 57.8052237 (new best train)
Epoch 13700 @ 1, LR: [0.001]: Train loss: 55.9363759, Test loss: 56.9183802 (new best train)
Epoch 13800 @ 1, LR: [0.001]: Train loss: 55.8527063, Test loss: 57.1111794 (new best train)
Epoch 13900 @ 1, LR: [0.001]: Train loss: 55.8795234, Test loss: 56.4397010
Epoch 14000 @ 1, LR: [0.001]: Train loss: 55.7884311, Test loss: 56.6937372 (new best train)
Epoch 14100 @ 1, LR: [0.001]: Train loss: 55.7551407, Test loss: 58.7503969 (new best train)
Epoch 14200 @ 1, LR: [0.001]: Train loss: 55.6936978, Test loss: 56.8123840 (new best train)
Epoch 14300 @ 1, LR: [0.001]: Train loss: 55.6399633, Test loss: 57.6417016 (new best train)
Epoch 14400 @ 1, LR: [0.001]: Train loss: 55.6392252, Test loss: 57.1305811 (new best train)
Epoch 14500 @ 1, LR: [0.001]: Train loss: 55.5482854, Test loss: 59.6332690 (new best train)
Epoch 14600 @ 1, LR: [0.001]: Train loss: 55.5313958, Test loss: 56.4096706 (new best train)
Epoch 14700 @ 1, LR: [0.001]: Train loss: 55.3901498, Test loss: 56.7665248 (new best train)
Epoch 14800 @ 1, LR: [0.001]: Train loss: 55.3265987, Test loss: 58.3515187 (new best train)
Epoch 14900 @ 1, LR: [0.001]: Train loss: 55.3382457, Test loss: 56.2719894
Epoch 15000 @ 1, LR: [0.001]: Train loss: 55.2423670, Test loss: 56.7429145 (new best train)
Epoch 15100 @ 1, LR: [0.001]: Train loss: 55.2510217, Test loss: 56.4595620
Epoch 15200 @ 1, LR: [0.001]: Train loss: 55.1322211, Test loss: 56.6561590 (new best train)
Epoch 15300 @ 1, LR: [0.001]: Train loss: 55.0964152, Test loss: 56.4263634 (new best train)
Epoch 15400 @ 1, LR: [0.001]: Train loss: 55.0665602, Test loss: 56.9763932 (new best train)
Epoch 15500 @ 1, LR: [0.001]: Train loss: 55.0299135, Test loss: 56.3282715 (new best train)
Epoch 15600 @ 1, LR: [0.001]: Train loss: 54.9464019, Test loss: 56.2898288 (new best train)
Epoch 15700 @ 1, LR: [0.001]: Train loss: 54.9192427, Test loss: 55.8787967 (new best train)
Epoch 15800 @ 1, LR: [0.001]: Train loss: 54.8230920, Test loss: 56.0797609 (new best train)
Epoch 15900 @ 1, LR: [0.001]: Train loss: 54.8032598, Test loss: 55.6275812 (new best train)
Epoch 16000 @ 1, LR: [0.001]: Train loss: 54.7794986, Test loss: 56.1399580 (new best train)
Epoch 16100 @ 1, LR: [0.001]: Train loss: 54.7510359, Test loss: 57.7899532 (new best train)
Epoch 16200 @ 1, LR: [0.001]: Train loss: 54.6352344, Test loss: 55.9448729 (new best train)
Epoch 16300 @ 1, LR: [0.001]: Train loss: 54.6399891, Test loss: 56.7874469
Epoch 16400 @ 1, LR: [0.001]: Train loss: 54.5284714, Test loss: 56.2244593 (new best train)
Epoch 16500 @ 1, LR: [0.001]: Train loss: 54.4810811, Test loss: 56.0557731 (new best train)
Epoch 16600 @ 1, LR: [0.001]: Train loss: 54.4256704, Test loss: 56.1354624 (new best train)
Epoch 16700 @ 1, LR: [0.001]: Train loss: 54.3397589, Test loss: 56.7949813 (new best train)
Epoch 16800 @ 1, LR: [0.001]: Train loss: 54.3181728, Test loss: 58.4310777 (new best train)
Epoch 16900 @ 1, LR: [0.001]: Train loss: 54.2743363, Test loss: 56.3305965 (new best train)
Epoch 17000 @ 1, LR: [0.001]: Train loss: 54.2015199, Test loss: 55.2176943 (new best train)
Epoch 17100 @ 1, LR: [0.001]: Train loss: 54.2107514, Test loss: 55.4496135
Epoch 17200 @ 1, LR: [0.001]: Train loss: 54.0599518, Test loss: 56.6313566 (new best train)
Epoch 17300 @ 1, LR: [0.001]: Train loss: 54.0740124, Test loss: 55.0271650
Epoch 17400 @ 1, LR: [0.001]: Train loss: 54.0327954, Test loss: 55.5552605 (new best train)
Epoch 17500 @ 1, LR: [0.001]: Train loss: 53.9983706, Test loss: 55.0420767 (new best train)
Epoch 17600 @ 1, LR: [0.001]: Train loss: 53.9037309, Test loss: 55.1065351 (new best train)
Epoch 17700 @ 1, LR: [0.001]: Train loss: 53.8733784, Test loss: 55.1719123 (new best train)
Epoch 17800 @ 1, LR: [0.001]: Train loss: 53.8546340, Test loss: 55.1472896 (new best train)
Epoch 17900 @ 1, LR: [0.001]: Train loss: 53.7742410, Test loss: 54.8775338 (new best train)
Epoch 18000 @ 1, LR: [0.001]: Train loss: 53.7452814, Test loss: 54.5932674 (new best train)
Epoch 18100 @ 1, LR: [0.001]: Train loss: 53.6881215, Test loss: 54.5866678 (new best train)
Epoch 18200 @ 1, LR: [0.001]: Train loss: 53.6797643, Test loss: 55.7543585 (new best train)
Epoch 18300 @ 1, LR: [0.001]: Train loss: 53.6505457, Test loss: 56.2627303 (new best train)
Epoch 18400 @ 1, LR: [0.001]: Train loss: 53.5515473, Test loss: 55.1596725 (new best train)
Epoch 18500 @ 1, LR: [0.001]: Train loss: 53.5455042, Test loss: 54.9129859 (new best train)
Epoch 18600 @ 1, LR: [0.001]: Train loss: 53.4722733, Test loss: 55.1322548 (new best train)
Epoch 18700 @ 1, LR: [0.001]: Train loss: 53.4088979, Test loss: 54.7227250 (new best train)
Epoch 18800 @ 1, LR: [0.001]: Train loss: 53.3853256, Test loss: 54.6499213 (new best train)
Epoch 18900 @ 1, LR: [0.001]: Train loss: 53.3729737, Test loss: 54.8156362 (new best train)
Epoch 19000 @ 1, LR: [0.001]: Train loss: 53.3109369, Test loss: 55.1064670 (new best train)
Epoch 19100 @ 1, LR: [0.001]: Train loss: 53.2714197, Test loss: 55.3108249 (new best train)
Epoch 19200 @ 1, LR: [0.001]: Train loss: 53.2906408, Test loss: 54.3692189
Epoch 19300 @ 1, LR: [0.001]: Train loss: 53.1921619, Test loss: 55.7264059 (new best train)
Epoch 19400 @ 1, LR: [0.001]: Train loss: 53.1859585, Test loss: 55.0871432 (new best train)
Epoch 19500 @ 1, LR: [0.001]: Train loss: 53.0898764, Test loss: 54.1823162 (new best train)
Epoch 19600 @ 1, LR: [0.001]: Train loss: 53.0628122, Test loss: 56.7545830 (new best train)
Epoch 19700 @ 1, LR: [0.001]: Train loss: 53.0346988, Test loss: 55.1984088 (new best train)
Epoch 19800 @ 1, LR: [0.001]: Train loss: 53.0300764, Test loss: 54.1478088 (new best train)
Epoch 19900 @ 1, LR: [0.001]: Train loss: 52.9905338, Test loss: 54.4084171 (new best train)
Epoch 20000 @ 1, LR: [0.001]: Train loss: 52.9138944, Test loss: 54.3650838 (new best train)
Epoch 20100 @ 1, LR: [0.001]: Train loss: 52.9018991, Test loss: 56.5402934 (new best train)
Epoch 20200 @ 1, LR: [0.001]: Train loss: 52.8330561, Test loss: 54.4456257 (new best train)
Epoch 20300 @ 1, LR: [0.001]: Train loss: 52.8057879, Test loss: 54.5647977 (new best train)
Epoch 20400 @ 1, LR: [0.001]: Train loss: 52.7744395, Test loss: 54.2982655 (new best train)
Epoch 20500 @ 1, LR: [0.001]: Train loss: 52.7552454, Test loss: 56.4352210 (new best train)
Epoch 20600 @ 1, LR: [0.001]: Train loss: 52.6849624, Test loss: 54.5621883 (new best train)
Epoch 20700 @ 1, LR: [0.001]: Train loss: 52.6948162, Test loss: 53.9649504
Epoch 20800 @ 1, LR: [0.001]: Train loss: 52.6500534, Test loss: 55.9808692 (new best train)
Epoch 20900 @ 1, LR: [0.001]: Train loss: 52.5637063, Test loss: 53.9884336 (new best train)
Epoch 21000 @ 1, LR: [0.001]: Train loss: 52.5558191, Test loss: 53.9823335 (new best train)
Epoch 21100 @ 1, LR: [0.001]: Train loss: 52.5903838, Test loss: 53.6939005
Epoch 21200 @ 1, LR: [0.001]: Train loss: 52.5275414, Test loss: 54.9773152 (new best train)
Epoch 21300 @ 1, LR: [0.001]: Train loss: 52.4950647, Test loss: 54.6329198 (new best train)
Epoch 21400 @ 1, LR: [0.001]: Train loss: 52.4262198, Test loss: 53.5424855 (new best train)
Epoch 21500 @ 1, LR: [0.001]: Train loss: 52.4087045, Test loss: 53.7931492 (new best train)
Epoch 21600 @ 1, LR: [0.001]: Train loss: 52.3509714, Test loss: 53.8745253 (new best train)
Epoch 21700 @ 1, LR: [0.001]: Train loss: 52.2967298, Test loss: 53.6427776 (new best train)
Epoch 21800 @ 1, LR: [0.001]: Train loss: 52.2876690, Test loss: 53.8320955 (new best train)
Epoch 21900 @ 1, LR: [0.001]: Train loss: 52.2519899, Test loss: 53.8508226 (new best train)
Epoch 22000 @ 1, LR: [0.001]: Train loss: 52.2149958, Test loss: 53.7103607 (new best train)
Epoch 22100 @ 1, LR: [0.001]: Train loss: 52.1767051, Test loss: 53.8134721 (new best train)
Epoch 22200 @ 1, LR: [0.001]: Train loss: 52.1920754, Test loss: 53.5943629
Epoch 22300 @ 1, LR: [0.001]: Train loss: 52.1236370, Test loss: 53.9095003 (new best train)
Epoch 22400 @ 1, LR: [0.001]: Train loss: 52.1083663, Test loss: 55.1704028 (new best train)
Epoch 22500 @ 1, LR: [0.001]: Train loss: 52.0894781, Test loss: 55.0743756 (new best train)
Epoch 22600 @ 1, LR: [0.001]: Train loss: 52.0644830, Test loss: 54.2951616 (new best train)
Epoch 22700 @ 1, LR: [0.001]: Train loss: 52.0241766, Test loss: 53.9017860 (new best train)
Epoch 22800 @ 1, LR: [0.001]: Train loss: 51.9504670, Test loss: 54.6356820 (new best train)
Epoch 22900 @ 1, LR: [0.001]: Train loss: 51.9034208, Test loss: 53.7748927 (new best train)
Epoch 23000 @ 1, LR: [0.001]: Train loss: 51.8918741, Test loss: 53.2098086 (new best train)
Epoch 23100 @ 1, LR: [0.001]: Train loss: 51.8601957, Test loss: 53.8450112 (new best train)
Epoch 23200 @ 1, LR: [0.001]: Train loss: 51.8040175, Test loss: 53.8851407 (new best train)
Epoch 23300 @ 1, LR: [0.001]: Train loss: 51.8122841, Test loss: 53.8117268
Epoch 23400 @ 1, LR: [0.001]: Train loss: 51.7544974, Test loss: 53.9424939 (new best train)
Epoch 23500 @ 1, LR: [0.001]: Train loss: 51.7219891, Test loss: 54.4798053 (new best train)
Epoch 23600 @ 1, LR: [0.001]: Train loss: 51.6835648, Test loss: 53.1227843 (new best train)
Epoch 23700 @ 1, LR: [0.001]: Train loss: 51.6771158, Test loss: 53.2634855 (new best train)
Epoch 23800 @ 1, LR: [0.001]: Train loss: 51.6620034, Test loss: 53.2766002 (new best train)
Epoch 23900 @ 1, LR: [0.001]: Train loss: 51.6000399, Test loss: 53.2072101 (new best train)
Epoch 24000 @ 1, LR: [0.001]: Train loss: 51.5885893, Test loss: 52.8347820 (new best train)
Epoch 24100 @ 1, LR: [0.001]: Train loss: 51.5101051, Test loss: 53.2068349 (new best train)
Epoch 24200 @ 1, LR: [0.001]: Train loss: 51.4906214, Test loss: 52.9501502 (new best train)
Epoch 24300 @ 1, LR: [0.001]: Train loss: 51.4923964, Test loss: 53.8361258
Epoch 24400 @ 1, LR: [0.001]: Train loss: 51.4408701, Test loss: 53.4515082 (new best train)
Epoch 24500 @ 1, LR: [0.001]: Train loss: 51.3865435, Test loss: 53.5354452 (new best train)
Epoch 24600 @ 1, LR: [0.001]: Train loss: 51.3494094, Test loss: 53.9316658 (new best train)
Epoch 24700 @ 1, LR: [0.001]: Train loss: 51.3122536, Test loss: 52.8364621 (new best train)
Epoch 24800 @ 1, LR: [0.001]: Train loss: 51.2701213, Test loss: 53.1117633 (new best train)
Epoch 24900 @ 1, LR: [0.001]: Train loss: 51.2752558, Test loss: 53.7510949
Epoch 25000 @ 1, LR: [0.001]: Train loss: 51.2211855, Test loss: 53.3265668 (new best train)
Epoch 25100 @ 1, LR: [0.001]: Train loss: 51.1904473, Test loss: 52.6349895 (new best train)
Epoch 25200 @ 1, LR: [0.001]: Train loss: 51.1699944, Test loss: 53.8246201 (new best train)
Epoch 25300 @ 1, LR: [0.001]: Train loss: 51.1475355, Test loss: 54.2727877 (new best train)
Epoch 25400 @ 1, LR: [0.001]: Train loss: 51.0705902, Test loss: 52.2344534 (new best train)
Epoch 25500 @ 1, LR: [0.001]: Train loss: 51.0316427, Test loss: 52.5792892 (new best train)
Epoch 25600 @ 1, LR: [0.001]: Train loss: 51.0000239, Test loss: 52.5144081 (new best train)
Epoch 25700 @ 1, LR: [0.001]: Train loss: 50.9762122, Test loss: 52.1476353 (new best train)
Epoch 25800 @ 1, LR: [0.001]: Train loss: 50.9621453, Test loss: 52.8695840 (new best train)
Epoch 25900 @ 1, LR: [0.001]: Train loss: 50.9138203, Test loss: 52.3211112 (new best train)
Epoch 26000 @ 1, LR: [0.001]: Train loss: 50.9015665, Test loss: 52.6296218 (new best train)
Epoch 26100 @ 1, LR: [0.001]: Train loss: 50.8671253, Test loss: 52.4706203 (new best train)
Epoch 26200 @ 1, LR: [0.001]: Train loss: 50.8306811, Test loss: 52.5849827 (new best train)
Epoch 26300 @ 1, LR: [0.001]: Train loss: 50.7669456, Test loss: 52.3268354 (new best train)
Epoch 26400 @ 1, LR: [0.001]: Train loss: 50.7518747, Test loss: 52.8888674 (new best train)
Epoch 26500 @ 1, LR: [0.001]: Train loss: 50.7278614, Test loss: 53.1968680 (new best train)
Epoch 26600 @ 1, LR: [0.001]: Train loss: 50.6835619, Test loss: 52.0991967 (new best train)
Epoch 26700 @ 1, LR: [0.001]: Train loss: 50.6816996, Test loss: 52.2985360 (new best train)
Epoch 26800 @ 1, LR: [0.001]: Train loss: 50.6170823, Test loss: 52.8610899 (new best train)
Epoch 26900 @ 1, LR: [0.001]: Train loss: 50.5898679, Test loss: 52.8371375 (new best train)
Epoch 27000 @ 1, LR: [0.001]: Train loss: 50.5501592, Test loss: 52.4350912 (new best train)
Epoch 27100 @ 1, LR: [0.001]: Train loss: 50.5226342, Test loss: 51.9294848 (new best train)
Epoch 27200 @ 1, LR: [0.001]: Train loss: 50.4994232, Test loss: 53.2821508 (new best train)
Epoch 27300 @ 1, LR: [0.001]: Train loss: 50.4516936, Test loss: 52.1177747 (new best train)
Epoch 27400 @ 1, LR: [0.001]: Train loss: 50.4149987, Test loss: 53.8317830 (new best train)
Epoch 27500 @ 1, LR: [0.001]: Train loss: 50.3888988, Test loss: 52.5565682 (new best train)
Epoch 27600 @ 1, LR: [0.001]: Train loss: 50.3705458, Test loss: 52.2791328 (new best train)
Epoch 27700 @ 1, LR: [0.001]: Train loss: 50.3493113, Test loss: 54.3263614 (new best train)
Epoch 27800 @ 1, LR: [0.001]: Train loss: 50.3134808, Test loss: 52.0666487 (new best train)
Epoch 27900 @ 1, LR: [0.001]: Train loss: 50.2778362, Test loss: 52.6725571 (new best train)
Epoch 28000 @ 1, LR: [0.001]: Train loss: 50.2328181, Test loss: 53.0434199 (new best train)
Epoch 28100 @ 1, LR: [0.001]: Train loss: 50.2252136, Test loss: 52.3740660 (new best train)
Epoch 28200 @ 1, LR: [0.001]: Train loss: 50.1672894, Test loss: 51.7870478 (new best train)
Epoch 28300 @ 1, LR: [0.001]: Train loss: 50.1182482, Test loss: 52.4483521 (new best train)
Epoch 28400 @ 1, LR: [0.001]: Train loss: 50.1304173, Test loss: 51.5638392
Epoch 28500 @ 1, LR: [0.001]: Train loss: 50.0663725, Test loss: 53.6193063 (new best train)
Epoch 28600 @ 1, LR: [0.001]: Train loss: 50.0671237, Test loss: 51.7102469
Epoch 28700 @ 1, LR: [0.001]: Train loss: 50.0388238, Test loss: 52.4374164 (new best train)
Epoch 28800 @ 1, LR: [0.001]: Train loss: 50.0091594, Test loss: 51.9742728 (new best train)
Epoch 28900 @ 1, LR: [0.001]: Train loss: 49.9338682, Test loss: 51.9130506 (new best train)
Epoch 29000 @ 1, LR: [0.001]: Train loss: 49.9526081, Test loss: 51.3632783
Epoch 29100 @ 1, LR: [0.001]: Train loss: 49.9065664, Test loss: 51.6996524 (new best train)
Epoch 29200 @ 1, LR: [0.001]: Train loss: 49.9036563, Test loss: 51.7734324 (new best train)
Epoch 29300 @ 1, LR: [0.001]: Train loss: 49.8060496, Test loss: 51.7420251 (new best train)
Epoch 29400 @ 1, LR: [0.001]: Train loss: 49.8014901, Test loss: 54.2247373 (new best train)
Epoch 29500 @ 1, LR: [0.001]: Train loss: 49.7751778, Test loss: 51.3252535 (new best train)
Epoch 29600 @ 1, LR: [0.001]: Train loss: 49.7471041, Test loss: 51.2971918 (new best train)
Epoch 29700 @ 1, LR: [0.001]: Train loss: 49.6783063, Test loss: 51.7000054 (new best train)
Epoch 29800 @ 1, LR: [0.001]: Train loss: 49.6634462, Test loss: 51.1849672 (new best train)
Epoch 29900 @ 1, LR: [0.001]: Train loss: 49.6390527, Test loss: 51.8458204 (new best train)
Epoch 30000 @ 1, LR: [0.001]: Train loss: 49.6062441, Test loss: 51.6584377 (new best train)
Best train perf: 49.60624406722, epoch: 30000
Fold 1 completed
Epoch 100 @ 2, LR: [0.001]: Train loss: 1504.7015046, Test loss: 164.5482997 (new best train)
Epoch 200 @ 2, LR: [0.001]: Train loss: 142.8924420, Test loss: 131.3253535 (new best train)
Epoch 300 @ 2, LR: [0.001]: Train loss: 100.2769832, Test loss: 90.3299940 (new best train)
Epoch 400 @ 2, LR: [0.001]: Train loss: 85.0548280, Test loss: 81.9760514 (new best train)
Epoch 500 @ 2, LR: [0.001]: Train loss: 80.5722377, Test loss: 77.8464160 (new best train)
Epoch 600 @ 2, LR: [0.001]: Train loss: 77.9957226, Test loss: 82.2609693 (new best train)
Epoch 700 @ 2, LR: [0.001]: Train loss: 76.2138894, Test loss: 76.5095854 (new best train)
Epoch 800 @ 2, LR: [0.001]: Train loss: 74.9726810, Test loss: 74.1995588 (new best train)
Epoch 900 @ 2, LR: [0.001]: Train loss: 74.3251171, Test loss: 72.3706985 (new best train)
Epoch 1000 @ 2, LR: [0.001]: Train loss: 73.1117656, Test loss: 77.1770495 (new best train)
Epoch 1100 @ 2, LR: [0.001]: Train loss: 72.7432142, Test loss: 77.6344034 (new best train)
Epoch 1200 @ 2, LR: [0.001]: Train loss: 71.9809860, Test loss: 71.0070353 (new best train)
Epoch 1300 @ 2, LR: [0.001]: Train loss: 71.4102581, Test loss: 71.0806294 (new best train)
Epoch 1400 @ 2, LR: [0.001]: Train loss: 70.9922152, Test loss: 69.5322220 (new best train)
Epoch 1500 @ 2, LR: [0.001]: Train loss: 70.5754648, Test loss: 71.6038966 (new best train)
Epoch 1600 @ 2, LR: [0.001]: Train loss: 70.2945078, Test loss: 71.5969438 (new best train)
Epoch 1700 @ 2, LR: [0.001]: Train loss: 69.8306096, Test loss: 68.8901630 (new best train)
Epoch 1800 @ 2, LR: [0.001]: Train loss: 69.5956441, Test loss: 68.7959864 (new best train)
Epoch 1900 @ 2, LR: [0.001]: Train loss: 69.2601949, Test loss: 68.1175782 (new best train)
Epoch 2000 @ 2, LR: [0.001]: Train loss: 69.0184308, Test loss: 69.0856737 (new best train)
Epoch 2100 @ 2, LR: [0.001]: Train loss: 68.8622295, Test loss: 69.7135619 (new best train)
Epoch 2200 @ 2, LR: [0.001]: Train loss: 68.4961360, Test loss: 67.7414826 (new best train)
Epoch 2300 @ 2, LR: [0.001]: Train loss: 68.2775686, Test loss: 72.1915059 (new best train)
Epoch 2400 @ 2, LR: [0.001]: Train loss: 67.9661064, Test loss: 68.1759888 (new best train)
Epoch 2500 @ 2, LR: [0.001]: Train loss: 67.8820293, Test loss: 67.3164238 (new best train)
Epoch 2600 @ 2, LR: [0.001]: Train loss: 67.7094402, Test loss: 67.1019539 (new best train)
Epoch 2700 @ 2, LR: [0.001]: Train loss: 67.5515794, Test loss: 69.4851433 (new best train)
Epoch 2800 @ 2, LR: [0.001]: Train loss: 67.3333183, Test loss: 67.6590807 (new best train)
Epoch 2900 @ 2, LR: [0.001]: Train loss: 67.1722634, Test loss: 66.8035793 (new best train)
Epoch 3000 @ 2, LR: [0.001]: Train loss: 67.0341655, Test loss: 66.6197092 (new best train)
Epoch 3100 @ 2, LR: [0.001]: Train loss: 66.9256774, Test loss: 66.3047098 (new best train)
Epoch 3200 @ 2, LR: [0.001]: Train loss: 66.7668875, Test loss: 67.3347805 (new best train)
Epoch 3300 @ 2, LR: [0.001]: Train loss: 66.6130215, Test loss: 66.4612761 (new best train)
Epoch 3400 @ 2, LR: [0.001]: Train loss: 66.5222252, Test loss: 66.1695077 (new best train)
Epoch 3500 @ 2, LR: [0.001]: Train loss: 66.4659087, Test loss: 67.4674411 (new best train)
Epoch 3600 @ 2, LR: [0.001]: Train loss: 66.4256200, Test loss: 66.0750629 (new best train)
Epoch 3700 @ 2, LR: [0.001]: Train loss: 66.2756977, Test loss: 65.7390758 (new best train)
Epoch 3800 @ 2, LR: [0.001]: Train loss: 66.1232284, Test loss: 65.7162845 (new best train)
Epoch 3900 @ 2, LR: [0.001]: Train loss: 66.0519684, Test loss: 66.2558250 (new best train)
Epoch 4000 @ 2, LR: [0.001]: Train loss: 66.0805381, Test loss: 66.6160286
Epoch 4100 @ 2, LR: [0.001]: Train loss: 65.8571423, Test loss: 67.2941619 (new best train)
Epoch 4200 @ 2, LR: [0.001]: Train loss: 65.7989089, Test loss: 65.6436143 (new best train)
Epoch 4300 @ 2, LR: [0.001]: Train loss: 65.7269528, Test loss: 67.6697408 (new best train)
Epoch 4400 @ 2, LR: [0.001]: Train loss: 65.6189592, Test loss: 66.5025817 (new best train)
Epoch 4500 @ 2, LR: [0.001]: Train loss: 65.5607957, Test loss: 65.5204306 (new best train)
Epoch 4600 @ 2, LR: [0.001]: Train loss: 65.4254035, Test loss: 65.6104707 (new best train)
Epoch 4700 @ 2, LR: [0.001]: Train loss: 65.3813200, Test loss: 66.2225221 (new best train)
Epoch 4800 @ 2, LR: [0.001]: Train loss: 65.3651654, Test loss: 65.2965297 (new best train)
Epoch 4900 @ 2, LR: [0.001]: Train loss: 65.4324271, Test loss: 65.5211236
Epoch 5000 @ 2, LR: [0.001]: Train loss: 65.1263293, Test loss: 65.5401498 (new best train)
Epoch 5100 @ 2, LR: [0.001]: Train loss: 65.1158794, Test loss: 64.8415901 (new best train)
Epoch 5200 @ 2, LR: [0.001]: Train loss: 64.9997796, Test loss: 65.3341758 (new best train)
Epoch 5300 @ 2, LR: [0.001]: Train loss: 64.9609438, Test loss: 65.3723620 (new best train)
Epoch 5400 @ 2, LR: [0.001]: Train loss: 64.9953305, Test loss: 65.0537065
Epoch 5500 @ 2, LR: [0.001]: Train loss: 64.8167018, Test loss: 65.3266416 (new best train)
Epoch 5600 @ 2, LR: [0.001]: Train loss: 64.7755438, Test loss: 65.2233886 (new best train)
Epoch 5700 @ 2, LR: [0.001]: Train loss: 64.6916195, Test loss: 64.9144891 (new best train)
Epoch 5800 @ 2, LR: [0.001]: Train loss: 64.6043606, Test loss: 64.9833630 (new best train)
Epoch 5900 @ 2, LR: [0.001]: Train loss: 64.7399668, Test loss: 65.9847580
Epoch 6000 @ 2, LR: [0.001]: Train loss: 64.5289866, Test loss: 64.8119923 (new best train)
Epoch 6100 @ 2, LR: [0.001]: Train loss: 64.4610877, Test loss: 64.3481368 (new best train)
Epoch 6200 @ 2, LR: [0.001]: Train loss: 64.3858533, Test loss: 64.4102094 (new best train)
Epoch 6300 @ 2, LR: [0.001]: Train loss: 64.3408601, Test loss: 65.9745207 (new best train)
Epoch 6400 @ 2, LR: [0.001]: Train loss: 64.3458986, Test loss: 64.8032319
Epoch 6500 @ 2, LR: [0.001]: Train loss: 64.2674028, Test loss: 64.4357897 (new best train)
Epoch 6600 @ 2, LR: [0.001]: Train loss: 64.2500822, Test loss: 64.1554912 (new best train)
Epoch 6700 @ 2, LR: [0.001]: Train loss: 64.1535139, Test loss: 64.4160938 (new best train)
Epoch 6800 @ 2, LR: [0.001]: Train loss: 64.1271292, Test loss: 63.9496648 (new best train)
Epoch 6900 @ 2, LR: [0.001]: Train loss: 64.0486961, Test loss: 64.1827340 (new best train)
Epoch 7000 @ 2, LR: [0.001]: Train loss: 64.0303481, Test loss: 64.2116274 (new best train)
Epoch 7100 @ 2, LR: [0.001]: Train loss: 63.9780659, Test loss: 64.2518345 (new best train)
Epoch 7200 @ 2, LR: [0.001]: Train loss: 63.9215352, Test loss: 64.0320361 (new best train)
Epoch 7300 @ 2, LR: [0.001]: Train loss: 63.9328384, Test loss: 63.9234334
Epoch 7400 @ 2, LR: [0.001]: Train loss: 63.8313130, Test loss: 63.8954517 (new best train)
Epoch 7500 @ 2, LR: [0.001]: Train loss: 63.8120949, Test loss: 64.7474947 (new best train)
Epoch 7600 @ 2, LR: [0.001]: Train loss: 63.7763606, Test loss: 64.6915351 (new best train)
Epoch 7700 @ 2, LR: [0.001]: Train loss: 63.7359323, Test loss: 63.7824928 (new best train)
Epoch 7800 @ 2, LR: [0.001]: Train loss: 63.6952351, Test loss: 64.4468924 (new best train)
Epoch 7900 @ 2, LR: [0.001]: Train loss: 63.6705100, Test loss: 64.0844127 (new best train)
Epoch 8000 @ 2, LR: [0.001]: Train loss: 63.6470469, Test loss: 64.0827282 (new best train)
Epoch 8100 @ 2, LR: [0.001]: Train loss: 63.5697950, Test loss: 64.8099461 (new best train)
Epoch 8200 @ 2, LR: [0.001]: Train loss: 63.5646854, Test loss: 63.4900089 (new best train)
Epoch 8300 @ 2, LR: [0.001]: Train loss: 63.5260211, Test loss: 64.5047311 (new best train)
Epoch 8400 @ 2, LR: [0.001]: Train loss: 63.5110268, Test loss: 64.4903880 (new best train)
Epoch 8500 @ 2, LR: [0.001]: Train loss: 63.4573621, Test loss: 66.9202499 (new best train)
Epoch 8600 @ 2, LR: [0.001]: Train loss: 63.4110794, Test loss: 63.4503227 (new best train)
Epoch 8700 @ 2, LR: [0.001]: Train loss: 63.3589743, Test loss: 63.8446749 (new best train)
Epoch 8800 @ 2, LR: [0.001]: Train loss: 63.3397872, Test loss: 64.1274575 (new best train)
Epoch 8900 @ 2, LR: [0.001]: Train loss: 63.2983678, Test loss: 63.6085682 (new best train)
Epoch 9000 @ 2, LR: [0.001]: Train loss: 63.2794799, Test loss: 63.8052705 (new best train)
Epoch 9100 @ 2, LR: [0.001]: Train loss: 63.2336744, Test loss: 63.5810706 (new best train)
Epoch 9200 @ 2, LR: [0.001]: Train loss: 63.2209528, Test loss: 64.1481365 (new best train)
Epoch 9300 @ 2, LR: [0.001]: Train loss: 63.1697898, Test loss: 63.9298368 (new best train)
Epoch 9400 @ 2, LR: [0.001]: Train loss: 63.1355485, Test loss: 63.3130549 (new best train)
Epoch 9500 @ 2, LR: [0.001]: Train loss: 63.0871287, Test loss: 63.6353505 (new best train)
Epoch 9600 @ 2, LR: [0.001]: Train loss: 63.0699312, Test loss: 63.3231446 (new best train)
Epoch 9700 @ 2, LR: [0.001]: Train loss: 63.0251256, Test loss: 63.0280937 (new best train)
Epoch 9800 @ 2, LR: [0.001]: Train loss: 63.0050403, Test loss: 63.9711415 (new best train)
Epoch 9900 @ 2, LR: [0.001]: Train loss: 62.9548516, Test loss: 63.4645644 (new best train)
Epoch 10000 @ 2, LR: [0.001]: Train loss: 62.9496909, Test loss: 63.0779114 (new best train)
Epoch 10100 @ 2, LR: [0.001]: Train loss: 62.9101003, Test loss: 63.4077348 (new best train)
Epoch 10200 @ 2, LR: [0.001]: Train loss: 62.8527509, Test loss: 63.1944532 (new best train)
Epoch 10300 @ 2, LR: [0.001]: Train loss: 62.8154753, Test loss: 63.8063697 (new best train)
Epoch 10400 @ 2, LR: [0.001]: Train loss: 62.8032832, Test loss: 63.0481827 (new best train)
Epoch 10500 @ 2, LR: [0.001]: Train loss: 62.7533919, Test loss: 63.4175066 (new best train)
Epoch 10600 @ 2, LR: [0.001]: Train loss: 62.7640662, Test loss: 63.3273470
Epoch 10700 @ 2, LR: [0.001]: Train loss: 62.7122935, Test loss: 63.5679569 (new best train)
Epoch 10800 @ 2, LR: [0.001]: Train loss: 62.6693222, Test loss: 64.2565965 (new best train)
Epoch 10900 @ 2, LR: [0.001]: Train loss: 62.6467966, Test loss: 62.8083286 (new best train)
Epoch 11000 @ 2, LR: [0.001]: Train loss: 62.6408642, Test loss: 62.6247950 (new best train)
Epoch 11100 @ 2, LR: [0.001]: Train loss: 62.5838757, Test loss: 62.7066290 (new best train)
Epoch 11200 @ 2, LR: [0.001]: Train loss: 62.5943757, Test loss: 63.4730771
Epoch 11300 @ 2, LR: [0.001]: Train loss: 62.5704568, Test loss: 63.8301520 (new best train)
Epoch 11400 @ 2, LR: [0.001]: Train loss: 62.5168980, Test loss: 63.9752799 (new best train)
Epoch 11500 @ 2, LR: [0.001]: Train loss: 62.4821437, Test loss: 62.9565888 (new best train)
Epoch 11600 @ 2, LR: [0.001]: Train loss: 62.4695972, Test loss: 62.5327536 (new best train)
Epoch 11700 @ 2, LR: [0.001]: Train loss: 62.4343464, Test loss: 63.0594717 (new best train)
Epoch 11800 @ 2, LR: [0.001]: Train loss: 62.4161506, Test loss: 62.7012758 (new best train)
Epoch 11900 @ 2, LR: [0.001]: Train loss: 62.3886797, Test loss: 63.0594526 (new best train)
Epoch 12000 @ 2, LR: [0.001]: Train loss: 62.3315837, Test loss: 62.9046401 (new best train)
Epoch 12100 @ 2, LR: [0.001]: Train loss: 62.3320333, Test loss: 64.2466165
Epoch 12200 @ 2, LR: [0.001]: Train loss: 62.3197628, Test loss: 62.6712159 (new best train)
Epoch 12300 @ 2, LR: [0.001]: Train loss: 62.2674269, Test loss: 62.4625662 (new best train)
Epoch 12400 @ 2, LR: [0.001]: Train loss: 62.2210128, Test loss: 62.3345313 (new best train)
Epoch 12500 @ 2, LR: [0.001]: Train loss: 62.2207241, Test loss: 62.5561151 (new best train)
Epoch 12600 @ 2, LR: [0.001]: Train loss: 62.2022513, Test loss: 64.1386478 (new best train)
Epoch 12700 @ 2, LR: [0.001]: Train loss: 62.1495485, Test loss: 62.3738384 (new best train)
Epoch 12800 @ 2, LR: [0.001]: Train loss: 62.0875000, Test loss: 62.3490769 (new best train)
Epoch 12900 @ 2, LR: [0.001]: Train loss: 62.0741605, Test loss: 62.3765277 (new best train)
Epoch 13000 @ 2, LR: [0.001]: Train loss: 62.0578405, Test loss: 63.1659604 (new best train)
Epoch 13100 @ 2, LR: [0.001]: Train loss: 62.0419923, Test loss: 62.1111385 (new best train)
Epoch 13200 @ 2, LR: [0.001]: Train loss: 62.0267618, Test loss: 62.3011634 (new best train)
Epoch 13300 @ 2, LR: [0.001]: Train loss: 61.9999401, Test loss: 62.0338107 (new best train)
Epoch 13400 @ 2, LR: [0.001]: Train loss: 61.9338512, Test loss: 62.2851343 (new best train)
Epoch 13500 @ 2, LR: [0.001]: Train loss: 61.9353713, Test loss: 63.1400434
Epoch 13600 @ 2, LR: [0.001]: Train loss: 61.9301801, Test loss: 62.2666967 (new best train)
Epoch 13700 @ 2, LR: [0.001]: Train loss: 61.8500843, Test loss: 62.3978485 (new best train)
Epoch 13800 @ 2, LR: [0.001]: Train loss: 61.8375953, Test loss: 62.0060924 (new best train)
Epoch 13900 @ 2, LR: [0.001]: Train loss: 61.8101057, Test loss: 62.6991222 (new best train)
Epoch 14000 @ 2, LR: [0.001]: Train loss: 61.8049790, Test loss: 62.1844522 (new best train)
Epoch 14100 @ 2, LR: [0.001]: Train loss: 61.7578467, Test loss: 62.2622120 (new best train)
Epoch 14200 @ 2, LR: [0.001]: Train loss: 61.7225753, Test loss: 62.1547528 (new best train)
Epoch 14300 @ 2, LR: [0.001]: Train loss: 61.6966717, Test loss: 62.5194860 (new best train)
Epoch 14400 @ 2, LR: [0.001]: Train loss: 61.6724308, Test loss: 62.3438681 (new best train)
Epoch 14500 @ 2, LR: [0.001]: Train loss: 61.6630958, Test loss: 62.4399114 (new best train)
Epoch 14600 @ 2, LR: [0.001]: Train loss: 61.6101729, Test loss: 62.8254969 (new best train)
Epoch 14700 @ 2, LR: [0.001]: Train loss: 61.5978767, Test loss: 61.7896251 (new best train)
Epoch 14800 @ 2, LR: [0.001]: Train loss: 61.5345870, Test loss: 63.5401361 (new best train)
Epoch 14900 @ 2, LR: [0.001]: Train loss: 61.5216164, Test loss: 62.8312626 (new best train)
Epoch 15000 @ 2, LR: [0.001]: Train loss: 61.5144723, Test loss: 61.6707381 (new best train)
Epoch 15100 @ 2, LR: [0.001]: Train loss: 61.4623301, Test loss: 63.2671877 (new best train)
Epoch 15200 @ 2, LR: [0.001]: Train loss: 61.4525020, Test loss: 62.1355449 (new best train)
Epoch 15300 @ 2, LR: [0.001]: Train loss: 61.3939818, Test loss: 62.1955785 (new best train)
Epoch 15400 @ 2, LR: [0.001]: Train loss: 61.3956789, Test loss: 61.6482577
Epoch 15500 @ 2, LR: [0.001]: Train loss: 61.3520514, Test loss: 62.6737867 (new best train)
Epoch 15600 @ 2, LR: [0.001]: Train loss: 61.3348507, Test loss: 61.6257303 (new best train)
Epoch 15700 @ 2, LR: [0.001]: Train loss: 61.2966146, Test loss: 61.9003391 (new best train)
Epoch 15800 @ 2, LR: [0.001]: Train loss: 61.2710111, Test loss: 61.5167307 (new best train)
Epoch 15900 @ 2, LR: [0.001]: Train loss: 61.2491696, Test loss: 61.5616149 (new best train)
Epoch 16000 @ 2, LR: [0.001]: Train loss: 61.1834660, Test loss: 62.1230676 (new best train)
Epoch 16100 @ 2, LR: [0.001]: Train loss: 61.1945233, Test loss: 61.3961037
Epoch 16200 @ 2, LR: [0.001]: Train loss: 61.1494719, Test loss: 61.8985972 (new best train)
Epoch 16300 @ 2, LR: [0.001]: Train loss: 61.1160562, Test loss: 61.5115545 (new best train)
Epoch 16400 @ 2, LR: [0.001]: Train loss: 61.0855034, Test loss: 61.8110986 (new best train)
Epoch 16500 @ 2, LR: [0.001]: Train loss: 61.0688162, Test loss: 61.3497472 (new best train)
Epoch 16600 @ 2, LR: [0.001]: Train loss: 61.0261797, Test loss: 61.3525224 (new best train)
Epoch 16700 @ 2, LR: [0.001]: Train loss: 60.9926933, Test loss: 61.1730151 (new best train)
Epoch 16800 @ 2, LR: [0.001]: Train loss: 60.9756155, Test loss: 61.1478695 (new best train)
Epoch 16900 @ 2, LR: [0.001]: Train loss: 60.9350285, Test loss: 61.6626495 (new best train)
Epoch 17000 @ 2, LR: [0.001]: Train loss: 60.9032823, Test loss: 61.8544893 (new best train)
Epoch 17100 @ 2, LR: [0.001]: Train loss: 60.8543557, Test loss: 61.2482038 (new best train)
Epoch 17200 @ 2, LR: [0.001]: Train loss: 60.8388335, Test loss: 61.4335884 (new best train)
Epoch 17300 @ 2, LR: [0.001]: Train loss: 60.7802539, Test loss: 60.9391099 (new best train)
Epoch 17400 @ 2, LR: [0.001]: Train loss: 60.7515897, Test loss: 60.8491712 (new best train)
Epoch 17500 @ 2, LR: [0.001]: Train loss: 60.7100315, Test loss: 63.0386280 (new best train)
Epoch 17600 @ 2, LR: [0.001]: Train loss: 60.6869066, Test loss: 61.0364537 (new best train)
Epoch 17700 @ 2, LR: [0.001]: Train loss: 60.6308664, Test loss: 61.6668370 (new best train)
Epoch 17800 @ 2, LR: [0.001]: Train loss: 60.5885373, Test loss: 60.8502108 (new best train)
Epoch 17900 @ 2, LR: [0.001]: Train loss: 60.5427374, Test loss: 60.5498344 (new best train)
Epoch 18000 @ 2, LR: [0.001]: Train loss: 60.5174381, Test loss: 60.5351227 (new best train)
Epoch 18100 @ 2, LR: [0.001]: Train loss: 60.4466478, Test loss: 61.6371179 (new best train)
Epoch 18200 @ 2, LR: [0.001]: Train loss: 60.4259712, Test loss: 60.8995775 (new best train)
Epoch 18300 @ 2, LR: [0.001]: Train loss: 60.3775621, Test loss: 60.5516963 (new best train)
Epoch 18400 @ 2, LR: [0.001]: Train loss: 60.3260535, Test loss: 60.5949800 (new best train)
Epoch 18500 @ 2, LR: [0.001]: Train loss: 60.2752919, Test loss: 60.6399395 (new best train)
Epoch 18600 @ 2, LR: [0.001]: Train loss: 60.2154876, Test loss: 60.5531790 (new best train)
Epoch 18700 @ 2, LR: [0.001]: Train loss: 60.1377396, Test loss: 60.9230961 (new best train)
Epoch 18800 @ 2, LR: [0.001]: Train loss: 60.0756701, Test loss: 60.6024578 (new best train)
Epoch 18900 @ 2, LR: [0.001]: Train loss: 60.0140455, Test loss: 61.5736504 (new best train)
Epoch 19000 @ 2, LR: [0.001]: Train loss: 59.9538902, Test loss: 60.2272507 (new best train)
Epoch 19100 @ 2, LR: [0.001]: Train loss: 59.8558686, Test loss: 61.1863656 (new best train)
Epoch 19200 @ 2, LR: [0.001]: Train loss: 59.7449289, Test loss: 60.4744655 (new best train)
Epoch 19300 @ 2, LR: [0.001]: Train loss: 59.6573517, Test loss: 60.1550963 (new best train)
Epoch 19400 @ 2, LR: [0.001]: Train loss: 59.5444011, Test loss: 59.5623268 (new best train)
Epoch 19500 @ 2, LR: [0.001]: Train loss: 59.3902900, Test loss: 59.2092445 (new best train)
Epoch 19600 @ 2, LR: [0.001]: Train loss: 59.1412147, Test loss: 60.3744497 (new best train)
Epoch 19700 @ 2, LR: [0.001]: Train loss: 58.9379111, Test loss: 60.3646940 (new best train)
Epoch 19800 @ 2, LR: [0.001]: Train loss: 58.5765245, Test loss: 61.5209328 (new best train)
Epoch 19900 @ 2, LR: [0.001]: Train loss: 58.1994444, Test loss: 59.3034776 (new best train)
Epoch 20000 @ 2, LR: [0.001]: Train loss: 57.9346387, Test loss: 57.6745005 (new best train)
Epoch 20100 @ 2, LR: [0.001]: Train loss: 57.7336445, Test loss: 57.6077581 (new best train)
Epoch 20200 @ 2, LR: [0.001]: Train loss: 57.3842228, Test loss: 58.0344723 (new best train)
Epoch 20300 @ 2, LR: [0.001]: Train loss: 57.1864443, Test loss: 57.8089775 (new best train)
Epoch 20400 @ 2, LR: [0.001]: Train loss: 57.0147143, Test loss: 57.2689540 (new best train)
Epoch 20500 @ 2, LR: [0.001]: Train loss: 56.7778938, Test loss: 57.0884229 (new best train)
Epoch 20600 @ 2, LR: [0.001]: Train loss: 56.6375115, Test loss: 56.7856611 (new best train)
Epoch 20700 @ 2, LR: [0.001]: Train loss: 56.4844168, Test loss: 56.3641553 (new best train)
Epoch 20800 @ 2, LR: [0.001]: Train loss: 56.3704944, Test loss: 56.1403924 (new best train)
Epoch 20900 @ 2, LR: [0.001]: Train loss: 56.1876022, Test loss: 55.9707986 (new best train)
Epoch 21000 @ 2, LR: [0.001]: Train loss: 56.0887190, Test loss: 56.1651817 (new best train)
Epoch 21100 @ 2, LR: [0.001]: Train loss: 55.9757350, Test loss: 56.0691415 (new best train)
Epoch 21200 @ 2, LR: [0.001]: Train loss: 55.8556584, Test loss: 55.2016826 (new best train)
Epoch 21300 @ 2, LR: [0.001]: Train loss: 55.8235109, Test loss: 56.6990563 (new best train)
Epoch 21400 @ 2, LR: [0.001]: Train loss: 55.6785603, Test loss: 58.3726307 (new best train)
Epoch 21500 @ 2, LR: [0.001]: Train loss: 55.5570955, Test loss: 55.9254543 (new best train)
Epoch 21600 @ 2, LR: [0.001]: Train loss: 55.5206438, Test loss: 56.7442007 (new best train)
Epoch 21700 @ 2, LR: [0.001]: Train loss: 55.3938858, Test loss: 54.9165940 (new best train)
Epoch 21800 @ 2, LR: [0.001]: Train loss: 55.3546733, Test loss: 55.1882941 (new best train)
Epoch 21900 @ 2, LR: [0.001]: Train loss: 55.2904609, Test loss: 56.0269541 (new best train)
Epoch 22000 @ 2, LR: [0.001]: Train loss: 55.1506235, Test loss: 57.6151087 (new best train)
Epoch 22100 @ 2, LR: [0.001]: Train loss: 55.1729128, Test loss: 54.6992917
Epoch 22200 @ 2, LR: [0.001]: Train loss: 54.9659755, Test loss: 56.5364114 (new best train)
Epoch 22300 @ 2, LR: [0.001]: Train loss: 55.0876412, Test loss: 58.6707503
Epoch 22400 @ 2, LR: [0.001]: Train loss: 54.9386422, Test loss: 55.1211456 (new best train)
Epoch 22500 @ 2, LR: [0.001]: Train loss: 54.8316959, Test loss: 56.4279200 (new best train)
Epoch 22600 @ 2, LR: [0.001]: Train loss: 54.7783228, Test loss: 56.0776226 (new best train)
Epoch 22700 @ 2, LR: [0.001]: Train loss: 54.6624857, Test loss: 55.2997105 (new best train)
Epoch 22800 @ 2, LR: [0.001]: Train loss: 54.6535955, Test loss: 58.0596618 (new best train)
Epoch 22900 @ 2, LR: [0.001]: Train loss: 54.6317187, Test loss: 54.4701863 (new best train)
Epoch 23000 @ 2, LR: [0.001]: Train loss: 54.5363752, Test loss: 55.2557803 (new best train)
Epoch 23100 @ 2, LR: [0.001]: Train loss: 54.3804865, Test loss: 54.2591656 (new best train)
Epoch 23200 @ 2, LR: [0.001]: Train loss: 54.3949519, Test loss: 55.4489503
Epoch 23300 @ 2, LR: [0.001]: Train loss: 54.4257890, Test loss: 56.3015003
Epoch 23400 @ 2, LR: [0.001]: Train loss: 54.3323598, Test loss: 54.9796865 (new best train)
Epoch 23500 @ 2, LR: [0.001]: Train loss: 54.2532664, Test loss: 54.8844088 (new best train)
Epoch 23600 @ 2, LR: [0.001]: Train loss: 54.2295093, Test loss: 54.9986507 (new best train)
Epoch 23700 @ 2, LR: [0.001]: Train loss: 54.1364474, Test loss: 54.6195230 (new best train)
Epoch 23800 @ 2, LR: [0.001]: Train loss: 54.0819258, Test loss: 55.0387117 (new best train)
Epoch 23900 @ 2, LR: [0.001]: Train loss: 54.1474365, Test loss: 54.2078178
Epoch 24000 @ 2, LR: [0.001]: Train loss: 53.9755160, Test loss: 54.1622341 (new best train)
Epoch 24100 @ 2, LR: [0.001]: Train loss: 53.8768684, Test loss: 54.2173934 (new best train)
Epoch 24200 @ 2, LR: [0.001]: Train loss: 53.8741437, Test loss: 54.3802955 (new best train)
Epoch 24300 @ 2, LR: [0.001]: Train loss: 53.8322496, Test loss: 56.0320713 (new best train)
Epoch 24400 @ 2, LR: [0.001]: Train loss: 53.7833289, Test loss: 54.3584482 (new best train)
Epoch 24500 @ 2, LR: [0.001]: Train loss: 53.7461050, Test loss: 53.9721557 (new best train)
Epoch 24600 @ 2, LR: [0.001]: Train loss: 53.7672495, Test loss: 53.8711159
Epoch 24700 @ 2, LR: [0.001]: Train loss: 53.6663330, Test loss: 54.3436959 (new best train)
Epoch 24800 @ 2, LR: [0.001]: Train loss: 53.6552997, Test loss: 54.2917423 (new best train)
Epoch 24900 @ 2, LR: [0.001]: Train loss: 53.5531582, Test loss: 54.0599376 (new best train)
Epoch 25000 @ 2, LR: [0.001]: Train loss: 53.5496108, Test loss: 55.0407317 (new best train)
Epoch 25100 @ 2, LR: [0.001]: Train loss: 53.4844829, Test loss: 55.5794650 (new best train)
Epoch 25200 @ 2, LR: [0.001]: Train loss: 53.3782690, Test loss: 54.1048696 (new best train)
Epoch 25300 @ 2, LR: [0.001]: Train loss: 53.3196093, Test loss: 53.7275428 (new best train)
Epoch 25400 @ 2, LR: [0.001]: Train loss: 53.3365775, Test loss: 53.6586002
Epoch 25500 @ 2, LR: [0.001]: Train loss: 53.2789530, Test loss: 53.5657357 (new best train)
Epoch 25600 @ 2, LR: [0.001]: Train loss: 53.2888642, Test loss: 53.9235145
Epoch 25700 @ 2, LR: [0.001]: Train loss: 53.1487069, Test loss: 53.7784043 (new best train)
Epoch 25800 @ 2, LR: [0.001]: Train loss: 53.0716212, Test loss: 54.1607373 (new best train)
Epoch 25900 @ 2, LR: [0.001]: Train loss: 53.1012925, Test loss: 52.9790497
Epoch 26000 @ 2, LR: [0.001]: Train loss: 52.9841272, Test loss: 54.5018444 (new best train)
Epoch 26100 @ 2, LR: [0.001]: Train loss: 52.9874222, Test loss: 57.2068819
Epoch 26200 @ 2, LR: [0.001]: Train loss: 52.9290419, Test loss: 54.0963168 (new best train)
Epoch 26300 @ 2, LR: [0.001]: Train loss: 52.8885405, Test loss: 52.9817233 (new best train)
Epoch 26400 @ 2, LR: [0.001]: Train loss: 52.7589145, Test loss: 55.6997414 (new best train)
Epoch 26500 @ 2, LR: [0.001]: Train loss: 52.7701288, Test loss: 53.0771288
Epoch 26600 @ 2, LR: [0.001]: Train loss: 52.7899382, Test loss: 53.9906344
Epoch 26700 @ 2, LR: [0.001]: Train loss: 52.6035435, Test loss: 53.3283641 (new best train)
Epoch 26800 @ 2, LR: [0.001]: Train loss: 52.6219703, Test loss: 53.3216086
Epoch 26900 @ 2, LR: [0.001]: Train loss: 52.5458988, Test loss: 56.2745614 (new best train)
Epoch 27000 @ 2, LR: [0.001]: Train loss: 52.4972808, Test loss: 54.3867218 (new best train)
Epoch 27100 @ 2, LR: [0.001]: Train loss: 52.4549524, Test loss: 53.2090089 (new best train)
Epoch 27200 @ 2, LR: [0.001]: Train loss: 52.3683642, Test loss: 54.0975837 (new best train)
Epoch 27300 @ 2, LR: [0.001]: Train loss: 52.3115901, Test loss: 52.6251727 (new best train)
Epoch 27400 @ 2, LR: [0.001]: Train loss: 52.3508691, Test loss: 53.3843502
Epoch 27500 @ 2, LR: [0.001]: Train loss: 52.2721420, Test loss: 56.7120350 (new best train)
Epoch 27600 @ 2, LR: [0.001]: Train loss: 52.2265929, Test loss: 54.8341918 (new best train)
Epoch 27700 @ 2, LR: [0.001]: Train loss: 52.2119956, Test loss: 52.7588773 (new best train)
Epoch 27800 @ 2, LR: [0.001]: Train loss: 52.0771337, Test loss: 52.7839530 (new best train)
Epoch 27900 @ 2, LR: [0.001]: Train loss: 52.0711583, Test loss: 53.6444704 (new best train)
Epoch 28000 @ 2, LR: [0.001]: Train loss: 51.9894778, Test loss: 53.2790974 (new best train)
Epoch 28100 @ 2, LR: [0.001]: Train loss: 51.9670362, Test loss: 54.7318062 (new best train)
Epoch 28200 @ 2, LR: [0.001]: Train loss: 51.9276173, Test loss: 54.6708760 (new best train)
Epoch 28300 @ 2, LR: [0.001]: Train loss: 51.8226925, Test loss: 54.1584251 (new best train)
Epoch 28400 @ 2, LR: [0.001]: Train loss: 51.7989207, Test loss: 55.0453742 (new best train)
Epoch 28500 @ 2, LR: [0.001]: Train loss: 51.7434725, Test loss: 52.4413798 (new best train)
Epoch 28600 @ 2, LR: [0.001]: Train loss: 51.6609869, Test loss: 53.4253120 (new best train)
Epoch 28700 @ 2, LR: [0.001]: Train loss: 51.6845915, Test loss: 53.2983909
Epoch 28800 @ 2, LR: [0.001]: Train loss: 51.6541682, Test loss: 53.4137078 (new best train)
Epoch 28900 @ 2, LR: [0.001]: Train loss: 51.5733602, Test loss: 53.3024827 (new best train)
Epoch 29000 @ 2, LR: [0.001]: Train loss: 51.4848832, Test loss: 51.8850195 (new best train)
Epoch 29100 @ 2, LR: [0.001]: Train loss: 51.5141478, Test loss: 52.3538038
Epoch 29200 @ 2, LR: [0.001]: Train loss: 51.4688126, Test loss: 53.4985851 (new best train)
Epoch 29300 @ 2, LR: [0.001]: Train loss: 51.3655577, Test loss: 52.4744448 (new best train)
Epoch 29400 @ 2, LR: [0.001]: Train loss: 51.3269004, Test loss: 53.2180873 (new best train)
Epoch 29500 @ 2, LR: [0.001]: Train loss: 51.3089489, Test loss: 52.7859902 (new best train)
Epoch 29600 @ 2, LR: [0.001]: Train loss: 51.2628144, Test loss: 51.7408862 (new best train)
Epoch 29700 @ 2, LR: [0.001]: Train loss: 51.2130466, Test loss: 52.4652234 (new best train)
Epoch 29800 @ 2, LR: [0.001]: Train loss: 51.1899268, Test loss: 52.0222198 (new best train)
Epoch 29900 @ 2, LR: [0.001]: Train loss: 51.1398436, Test loss: 52.0483829 (new best train)
Epoch 30000 @ 2, LR: [0.001]: Train loss: 51.0793818, Test loss: 52.8833424 (new best train)
Best train perf: 51.07938179959719, epoch: 30000
Fold 2 completed
Epoch 100 @ 3, LR: [0.001]: Train loss: 1442.9274368, Test loss: 157.9747973 (new best train)
Epoch 200 @ 3, LR: [0.001]: Train loss: 138.4856122, Test loss: 109.3340721 (new best train)
Epoch 300 @ 3, LR: [0.001]: Train loss: 91.5384199, Test loss: 90.9118694 (new best train)
Epoch 400 @ 3, LR: [0.001]: Train loss: 83.9122283, Test loss: 77.8750284 (new best train)
Epoch 500 @ 3, LR: [0.001]: Train loss: 80.4824298, Test loss: 79.2758005 (new best train)
Epoch 600 @ 3, LR: [0.001]: Train loss: 78.2242261, Test loss: 84.0315922 (new best train)
Epoch 700 @ 3, LR: [0.001]: Train loss: 76.6272327, Test loss: 74.6616413 (new best train)
Epoch 800 @ 3, LR: [0.001]: Train loss: 75.8062883, Test loss: 72.5024540 (new best train)
Epoch 900 @ 3, LR: [0.001]: Train loss: 74.9145867, Test loss: 70.8741893 (new best train)
Epoch 1000 @ 3, LR: [0.001]: Train loss: 74.0146976, Test loss: 70.3316498 (new best train)
Epoch 1100 @ 3, LR: [0.001]: Train loss: 73.4775653, Test loss: 75.3235571 (new best train)
Epoch 1200 @ 3, LR: [0.001]: Train loss: 72.9060099, Test loss: 70.4855730 (new best train)
Epoch 1300 @ 3, LR: [0.001]: Train loss: 72.3316544, Test loss: 71.9479005 (new best train)
Epoch 1400 @ 3, LR: [0.001]: Train loss: 71.8845693, Test loss: 69.0129857 (new best train)
Epoch 1500 @ 3, LR: [0.001]: Train loss: 71.4850680, Test loss: 71.0092940 (new best train)
Epoch 1600 @ 3, LR: [0.001]: Train loss: 71.0861062, Test loss: 69.3385463 (new best train)
Epoch 1700 @ 3, LR: [0.001]: Train loss: 70.6901386, Test loss: 68.8931880 (new best train)
Epoch 1800 @ 3, LR: [0.001]: Train loss: 70.4777983, Test loss: 74.8873436 (new best train)
Epoch 1900 @ 3, LR: [0.001]: Train loss: 70.2352575, Test loss: 67.1897859 (new best train)
Epoch 2000 @ 3, LR: [0.001]: Train loss: 69.9840887, Test loss: 67.8833496 (new best train)
Epoch 2100 @ 3, LR: [0.001]: Train loss: 69.7927523, Test loss: 66.6225134 (new best train)
Epoch 2200 @ 3, LR: [0.001]: Train loss: 69.3978887, Test loss: 66.5037968 (new best train)
Epoch 2300 @ 3, LR: [0.001]: Train loss: 69.2696586, Test loss: 68.1405352 (new best train)
Epoch 2400 @ 3, LR: [0.001]: Train loss: 69.0220986, Test loss: 67.7458367 (new best train)
Epoch 2500 @ 3, LR: [0.001]: Train loss: 68.8276659, Test loss: 65.8312708 (new best train)
Epoch 2600 @ 3, LR: [0.001]: Train loss: 68.6407379, Test loss: 65.8185027 (new best train)
Epoch 2700 @ 3, LR: [0.001]: Train loss: 68.4515454, Test loss: 65.8028321 (new best train)
Epoch 2800 @ 3, LR: [0.001]: Train loss: 68.2795540, Test loss: 66.3145523 (new best train)
Epoch 2900 @ 3, LR: [0.001]: Train loss: 68.2178450, Test loss: 66.3242890 (new best train)
Epoch 3000 @ 3, LR: [0.001]: Train loss: 67.9251282, Test loss: 65.3906862 (new best train)
Epoch 3100 @ 3, LR: [0.001]: Train loss: 67.9606829, Test loss: 66.4469914
Epoch 3200 @ 3, LR: [0.001]: Train loss: 67.6505575, Test loss: 66.2307482 (new best train)
Epoch 3300 @ 3, LR: [0.001]: Train loss: 67.5745424, Test loss: 66.8708133 (new best train)
Epoch 3400 @ 3, LR: [0.001]: Train loss: 67.4649707, Test loss: 66.6329303 (new best train)
Epoch 3500 @ 3, LR: [0.001]: Train loss: 67.3608858, Test loss: 65.5485288 (new best train)
Epoch 3600 @ 3, LR: [0.001]: Train loss: 67.3181560, Test loss: 65.1039203 (new best train)
Epoch 3700 @ 3, LR: [0.001]: Train loss: 67.1413836, Test loss: 70.3867365 (new best train)
Epoch 3800 @ 3, LR: [0.001]: Train loss: 67.0398000, Test loss: 65.5017605 (new best train)
Epoch 3900 @ 3, LR: [0.001]: Train loss: 66.9974755, Test loss: 65.7139641 (new best train)
Epoch 4000 @ 3, LR: [0.001]: Train loss: 66.9012107, Test loss: 65.2974910 (new best train)
Epoch 4100 @ 3, LR: [0.001]: Train loss: 66.8414726, Test loss: 64.7622989 (new best train)
Epoch 4200 @ 3, LR: [0.001]: Train loss: 66.7045373, Test loss: 66.0452954 (new best train)
Epoch 4300 @ 3, LR: [0.001]: Train loss: 66.6419525, Test loss: 64.5308640 (new best train)
Epoch 4400 @ 3, LR: [0.001]: Train loss: 66.5743725, Test loss: 64.5558723 (new best train)
Epoch 4500 @ 3, LR: [0.001]: Train loss: 66.4216237, Test loss: 64.6528847 (new best train)
Epoch 4600 @ 3, LR: [0.001]: Train loss: 66.4042585, Test loss: 64.3596896 (new best train)
Epoch 4700 @ 3, LR: [0.001]: Train loss: 66.2734602, Test loss: 66.2676464 (new best train)
Epoch 4800 @ 3, LR: [0.001]: Train loss: 66.2426473, Test loss: 63.9157440 (new best train)
Epoch 4900 @ 3, LR: [0.001]: Train loss: 66.1581305, Test loss: 63.8478464 (new best train)
Epoch 5000 @ 3, LR: [0.001]: Train loss: 66.0020166, Test loss: 63.9485637 (new best train)
Epoch 5100 @ 3, LR: [0.001]: Train loss: 65.9934490, Test loss: 64.4052790 (new best train)
Epoch 5200 @ 3, LR: [0.001]: Train loss: 65.8741086, Test loss: 63.5755985 (new best train)
Epoch 5300 @ 3, LR: [0.001]: Train loss: 65.8401917, Test loss: 64.1039131 (new best train)
Epoch 5400 @ 3, LR: [0.001]: Train loss: 65.7698961, Test loss: 64.3558144 (new best train)
Epoch 5500 @ 3, LR: [0.001]: Train loss: 65.6785773, Test loss: 65.9509810 (new best train)
Epoch 5600 @ 3, LR: [0.001]: Train loss: 65.6652503, Test loss: 64.7105586 (new best train)
Epoch 5700 @ 3, LR: [0.001]: Train loss: 65.5681439, Test loss: 63.5902164 (new best train)
Epoch 5800 @ 3, LR: [0.001]: Train loss: 65.5042349, Test loss: 63.9320926 (new best train)
Epoch 5900 @ 3, LR: [0.001]: Train loss: 65.4401187, Test loss: 69.2269457 (new best train)
Epoch 6000 @ 3, LR: [0.001]: Train loss: 65.3475647, Test loss: 64.5964891 (new best train)
Epoch 6100 @ 3, LR: [0.001]: Train loss: 65.3132818, Test loss: 67.0445599 (new best train)
Epoch 6200 @ 3, LR: [0.001]: Train loss: 65.2380259, Test loss: 63.5388426 (new best train)
Epoch 6300 @ 3, LR: [0.001]: Train loss: 65.2081027, Test loss: 63.3353140 (new best train)
Epoch 6400 @ 3, LR: [0.001]: Train loss: 65.1052811, Test loss: 63.1333105 (new best train)
Epoch 6500 @ 3, LR: [0.001]: Train loss: 65.0972047, Test loss: 63.7417710 (new best train)
Epoch 6600 @ 3, LR: [0.001]: Train loss: 65.0088785, Test loss: 63.5530316 (new best train)
Epoch 6700 @ 3, LR: [0.001]: Train loss: 64.9903565, Test loss: 64.1300720 (new best train)
Epoch 6800 @ 3, LR: [0.001]: Train loss: 64.9057572, Test loss: 64.7653890 (new best train)
Epoch 6900 @ 3, LR: [0.001]: Train loss: 64.8629892, Test loss: 63.2294092 (new best train)
Epoch 7000 @ 3, LR: [0.001]: Train loss: 64.8381751, Test loss: 63.2296924 (new best train)
Epoch 7100 @ 3, LR: [0.001]: Train loss: 64.7889907, Test loss: 62.8997292 (new best train)
Epoch 7200 @ 3, LR: [0.001]: Train loss: 64.7718514, Test loss: 62.9694874 (new best train)
Epoch 7300 @ 3, LR: [0.001]: Train loss: 64.6942819, Test loss: 63.3292615 (new best train)
Epoch 7400 @ 3, LR: [0.001]: Train loss: 64.6198877, Test loss: 62.7686749 (new best train)
Epoch 7500 @ 3, LR: [0.001]: Train loss: 64.5824927, Test loss: 63.2532031 (new best train)
Epoch 7600 @ 3, LR: [0.001]: Train loss: 64.5629233, Test loss: 62.6216554 (new best train)
Epoch 7700 @ 3, LR: [0.001]: Train loss: 64.4988984, Test loss: 63.3238756 (new best train)
Epoch 7800 @ 3, LR: [0.001]: Train loss: 64.4478975, Test loss: 62.9260022 (new best train)
Epoch 7900 @ 3, LR: [0.001]: Train loss: 64.4195640, Test loss: 64.2590327 (new best train)
Epoch 8000 @ 3, LR: [0.001]: Train loss: 64.3592388, Test loss: 62.3153992 (new best train)
Epoch 8100 @ 3, LR: [0.001]: Train loss: 64.3190890, Test loss: 62.6234087 (new best train)
Epoch 8200 @ 3, LR: [0.001]: Train loss: 64.2941304, Test loss: 62.2542005 (new best train)
Epoch 8300 @ 3, LR: [0.001]: Train loss: 64.2497569, Test loss: 62.4878233 (new best train)
Epoch 8400 @ 3, LR: [0.001]: Train loss: 64.1768144, Test loss: 62.9020737 (new best train)
Epoch 8500 @ 3, LR: [0.001]: Train loss: 64.1275521, Test loss: 62.1966883 (new best train)
Epoch 8600 @ 3, LR: [0.001]: Train loss: 64.1323186, Test loss: 62.1529478
Epoch 8700 @ 3, LR: [0.001]: Train loss: 64.0918927, Test loss: 62.5756613 (new best train)
Epoch 8800 @ 3, LR: [0.001]: Train loss: 64.0138050, Test loss: 61.9920672 (new best train)
Epoch 8900 @ 3, LR: [0.001]: Train loss: 64.0238473, Test loss: 62.2461290
Epoch 9000 @ 3, LR: [0.001]: Train loss: 63.9484089, Test loss: 62.3955780 (new best train)
Epoch 9100 @ 3, LR: [0.001]: Train loss: 63.9264767, Test loss: 62.4023101 (new best train)
Epoch 9200 @ 3, LR: [0.001]: Train loss: 63.8706973, Test loss: 62.8262090 (new best train)
Epoch 9300 @ 3, LR: [0.001]: Train loss: 63.8277424, Test loss: 61.9988867 (new best train)
Epoch 9400 @ 3, LR: [0.001]: Train loss: 63.8038662, Test loss: 62.5157835 (new best train)
Epoch 9500 @ 3, LR: [0.001]: Train loss: 63.7579878, Test loss: 65.6166986 (new best train)
Epoch 9600 @ 3, LR: [0.001]: Train loss: 63.7119075, Test loss: 62.7131306 (new best train)
Epoch 9700 @ 3, LR: [0.001]: Train loss: 63.6789997, Test loss: 62.1732905 (new best train)
Epoch 9800 @ 3, LR: [0.001]: Train loss: 63.6638034, Test loss: 62.0161656 (new best train)
Epoch 9900 @ 3, LR: [0.001]: Train loss: 63.6357570, Test loss: 61.9084918 (new best train)
Epoch 10000 @ 3, LR: [0.001]: Train loss: 63.5866414, Test loss: 61.5902235 (new best train)
Epoch 10100 @ 3, LR: [0.001]: Train loss: 63.5556710, Test loss: 62.9089321 (new best train)
Epoch 10200 @ 3, LR: [0.001]: Train loss: 63.5140743, Test loss: 61.7069548 (new best train)
Epoch 10300 @ 3, LR: [0.001]: Train loss: 63.4859527, Test loss: 62.1332936 (new best train)
Epoch 10400 @ 3, LR: [0.001]: Train loss: 63.4550439, Test loss: 61.8155120 (new best train)
Epoch 10500 @ 3, LR: [0.001]: Train loss: 63.4383845, Test loss: 61.7306567 (new best train)
Epoch 10600 @ 3, LR: [0.001]: Train loss: 63.3843949, Test loss: 61.6534889 (new best train)
Epoch 10700 @ 3, LR: [0.001]: Train loss: 63.3573331, Test loss: 61.9579074 (new best train)
Epoch 10800 @ 3, LR: [0.001]: Train loss: 63.3279521, Test loss: 61.8789185 (new best train)
Epoch 10900 @ 3, LR: [0.001]: Train loss: 63.2898442, Test loss: 62.4125130 (new best train)
Epoch 11000 @ 3, LR: [0.001]: Train loss: 63.2679024, Test loss: 61.7277125 (new best train)
Epoch 11100 @ 3, LR: [0.001]: Train loss: 63.2251880, Test loss: 63.1718800 (new best train)
Epoch 11200 @ 3, LR: [0.001]: Train loss: 63.1971234, Test loss: 61.6328184 (new best train)
Epoch 11300 @ 3, LR: [0.001]: Train loss: 63.1794170, Test loss: 61.9272297 (new best train)
Epoch 11400 @ 3, LR: [0.001]: Train loss: 63.1295741, Test loss: 61.3287859 (new best train)
Epoch 11500 @ 3, LR: [0.001]: Train loss: 63.0856130, Test loss: 61.6040232 (new best train)
Epoch 11600 @ 3, LR: [0.001]: Train loss: 63.0810712, Test loss: 61.6109697 (new best train)
Epoch 11700 @ 3, LR: [0.001]: Train loss: 63.0471427, Test loss: 61.3092424 (new best train)
Epoch 11800 @ 3, LR: [0.001]: Train loss: 63.0221291, Test loss: 61.5287647 (new best train)
Epoch 11900 @ 3, LR: [0.001]: Train loss: 62.9912102, Test loss: 61.4178871 (new best train)
Epoch 12000 @ 3, LR: [0.001]: Train loss: 62.9493799, Test loss: 63.0240279 (new best train)
Epoch 12100 @ 3, LR: [0.001]: Train loss: 62.9380585, Test loss: 62.1049174 (new best train)
Epoch 12200 @ 3, LR: [0.001]: Train loss: 62.9154586, Test loss: 61.7777242 (new best train)
Epoch 12300 @ 3, LR: [0.001]: Train loss: 62.8709432, Test loss: 61.4404196 (new best train)
Epoch 12400 @ 3, LR: [0.001]: Train loss: 62.8588896, Test loss: 61.1849945 (new best train)
Epoch 12500 @ 3, LR: [0.001]: Train loss: 62.8066809, Test loss: 61.0705972 (new best train)
Epoch 12600 @ 3, LR: [0.001]: Train loss: 62.7975958, Test loss: 61.0131702 (new best train)
Epoch 12700 @ 3, LR: [0.001]: Train loss: 62.7345208, Test loss: 61.1124221 (new best train)
Epoch 12800 @ 3, LR: [0.001]: Train loss: 62.7208584, Test loss: 61.1725641 (new best train)
Epoch 12900 @ 3, LR: [0.001]: Train loss: 62.6904821, Test loss: 60.9797772 (new best train)
Epoch 13000 @ 3, LR: [0.001]: Train loss: 62.6691279, Test loss: 61.2874478 (new best train)
Epoch 13100 @ 3, LR: [0.001]: Train loss: 62.6174407, Test loss: 60.8442292 (new best train)
Epoch 13200 @ 3, LR: [0.001]: Train loss: 62.6078778, Test loss: 60.9909602 (new best train)
Epoch 13300 @ 3, LR: [0.001]: Train loss: 62.5822964, Test loss: 60.6829739 (new best train)
Epoch 13400 @ 3, LR: [0.001]: Train loss: 62.5311947, Test loss: 61.1941533 (new best train)
Epoch 13500 @ 3, LR: [0.001]: Train loss: 62.5216212, Test loss: 61.1353714 (new best train)
Epoch 13600 @ 3, LR: [0.001]: Train loss: 62.4882788, Test loss: 60.6546851 (new best train)
Epoch 13700 @ 3, LR: [0.001]: Train loss: 62.4874330, Test loss: 61.2819906 (new best train)
Epoch 13800 @ 3, LR: [0.001]: Train loss: 62.4302251, Test loss: 60.8635321 (new best train)
Epoch 13900 @ 3, LR: [0.001]: Train loss: 62.4258858, Test loss: 60.4658012 (new best train)
Epoch 14000 @ 3, LR: [0.001]: Train loss: 62.3751459, Test loss: 60.8296135 (new best train)
Epoch 14100 @ 3, LR: [0.001]: Train loss: 62.3821062, Test loss: 60.5835807
Epoch 14200 @ 3, LR: [0.001]: Train loss: 62.3269599, Test loss: 61.2216355 (new best train)
Epoch 14300 @ 3, LR: [0.001]: Train loss: 62.3076920, Test loss: 60.9571778 (new best train)
Epoch 14400 @ 3, LR: [0.001]: Train loss: 62.2886873, Test loss: 60.7777315 (new best train)
Epoch 14500 @ 3, LR: [0.001]: Train loss: 62.2498628, Test loss: 61.2525273 (new best train)
Epoch 14600 @ 3, LR: [0.001]: Train loss: 62.2296984, Test loss: 60.8394369 (new best train)
Epoch 14700 @ 3, LR: [0.001]: Train loss: 62.1905579, Test loss: 61.0446241 (new best train)
Epoch 14800 @ 3, LR: [0.001]: Train loss: 62.1682227, Test loss: 60.4583973 (new best train)
Epoch 14900 @ 3, LR: [0.001]: Train loss: 62.1700437, Test loss: 61.1052716
Epoch 15000 @ 3, LR: [0.001]: Train loss: 62.1063243, Test loss: 60.6040903 (new best train)
Epoch 15100 @ 3, LR: [0.001]: Train loss: 62.0844528, Test loss: 60.5307516 (new best train)
Epoch 15200 @ 3, LR: [0.001]: Train loss: 62.0702422, Test loss: 60.7525015 (new best train)
Epoch 15300 @ 3, LR: [0.001]: Train loss: 62.0485451, Test loss: 61.2707672 (new best train)
Epoch 15400 @ 3, LR: [0.001]: Train loss: 62.0038706, Test loss: 61.1567518 (new best train)
Epoch 15500 @ 3, LR: [0.001]: Train loss: 61.9862497, Test loss: 60.1858466 (new best train)
Epoch 15600 @ 3, LR: [0.001]: Train loss: 61.9666079, Test loss: 60.4930254 (new best train)
Epoch 15700 @ 3, LR: [0.001]: Train loss: 61.9269442, Test loss: 60.5731752 (new best train)
Epoch 15800 @ 3, LR: [0.001]: Train loss: 61.9122001, Test loss: 60.4881489 (new best train)
Epoch 15900 @ 3, LR: [0.001]: Train loss: 61.8627007, Test loss: 60.1732575 (new best train)
Epoch 16000 @ 3, LR: [0.001]: Train loss: 61.8650348, Test loss: 60.2204968
Epoch 16100 @ 3, LR: [0.001]: Train loss: 61.8351904, Test loss: 60.5026556 (new best train)
Epoch 16200 @ 3, LR: [0.001]: Train loss: 61.8244828, Test loss: 60.9791470 (new best train)
Epoch 16300 @ 3, LR: [0.001]: Train loss: 61.7857734, Test loss: 60.2231608 (new best train)
Epoch 16400 @ 3, LR: [0.001]: Train loss: 61.7513678, Test loss: 60.6817535 (new best train)
Epoch 16500 @ 3, LR: [0.001]: Train loss: 61.7582588, Test loss: 60.1781790
Epoch 16600 @ 3, LR: [0.001]: Train loss: 61.6876137, Test loss: 60.2505004 (new best train)
Epoch 16700 @ 3, LR: [0.001]: Train loss: 61.6847954, Test loss: 60.6814477 (new best train)
Epoch 16800 @ 3, LR: [0.001]: Train loss: 61.6449265, Test loss: 60.4781097 (new best train)
Epoch 16900 @ 3, LR: [0.001]: Train loss: 61.6151368, Test loss: 60.1923183 (new best train)
Epoch 17000 @ 3, LR: [0.001]: Train loss: 61.6099135, Test loss: 59.7904002 (new best train)
Epoch 17100 @ 3, LR: [0.001]: Train loss: 61.5798246, Test loss: 60.7522256 (new best train)
Epoch 17200 @ 3, LR: [0.001]: Train loss: 61.5405441, Test loss: 59.9706366 (new best train)
Epoch 17300 @ 3, LR: [0.001]: Train loss: 61.5009697, Test loss: 61.3156227 (new best train)
Epoch 17400 @ 3, LR: [0.001]: Train loss: 61.4901900, Test loss: 59.6784377 (new best train)
Epoch 17500 @ 3, LR: [0.001]: Train loss: 61.4975390, Test loss: 59.8431921
Epoch 17600 @ 3, LR: [0.001]: Train loss: 61.4583639, Test loss: 60.5984221 (new best train)
Epoch 17700 @ 3, LR: [0.001]: Train loss: 61.3842472, Test loss: 59.7974744 (new best train)
Epoch 17800 @ 3, LR: [0.001]: Train loss: 61.3515281, Test loss: 59.7824429 (new best train)
Epoch 17900 @ 3, LR: [0.001]: Train loss: 61.3434729, Test loss: 60.1850583 (new best train)
Epoch 18000 @ 3, LR: [0.001]: Train loss: 61.3242345, Test loss: 60.0007408 (new best train)
Epoch 18100 @ 3, LR: [0.001]: Train loss: 61.2471275, Test loss: 59.7717878 (new best train)
Epoch 18200 @ 3, LR: [0.001]: Train loss: 61.2441491, Test loss: 60.8382230 (new best train)
Epoch 18300 @ 3, LR: [0.001]: Train loss: 61.2411120, Test loss: 60.9300558 (new best train)
Epoch 18400 @ 3, LR: [0.001]: Train loss: 61.1876471, Test loss: 59.7669405 (new best train)
Epoch 18500 @ 3, LR: [0.001]: Train loss: 61.1710838, Test loss: 59.3389424 (new best train)
Epoch 18600 @ 3, LR: [0.001]: Train loss: 61.1252648, Test loss: 59.5525713 (new best train)
Epoch 18700 @ 3, LR: [0.001]: Train loss: 61.0960568, Test loss: 61.1250223 (new best train)
Epoch 18800 @ 3, LR: [0.001]: Train loss: 61.0842462, Test loss: 60.1078250 (new best train)
Epoch 18900 @ 3, LR: [0.001]: Train loss: 61.0406675, Test loss: 59.9506353 (new best train)
Epoch 19000 @ 3, LR: [0.001]: Train loss: 60.9934032, Test loss: 59.5534210 (new best train)
Epoch 19100 @ 3, LR: [0.001]: Train loss: 60.9666972, Test loss: 59.6584183 (new best train)
Epoch 19200 @ 3, LR: [0.001]: Train loss: 60.9379355, Test loss: 59.2685723 (new best train)
Epoch 19300 @ 3, LR: [0.001]: Train loss: 60.9274120, Test loss: 59.2627115 (new best train)
Epoch 19400 @ 3, LR: [0.001]: Train loss: 60.8687831, Test loss: 59.4147667 (new best train)
Epoch 19500 @ 3, LR: [0.001]: Train loss: 60.8360292, Test loss: 59.6326208 (new best train)
Epoch 19600 @ 3, LR: [0.001]: Train loss: 60.8172668, Test loss: 61.5245933 (new best train)
Epoch 19700 @ 3, LR: [0.001]: Train loss: 60.7857634, Test loss: 59.7479403 (new best train)
Epoch 19800 @ 3, LR: [0.001]: Train loss: 60.7489313, Test loss: 59.4185170 (new best train)
Epoch 19900 @ 3, LR: [0.001]: Train loss: 60.7032465, Test loss: 59.3476402 (new best train)
Epoch 20000 @ 3, LR: [0.001]: Train loss: 60.6862034, Test loss: 59.2272810 (new best train)
Epoch 20100 @ 3, LR: [0.001]: Train loss: 60.6191302, Test loss: 59.4804260 (new best train)
Epoch 20200 @ 3, LR: [0.001]: Train loss: 60.6221807, Test loss: 59.4644313
Epoch 20300 @ 3, LR: [0.001]: Train loss: 60.5721228, Test loss: 58.9730467 (new best train)
Epoch 20400 @ 3, LR: [0.001]: Train loss: 60.5503882, Test loss: 59.5440674 (new best train)
Epoch 20500 @ 3, LR: [0.001]: Train loss: 60.5009804, Test loss: 59.1839939 (new best train)
Epoch 20600 @ 3, LR: [0.001]: Train loss: 60.4723333, Test loss: 59.2214176 (new best train)
Epoch 20700 @ 3, LR: [0.001]: Train loss: 60.4295663, Test loss: 58.8128818 (new best train)
Epoch 20800 @ 3, LR: [0.001]: Train loss: 60.3832745, Test loss: 59.0012286 (new best train)
Epoch 20900 @ 3, LR: [0.001]: Train loss: 60.3645730, Test loss: 58.9059558 (new best train)
Epoch 21000 @ 3, LR: [0.001]: Train loss: 60.3484446, Test loss: 59.6160804 (new best train)
Epoch 21100 @ 3, LR: [0.001]: Train loss: 60.2926056, Test loss: 58.8483025 (new best train)
Epoch 21200 @ 3, LR: [0.001]: Train loss: 60.2741907, Test loss: 59.3418255 (new best train)
Epoch 21300 @ 3, LR: [0.001]: Train loss: 60.2290584, Test loss: 59.0335227 (new best train)
Epoch 21400 @ 3, LR: [0.001]: Train loss: 60.1958596, Test loss: 59.4940023 (new best train)
Epoch 21500 @ 3, LR: [0.001]: Train loss: 60.1583959, Test loss: 58.6340880 (new best train)
Epoch 21600 @ 3, LR: [0.001]: Train loss: 60.1282414, Test loss: 59.8312779 (new best train)
Epoch 21700 @ 3, LR: [0.001]: Train loss: 60.0756271, Test loss: 59.0775500 (new best train)
Epoch 21800 @ 3, LR: [0.001]: Train loss: 60.0897067, Test loss: 59.1906772
Epoch 21900 @ 3, LR: [0.001]: Train loss: 60.0131917, Test loss: 58.4955675 (new best train)
Epoch 22000 @ 3, LR: [0.001]: Train loss: 59.9684210, Test loss: 59.7263984 (new best train)
Epoch 22100 @ 3, LR: [0.001]: Train loss: 59.9701687, Test loss: 58.6153974
Epoch 22200 @ 3, LR: [0.001]: Train loss: 59.8931507, Test loss: 58.7029560 (new best train)
Epoch 22300 @ 3, LR: [0.001]: Train loss: 59.8508435, Test loss: 58.7986221 (new best train)
Epoch 22400 @ 3, LR: [0.001]: Train loss: 59.8110519, Test loss: 58.8277024 (new best train)
Epoch 22500 @ 3, LR: [0.001]: Train loss: 59.7913725, Test loss: 58.8292882 (new best train)
Epoch 22600 @ 3, LR: [0.001]: Train loss: 59.7414229, Test loss: 58.7047189 (new best train)
Epoch 22700 @ 3, LR: [0.001]: Train loss: 59.6867733, Test loss: 58.1432031 (new best train)
Epoch 22800 @ 3, LR: [0.001]: Train loss: 59.6632112, Test loss: 58.3359539 (new best train)
Epoch 22900 @ 3, LR: [0.001]: Train loss: 59.6217206, Test loss: 58.5077219 (new best train)
Epoch 23000 @ 3, LR: [0.001]: Train loss: 59.5414589, Test loss: 60.0197839 (new best train)
Epoch 23100 @ 3, LR: [0.001]: Train loss: 59.5211742, Test loss: 58.3898851 (new best train)
Epoch 23200 @ 3, LR: [0.001]: Train loss: 59.4778871, Test loss: 59.1988097 (new best train)
Epoch 23300 @ 3, LR: [0.001]: Train loss: 59.4438473, Test loss: 58.3945275 (new best train)
Epoch 23400 @ 3, LR: [0.001]: Train loss: 59.4234666, Test loss: 58.4710211 (new best train)
Epoch 23500 @ 3, LR: [0.001]: Train loss: 59.3533855, Test loss: 59.6978019 (new best train)
Epoch 23600 @ 3, LR: [0.001]: Train loss: 59.3343136, Test loss: 57.6977187 (new best train)
Epoch 23700 @ 3, LR: [0.001]: Train loss: 59.2842791, Test loss: 58.8394338 (new best train)
Epoch 23800 @ 3, LR: [0.001]: Train loss: 59.2298546, Test loss: 58.7011053 (new best train)
Epoch 23900 @ 3, LR: [0.001]: Train loss: 59.1909923, Test loss: 58.4055614 (new best train)
Epoch 24000 @ 3, LR: [0.001]: Train loss: 59.1379008, Test loss: 57.9101529 (new best train)
Epoch 24100 @ 3, LR: [0.001]: Train loss: 59.1095612, Test loss: 57.3504272 (new best train)
Epoch 24200 @ 3, LR: [0.001]: Train loss: 59.0434245, Test loss: 57.3984469 (new best train)
Epoch 24300 @ 3, LR: [0.001]: Train loss: 59.0267884, Test loss: 57.5565958 (new best train)
Epoch 24400 @ 3, LR: [0.001]: Train loss: 58.9510880, Test loss: 57.5897819 (new best train)
Epoch 24500 @ 3, LR: [0.001]: Train loss: 58.9349495, Test loss: 57.6591741 (new best train)
Epoch 24600 @ 3, LR: [0.001]: Train loss: 58.8637849, Test loss: 57.3396202 (new best train)
Epoch 24700 @ 3, LR: [0.001]: Train loss: 58.8622432, Test loss: 57.9255862 (new best train)
Epoch 24800 @ 3, LR: [0.001]: Train loss: 58.7800515, Test loss: 58.3051941 (new best train)
Epoch 24900 @ 3, LR: [0.001]: Train loss: 58.7479828, Test loss: 57.1952251 (new best train)
Epoch 25000 @ 3, LR: [0.001]: Train loss: 58.6662421, Test loss: 57.3313032 (new best train)
Epoch 25100 @ 3, LR: [0.001]: Train loss: 58.6733007, Test loss: 57.0855752
Epoch 25200 @ 3, LR: [0.001]: Train loss: 58.5881447, Test loss: 58.0647793 (new best train)
Epoch 25300 @ 3, LR: [0.001]: Train loss: 58.5820782, Test loss: 57.2891126 (new best train)
Epoch 25400 @ 3, LR: [0.001]: Train loss: 58.5166920, Test loss: 57.9996257 (new best train)
Epoch 25500 @ 3, LR: [0.001]: Train loss: 58.4896015, Test loss: 59.4138189 (new best train)
Epoch 25600 @ 3, LR: [0.001]: Train loss: 58.4374787, Test loss: 56.9311395 (new best train)
Epoch 25700 @ 3, LR: [0.001]: Train loss: 58.3783373, Test loss: 56.9073851 (new best train)
Epoch 25800 @ 3, LR: [0.001]: Train loss: 58.3289983, Test loss: 56.8814756 (new best train)
Epoch 25900 @ 3, LR: [0.001]: Train loss: 58.2716209, Test loss: 57.7817984 (new best train)
Epoch 26000 @ 3, LR: [0.001]: Train loss: 58.2694889, Test loss: 57.1550315 (new best train)
Epoch 26100 @ 3, LR: [0.001]: Train loss: 58.2015852, Test loss: 57.6888607 (new best train)
Epoch 26200 @ 3, LR: [0.001]: Train loss: 58.1573929, Test loss: 57.2778805 (new best train)
Epoch 26300 @ 3, LR: [0.001]: Train loss: 58.0958981, Test loss: 57.2220107 (new best train)
Epoch 26400 @ 3, LR: [0.001]: Train loss: 58.0376046, Test loss: 57.1036409 (new best train)
Epoch 26500 @ 3, LR: [0.001]: Train loss: 58.0505734, Test loss: 57.5840653
Epoch 26600 @ 3, LR: [0.001]: Train loss: 57.9268469, Test loss: 56.4998952 (new best train)
Epoch 26700 @ 3, LR: [0.001]: Train loss: 57.9088445, Test loss: 56.3338529 (new best train)
Epoch 26800 @ 3, LR: [0.001]: Train loss: 57.8501597, Test loss: 56.6590523 (new best train)
Epoch 26900 @ 3, LR: [0.001]: Train loss: 57.8143401, Test loss: 60.6552821 (new best train)
Epoch 27000 @ 3, LR: [0.001]: Train loss: 57.7679076, Test loss: 56.8837913 (new best train)
Epoch 27100 @ 3, LR: [0.001]: Train loss: 57.7455866, Test loss: 56.3984458 (new best train)
Epoch 27200 @ 3, LR: [0.001]: Train loss: 57.7109285, Test loss: 56.3440218 (new best train)
Epoch 27300 @ 3, LR: [0.001]: Train loss: 57.6680693, Test loss: 57.4274375 (new best train)
Epoch 27400 @ 3, LR: [0.001]: Train loss: 57.6023869, Test loss: 56.1974910 (new best train)
Epoch 27500 @ 3, LR: [0.001]: Train loss: 57.5468599, Test loss: 56.3964909 (new best train)
Epoch 27600 @ 3, LR: [0.001]: Train loss: 57.5111373, Test loss: 57.1970226 (new best train)
Epoch 27700 @ 3, LR: [0.001]: Train loss: 57.4906312, Test loss: 56.8342039 (new best train)
Epoch 27800 @ 3, LR: [0.001]: Train loss: 57.4053639, Test loss: 56.6158202 (new best train)
Epoch 27900 @ 3, LR: [0.001]: Train loss: 57.3764231, Test loss: 56.1887057 (new best train)
Epoch 28000 @ 3, LR: [0.001]: Train loss: 57.3363717, Test loss: 56.1206868 (new best train)
Epoch 28100 @ 3, LR: [0.001]: Train loss: 57.2669184, Test loss: 56.8205241 (new best train)
Epoch 28200 @ 3, LR: [0.001]: Train loss: 57.2238127, Test loss: 55.7326259 (new best train)
Epoch 28300 @ 3, LR: [0.001]: Train loss: 57.1816069, Test loss: 55.7658578 (new best train)
Epoch 28400 @ 3, LR: [0.001]: Train loss: 57.1290243, Test loss: 57.3917262 (new best train)
Epoch 28500 @ 3, LR: [0.001]: Train loss: 57.0817570, Test loss: 55.6526711 (new best train)
Epoch 28600 @ 3, LR: [0.001]: Train loss: 57.0208194, Test loss: 56.6894762 (new best train)
Epoch 28700 @ 3, LR: [0.001]: Train loss: 56.9676921, Test loss: 55.9087325 (new best train)
Epoch 28800 @ 3, LR: [0.001]: Train loss: 56.9436424, Test loss: 55.6030053 (new best train)
Epoch 28900 @ 3, LR: [0.001]: Train loss: 56.9449087, Test loss: 56.2262035
Epoch 29000 @ 3, LR: [0.001]: Train loss: 56.8560469, Test loss: 56.3450271 (new best train)
Epoch 29100 @ 3, LR: [0.001]: Train loss: 56.7870053, Test loss: 56.7908053 (new best train)
Epoch 29200 @ 3, LR: [0.001]: Train loss: 56.7723393, Test loss: 55.5506949 (new best train)
Epoch 29300 @ 3, LR: [0.001]: Train loss: 56.7298135, Test loss: 56.3507423 (new best train)
Epoch 29400 @ 3, LR: [0.001]: Train loss: 56.6590405, Test loss: 55.6205668 (new best train)
Epoch 29500 @ 3, LR: [0.001]: Train loss: 56.6385288, Test loss: 56.1737022 (new best train)
Epoch 29600 @ 3, LR: [0.001]: Train loss: 56.5900969, Test loss: 56.5610662 (new best train)
Epoch 29700 @ 3, LR: [0.001]: Train loss: 56.5514335, Test loss: 55.7294129 (new best train)
Epoch 29800 @ 3, LR: [0.001]: Train loss: 56.4893454, Test loss: 55.9852905 (new best train)
Epoch 29900 @ 3, LR: [0.001]: Train loss: 56.4805439, Test loss: 55.9707531 (new best train)
Epoch 30000 @ 3, LR: [0.001]: Train loss: 56.3948294, Test loss: 56.9467749 (new best train)
Best train perf: 56.394829393942565, epoch: 30000
Fold 3 completed
Epoch 100 @ 4, LR: [0.001]: Train loss: 1416.8062503, Test loss: 159.7889848 (new best train)
Epoch 200 @ 4, LR: [0.001]: Train loss: 139.9121406, Test loss: 114.8416968 (new best train)
Epoch 300 @ 4, LR: [0.001]: Train loss: 96.7117336, Test loss: 89.0741426 (new best train)
Epoch 400 @ 4, LR: [0.001]: Train loss: 84.9704745, Test loss: 89.1385805 (new best train)
Epoch 500 @ 4, LR: [0.001]: Train loss: 81.1493723, Test loss: 80.2609790 (new best train)
Epoch 600 @ 4, LR: [0.001]: Train loss: 78.8548133, Test loss: 81.8522513 (new best train)
Epoch 700 @ 4, LR: [0.001]: Train loss: 77.2352589, Test loss: 80.6324460 (new best train)
Epoch 800 @ 4, LR: [0.001]: Train loss: 75.9209409, Test loss: 78.4335235 (new best train)
Epoch 900 @ 4, LR: [0.001]: Train loss: 74.9257155, Test loss: 82.1086073 (new best train)
Epoch 1000 @ 4, LR: [0.001]: Train loss: 73.9543969, Test loss: 75.6172891 (new best train)
Epoch 1100 @ 4, LR: [0.001]: Train loss: 73.1568841, Test loss: 74.0073924 (new best train)
Epoch 1200 @ 4, LR: [0.001]: Train loss: 72.3508889, Test loss: 73.5601227 (new best train)
Epoch 1300 @ 4, LR: [0.001]: Train loss: 71.7348517, Test loss: 71.7961710 (new best train)
Epoch 1400 @ 4, LR: [0.001]: Train loss: 71.1654590, Test loss: 72.9832595 (new best train)
Epoch 1500 @ 4, LR: [0.001]: Train loss: 70.8765041, Test loss: 71.8460292 (new best train)
Epoch 1600 @ 4, LR: [0.001]: Train loss: 70.4778771, Test loss: 71.8825473 (new best train)
Epoch 1700 @ 4, LR: [0.001]: Train loss: 70.1190924, Test loss: 70.4918655 (new best train)
Epoch 1800 @ 4, LR: [0.001]: Train loss: 69.8400339, Test loss: 70.3265104 (new best train)
Epoch 1900 @ 4, LR: [0.001]: Train loss: 69.6766805, Test loss: 70.0226073 (new best train)
Epoch 2000 @ 4, LR: [0.001]: Train loss: 69.3035568, Test loss: 70.7770033 (new best train)
Epoch 2100 @ 4, LR: [0.001]: Train loss: 69.2080447, Test loss: 71.5900709 (new best train)
Epoch 2200 @ 4, LR: [0.001]: Train loss: 68.9245745, Test loss: 69.5861366 (new best train)
Epoch 2300 @ 4, LR: [0.001]: Train loss: 68.7904561, Test loss: 72.2505481 (new best train)
Epoch 2400 @ 4, LR: [0.001]: Train loss: 68.5589850, Test loss: 73.2732743 (new best train)
Epoch 2500 @ 4, LR: [0.001]: Train loss: 68.3720178, Test loss: 69.2459684 (new best train)
Epoch 2600 @ 4, LR: [0.001]: Train loss: 68.1632652, Test loss: 69.2788796 (new best train)
Epoch 2700 @ 4, LR: [0.001]: Train loss: 68.0807450, Test loss: 69.0664532 (new best train)
Epoch 2800 @ 4, LR: [0.001]: Train loss: 67.9003714, Test loss: 68.6713804 (new best train)
Epoch 2900 @ 4, LR: [0.001]: Train loss: 67.7725402, Test loss: 69.7204553 (new best train)
Epoch 3000 @ 4, LR: [0.001]: Train loss: 67.5395502, Test loss: 68.6818325 (new best train)
Epoch 3100 @ 4, LR: [0.001]: Train loss: 67.4236966, Test loss: 71.5758349 (new best train)
Epoch 3200 @ 4, LR: [0.001]: Train loss: 67.2675603, Test loss: 72.5642152 (new best train)
Epoch 3300 @ 4, LR: [0.001]: Train loss: 67.1892984, Test loss: 68.2011009 (new best train)
Epoch 3400 @ 4, LR: [0.001]: Train loss: 67.0152659, Test loss: 71.8460672 (new best train)
Epoch 3500 @ 4, LR: [0.001]: Train loss: 66.8440242, Test loss: 68.6573670 (new best train)
Epoch 3600 @ 4, LR: [0.001]: Train loss: 66.8450893, Test loss: 70.1452625
Epoch 3700 @ 4, LR: [0.001]: Train loss: 66.6031479, Test loss: 68.0995501 (new best train)
Epoch 3800 @ 4, LR: [0.001]: Train loss: 66.5683226, Test loss: 67.7808212 (new best train)
Epoch 3900 @ 4, LR: [0.001]: Train loss: 66.4950784, Test loss: 68.0019832 (new best train)
Epoch 4000 @ 4, LR: [0.001]: Train loss: 66.3266037, Test loss: 71.3168864 (new best train)
Epoch 4100 @ 4, LR: [0.001]: Train loss: 66.1990163, Test loss: 68.0425357 (new best train)
Epoch 4200 @ 4, LR: [0.001]: Train loss: 66.0897821, Test loss: 67.4443283 (new best train)
Epoch 4300 @ 4, LR: [0.001]: Train loss: 66.0874262, Test loss: 67.3779489 (new best train)
Epoch 4400 @ 4, LR: [0.001]: Train loss: 65.8713294, Test loss: 67.1061922 (new best train)
Epoch 4500 @ 4, LR: [0.001]: Train loss: 65.7627545, Test loss: 67.9325229 (new best train)
Epoch 4600 @ 4, LR: [0.001]: Train loss: 65.7093887, Test loss: 68.1503292 (new best train)
Epoch 4700 @ 4, LR: [0.001]: Train loss: 65.7091723, Test loss: 66.8064250 (new best train)
Epoch 4800 @ 4, LR: [0.001]: Train loss: 65.5756052, Test loss: 68.0663358 (new best train)
Epoch 4900 @ 4, LR: [0.001]: Train loss: 65.4565138, Test loss: 66.7743491 (new best train)
Epoch 5000 @ 4, LR: [0.001]: Train loss: 65.4440115, Test loss: 66.6554362 (new best train)
Epoch 5100 @ 4, LR: [0.001]: Train loss: 65.3590433, Test loss: 72.0688712 (new best train)
Epoch 5200 @ 4, LR: [0.001]: Train loss: 65.2920877, Test loss: 66.6125352 (new best train)
Epoch 5300 @ 4, LR: [0.001]: Train loss: 65.2234880, Test loss: 66.4574278 (new best train)
Epoch 5400 @ 4, LR: [0.001]: Train loss: 65.1464112, Test loss: 66.6325671 (new best train)
Epoch 5500 @ 4, LR: [0.001]: Train loss: 65.0644836, Test loss: 66.5601035 (new best train)
Epoch 5600 @ 4, LR: [0.001]: Train loss: 64.9848695, Test loss: 66.8274871 (new best train)
Epoch 5700 @ 4, LR: [0.001]: Train loss: 64.8709201, Test loss: 67.2279129 (new best train)
Epoch 5800 @ 4, LR: [0.001]: Train loss: 64.8617112, Test loss: 67.5364478 (new best train)
Epoch 5900 @ 4, LR: [0.001]: Train loss: 64.8457697, Test loss: 66.3771608 (new best train)
Epoch 6000 @ 4, LR: [0.001]: Train loss: 64.7534777, Test loss: 66.6800114 (new best train)
Epoch 6100 @ 4, LR: [0.001]: Train loss: 64.7051060, Test loss: 66.4070476 (new best train)
Epoch 6200 @ 4, LR: [0.001]: Train loss: 64.6863064, Test loss: 66.4044570 (new best train)
Epoch 6300 @ 4, LR: [0.001]: Train loss: 64.6461821, Test loss: 67.4118069 (new best train)
Epoch 6400 @ 4, LR: [0.001]: Train loss: 64.5708292, Test loss: 66.4399309 (new best train)
Epoch 6500 @ 4, LR: [0.001]: Train loss: 64.5454786, Test loss: 66.1112882 (new best train)
Epoch 6600 @ 4, LR: [0.001]: Train loss: 64.5425695, Test loss: 65.8247120 (new best train)
Epoch 6700 @ 4, LR: [0.001]: Train loss: 64.4348838, Test loss: 68.3130757 (new best train)
Epoch 6800 @ 4, LR: [0.001]: Train loss: 64.3909194, Test loss: 66.8881378 (new best train)
Epoch 6900 @ 4, LR: [0.001]: Train loss: 64.4021056, Test loss: 66.0536403
Epoch 7000 @ 4, LR: [0.001]: Train loss: 64.3219218, Test loss: 65.8449293 (new best train)
Epoch 7100 @ 4, LR: [0.001]: Train loss: 64.2946238, Test loss: 66.2199011 (new best train)
Epoch 7200 @ 4, LR: [0.001]: Train loss: 64.2889636, Test loss: 65.7820415 (new best train)
Epoch 7300 @ 4, LR: [0.001]: Train loss: 64.2009253, Test loss: 66.4213193 (new best train)
Epoch 7400 @ 4, LR: [0.001]: Train loss: 64.2074560, Test loss: 65.7827765
Epoch 7500 @ 4, LR: [0.001]: Train loss: 64.1440029, Test loss: 65.6054440 (new best train)
Epoch 7600 @ 4, LR: [0.001]: Train loss: 64.1110103, Test loss: 65.8647513 (new best train)
Epoch 7700 @ 4, LR: [0.001]: Train loss: 64.0445929, Test loss: 68.2522841 (new best train)
Epoch 7800 @ 4, LR: [0.001]: Train loss: 64.0833913, Test loss: 68.5502135
Epoch 7900 @ 4, LR: [0.001]: Train loss: 63.9952920, Test loss: 69.1206926 (new best train)
Epoch 8000 @ 4, LR: [0.001]: Train loss: 63.9929581, Test loss: 65.5711916 (new best train)
Epoch 8100 @ 4, LR: [0.001]: Train loss: 63.9726693, Test loss: 67.8315654 (new best train)
Epoch 8200 @ 4, LR: [0.001]: Train loss: 63.8723730, Test loss: 65.5855293 (new best train)
Epoch 8300 @ 4, LR: [0.001]: Train loss: 63.8633862, Test loss: 66.9661521 (new best train)
Epoch 8400 @ 4, LR: [0.001]: Train loss: 63.8345476, Test loss: 65.7892910 (new best train)
Epoch 8500 @ 4, LR: [0.001]: Train loss: 63.7981139, Test loss: 65.6688126 (new best train)
Epoch 8600 @ 4, LR: [0.001]: Train loss: 63.7566783, Test loss: 65.9863415 (new best train)
Epoch 8700 @ 4, LR: [0.001]: Train loss: 63.7361187, Test loss: 65.6930557 (new best train)
Epoch 8800 @ 4, LR: [0.001]: Train loss: 63.6964870, Test loss: 65.7798819 (new best train)
Epoch 8900 @ 4, LR: [0.001]: Train loss: 63.6795995, Test loss: 65.4124288 (new best train)
Epoch 9000 @ 4, LR: [0.001]: Train loss: 63.6065471, Test loss: 65.1446678 (new best train)
Epoch 9100 @ 4, LR: [0.001]: Train loss: 63.6097874, Test loss: 65.2460641
Epoch 9200 @ 4, LR: [0.001]: Train loss: 63.5127408, Test loss: 64.9871673 (new best train)
Epoch 9300 @ 4, LR: [0.001]: Train loss: 63.5387500, Test loss: 65.1623023
Epoch 9400 @ 4, LR: [0.001]: Train loss: 63.4823665, Test loss: 64.9417737 (new best train)
Epoch 9500 @ 4, LR: [0.001]: Train loss: 63.4204841, Test loss: 65.1541567 (new best train)
Epoch 9600 @ 4, LR: [0.001]: Train loss: 63.3844092, Test loss: 65.3269223 (new best train)
Epoch 9700 @ 4, LR: [0.001]: Train loss: 63.4042653, Test loss: 65.1928743
Epoch 9800 @ 4, LR: [0.001]: Train loss: 63.3208000, Test loss: 65.2565981 (new best train)
Epoch 9900 @ 4, LR: [0.001]: Train loss: 63.3514139, Test loss: 65.5157948
Epoch 10000 @ 4, LR: [0.001]: Train loss: 63.2779498, Test loss: 64.8632171 (new best train)
Epoch 10100 @ 4, LR: [0.001]: Train loss: 63.2521919, Test loss: 65.6574541 (new best train)
Epoch 10200 @ 4, LR: [0.001]: Train loss: 63.2140123, Test loss: 64.9162754 (new best train)
Epoch 10300 @ 4, LR: [0.001]: Train loss: 63.1757533, Test loss: 64.7925497 (new best train)
Epoch 10400 @ 4, LR: [0.001]: Train loss: 63.1763597, Test loss: 64.9688405
Epoch 10500 @ 4, LR: [0.001]: Train loss: 63.1159771, Test loss: 64.9594313 (new best train)
Epoch 10600 @ 4, LR: [0.001]: Train loss: 63.0802025, Test loss: 64.7401884 (new best train)
Epoch 10700 @ 4, LR: [0.001]: Train loss: 63.0544492, Test loss: 65.0596334 (new best train)
Epoch 10800 @ 4, LR: [0.001]: Train loss: 63.0510815, Test loss: 65.0357662 (new best train)
Epoch 10900 @ 4, LR: [0.001]: Train loss: 62.9821745, Test loss: 64.5406750 (new best train)
Epoch 11000 @ 4, LR: [0.001]: Train loss: 62.9813872, Test loss: 64.7097684 (new best train)
Epoch 11100 @ 4, LR: [0.001]: Train loss: 62.9308075, Test loss: 65.1608943 (new best train)
Epoch 11200 @ 4, LR: [0.001]: Train loss: 62.9354094, Test loss: 64.5811347
Epoch 11300 @ 4, LR: [0.001]: Train loss: 62.8642751, Test loss: 64.5710844 (new best train)
Epoch 11400 @ 4, LR: [0.001]: Train loss: 62.8286354, Test loss: 64.7936163 (new best train)
Epoch 11500 @ 4, LR: [0.001]: Train loss: 62.8513737, Test loss: 64.5568104
Epoch 11600 @ 4, LR: [0.001]: Train loss: 62.7987615, Test loss: 64.8313475 (new best train)
Epoch 11700 @ 4, LR: [0.001]: Train loss: 62.7783689, Test loss: 66.3221262 (new best train)
Epoch 11800 @ 4, LR: [0.001]: Train loss: 62.7269633, Test loss: 64.4598680 (new best train)
Epoch 11900 @ 4, LR: [0.001]: Train loss: 62.7121844, Test loss: 64.4447935 (new best train)
Epoch 12000 @ 4, LR: [0.001]: Train loss: 62.6816011, Test loss: 64.8851025 (new best train)
Epoch 12100 @ 4, LR: [0.001]: Train loss: 62.6486681, Test loss: 64.4959221 (new best train)
Epoch 12200 @ 4, LR: [0.001]: Train loss: 62.6221323, Test loss: 64.3749102 (new best train)
Epoch 12300 @ 4, LR: [0.001]: Train loss: 62.6033837, Test loss: 64.6350045 (new best train)
Epoch 12400 @ 4, LR: [0.001]: Train loss: 62.5778722, Test loss: 64.3131037 (new best train)
Epoch 12500 @ 4, LR: [0.001]: Train loss: 62.5393023, Test loss: 64.6702897 (new best train)
Epoch 12600 @ 4, LR: [0.001]: Train loss: 62.5306166, Test loss: 64.4618016 (new best train)
Epoch 12700 @ 4, LR: [0.001]: Train loss: 62.4945781, Test loss: 64.2477292 (new best train)
Epoch 12800 @ 4, LR: [0.001]: Train loss: 62.4769280, Test loss: 64.7306688 (new best train)
Epoch 12900 @ 4, LR: [0.001]: Train loss: 62.4275364, Test loss: 64.3051908 (new best train)
Epoch 13000 @ 4, LR: [0.001]: Train loss: 62.4368597, Test loss: 64.6481572
Epoch 13100 @ 4, LR: [0.001]: Train loss: 62.4002172, Test loss: 63.9904162 (new best train)
Epoch 13200 @ 4, LR: [0.001]: Train loss: 62.3678011, Test loss: 64.2295854 (new best train)
Epoch 13300 @ 4, LR: [0.001]: Train loss: 62.3499159, Test loss: 64.0512898 (new best train)
Epoch 13400 @ 4, LR: [0.001]: Train loss: 62.2772378, Test loss: 64.1122154 (new best train)
Epoch 13500 @ 4, LR: [0.001]: Train loss: 62.2855852, Test loss: 64.1752866
Epoch 13600 @ 4, LR: [0.001]: Train loss: 62.2728149, Test loss: 63.9271404 (new best train)
Epoch 13700 @ 4, LR: [0.001]: Train loss: 62.2461805, Test loss: 64.1002788 (new best train)
Epoch 13800 @ 4, LR: [0.001]: Train loss: 62.2207049, Test loss: 65.1845630 (new best train)
Epoch 13900 @ 4, LR: [0.001]: Train loss: 62.2202089, Test loss: 65.7039105 (new best train)
Epoch 14000 @ 4, LR: [0.001]: Train loss: 62.1761217, Test loss: 63.8042237 (new best train)
Epoch 14100 @ 4, LR: [0.001]: Train loss: 62.1777266, Test loss: 63.9451389
Epoch 14200 @ 4, LR: [0.001]: Train loss: 62.1094925, Test loss: 64.9384710 (new best train)
Epoch 14300 @ 4, LR: [0.001]: Train loss: 62.1120117, Test loss: 63.9232612
Epoch 14400 @ 4, LR: [0.001]: Train loss: 62.0853483, Test loss: 64.0341137 (new best train)
Epoch 14500 @ 4, LR: [0.001]: Train loss: 62.0933751, Test loss: 63.8321357
Epoch 14600 @ 4, LR: [0.001]: Train loss: 62.0396462, Test loss: 64.3321250 (new best train)
Epoch 14700 @ 4, LR: [0.001]: Train loss: 62.0096085, Test loss: 63.6341373 (new best train)
Epoch 14800 @ 4, LR: [0.001]: Train loss: 61.9717049, Test loss: 64.7416713 (new best train)
Epoch 14900 @ 4, LR: [0.001]: Train loss: 61.9675200, Test loss: 63.7148673 (new best train)
Epoch 15000 @ 4, LR: [0.001]: Train loss: 61.9541615, Test loss: 63.8291544 (new best train)
Epoch 15100 @ 4, LR: [0.001]: Train loss: 61.9153004, Test loss: 63.9150130 (new best train)
Epoch 15200 @ 4, LR: [0.001]: Train loss: 61.9177329, Test loss: 63.4494827
Epoch 15300 @ 4, LR: [0.001]: Train loss: 61.8855841, Test loss: 63.9013445 (new best train)
Epoch 15400 @ 4, LR: [0.001]: Train loss: 61.8371461, Test loss: 63.6804138 (new best train)
Epoch 15500 @ 4, LR: [0.001]: Train loss: 61.8411255, Test loss: 63.5297031
Epoch 15600 @ 4, LR: [0.001]: Train loss: 61.8049528, Test loss: 65.6187122 (new best train)
Epoch 15700 @ 4, LR: [0.001]: Train loss: 61.7873392, Test loss: 63.4346435 (new best train)
Epoch 15800 @ 4, LR: [0.001]: Train loss: 61.7732699, Test loss: 63.5272363 (new best train)
Epoch 15900 @ 4, LR: [0.001]: Train loss: 61.7230192, Test loss: 64.2091873 (new best train)
Epoch 16000 @ 4, LR: [0.001]: Train loss: 61.7081727, Test loss: 64.9675066 (new best train)
Epoch 16100 @ 4, LR: [0.001]: Train loss: 61.7085925, Test loss: 63.7856997
Epoch 16200 @ 4, LR: [0.001]: Train loss: 61.6661205, Test loss: 63.7811198 (new best train)
Epoch 16300 @ 4, LR: [0.001]: Train loss: 61.6708884, Test loss: 64.0718477
Epoch 16400 @ 4, LR: [0.001]: Train loss: 61.6316330, Test loss: 64.2824480 (new best train)
Epoch 16500 @ 4, LR: [0.001]: Train loss: 61.6049913, Test loss: 63.5874513 (new best train)
Epoch 16600 @ 4, LR: [0.001]: Train loss: 61.5674384, Test loss: 63.4939346 (new best train)
Epoch 16700 @ 4, LR: [0.001]: Train loss: 61.5584134, Test loss: 63.5857823 (new best train)
Epoch 16800 @ 4, LR: [0.001]: Train loss: 61.5372616, Test loss: 63.3533568 (new best train)
Epoch 16900 @ 4, LR: [0.001]: Train loss: 61.4921858, Test loss: 63.3532270 (new best train)
Epoch 17000 @ 4, LR: [0.001]: Train loss: 61.5005501, Test loss: 64.3869975
Epoch 17100 @ 4, LR: [0.001]: Train loss: 61.4565088, Test loss: 64.6652453 (new best train)
Epoch 17200 @ 4, LR: [0.001]: Train loss: 61.4405289, Test loss: 64.0684860 (new best train)
Epoch 17300 @ 4, LR: [0.001]: Train loss: 61.4283835, Test loss: 63.1451802 (new best train)
Epoch 17400 @ 4, LR: [0.001]: Train loss: 61.3890311, Test loss: 63.8880933 (new best train)
Epoch 17500 @ 4, LR: [0.001]: Train loss: 61.3801534, Test loss: 63.3622894 (new best train)
Epoch 17600 @ 4, LR: [0.001]: Train loss: 61.3566473, Test loss: 63.1136347 (new best train)
Epoch 17700 @ 4, LR: [0.001]: Train loss: 61.3507460, Test loss: 63.0847267 (new best train)
Epoch 17800 @ 4, LR: [0.001]: Train loss: 61.2942019, Test loss: 63.1666305 (new best train)
Epoch 17900 @ 4, LR: [0.001]: Train loss: 61.2914256, Test loss: 63.6480947 (new best train)
Epoch 18000 @ 4, LR: [0.001]: Train loss: 61.2481113, Test loss: 63.2137148 (new best train)
Epoch 18100 @ 4, LR: [0.001]: Train loss: 61.2182838, Test loss: 63.3002343 (new best train)
Epoch 18200 @ 4, LR: [0.001]: Train loss: 61.1937081, Test loss: 63.0222621 (new best train)
Epoch 18300 @ 4, LR: [0.001]: Train loss: 61.1554128, Test loss: 63.3241268 (new best train)
Epoch 18400 @ 4, LR: [0.001]: Train loss: 61.1423506, Test loss: 62.8888559 (new best train)
Epoch 18500 @ 4, LR: [0.001]: Train loss: 61.0932785, Test loss: 64.0872220 (new best train)
Epoch 18600 @ 4, LR: [0.001]: Train loss: 61.0346333, Test loss: 62.9335186 (new best train)
Epoch 18700 @ 4, LR: [0.001]: Train loss: 61.0249444, Test loss: 62.9416623 (new best train)
Epoch 18800 @ 4, LR: [0.001]: Train loss: 60.9823589, Test loss: 63.2402212 (new best train)
Epoch 18900 @ 4, LR: [0.001]: Train loss: 60.9179973, Test loss: 63.2442424 (new best train)
Epoch 19000 @ 4, LR: [0.001]: Train loss: 60.8399786, Test loss: 62.5608465 (new best train)
Epoch 19100 @ 4, LR: [0.001]: Train loss: 60.7672322, Test loss: 62.3767352 (new best train)
Epoch 19200 @ 4, LR: [0.001]: Train loss: 60.6934379, Test loss: 62.7695589 (new best train)
Epoch 19300 @ 4, LR: [0.001]: Train loss: 60.6025189, Test loss: 63.2108298 (new best train)
Epoch 19400 @ 4, LR: [0.001]: Train loss: 60.4437951, Test loss: 63.0242281 (new best train)
Epoch 19500 @ 4, LR: [0.001]: Train loss: 60.3385530, Test loss: 61.8109260 (new best train)
Epoch 19600 @ 4, LR: [0.001]: Train loss: 60.1777214, Test loss: 61.8275801 (new best train)
Epoch 19700 @ 4, LR: [0.001]: Train loss: 60.0049912, Test loss: 61.3362979 (new best train)
Epoch 19800 @ 4, LR: [0.001]: Train loss: 59.8081790, Test loss: 62.2528525 (new best train)
Epoch 19900 @ 4, LR: [0.001]: Train loss: 59.6103948, Test loss: 62.6373742 (new best train)
Epoch 20000 @ 4, LR: [0.001]: Train loss: 59.4733791, Test loss: 60.7508441 (new best train)
Epoch 20100 @ 4, LR: [0.001]: Train loss: 59.2530164, Test loss: 61.8141282 (new best train)
Epoch 20200 @ 4, LR: [0.001]: Train loss: 59.1238418, Test loss: 61.3075588 (new best train)
Epoch 20300 @ 4, LR: [0.001]: Train loss: 58.9636585, Test loss: 61.0299627 (new best train)
Epoch 20400 @ 4, LR: [0.001]: Train loss: 58.7620451, Test loss: 61.8218490 (new best train)
Epoch 20500 @ 4, LR: [0.001]: Train loss: 58.6343425, Test loss: 60.8870811 (new best train)
Epoch 20600 @ 4, LR: [0.001]: Train loss: 58.4694074, Test loss: 61.7767868 (new best train)
Epoch 20700 @ 4, LR: [0.001]: Train loss: 58.2828887, Test loss: 60.3004287 (new best train)
Epoch 20800 @ 4, LR: [0.001]: Train loss: 58.2611881, Test loss: 60.8862265 (new best train)
Epoch 20900 @ 4, LR: [0.001]: Train loss: 58.0181201, Test loss: 59.7458517 (new best train)
Epoch 21000 @ 4, LR: [0.001]: Train loss: 57.8780833, Test loss: 61.3445768 (new best train)
Epoch 21100 @ 4, LR: [0.001]: Train loss: 57.8094351, Test loss: 60.2386362 (new best train)
Epoch 21200 @ 4, LR: [0.001]: Train loss: 57.6530332, Test loss: 60.1594390 (new best train)
Epoch 21300 @ 4, LR: [0.001]: Train loss: 57.4579150, Test loss: 58.8343669 (new best train)
Epoch 21400 @ 4, LR: [0.001]: Train loss: 57.5065174, Test loss: 59.6834674
Epoch 21500 @ 4, LR: [0.001]: Train loss: 57.3750810, Test loss: 58.7968270 (new best train)
Epoch 21600 @ 4, LR: [0.001]: Train loss: 57.2827404, Test loss: 58.9778435 (new best train)
Epoch 21700 @ 4, LR: [0.001]: Train loss: 57.1112795, Test loss: 58.5266345 (new best train)
Epoch 21800 @ 4, LR: [0.001]: Train loss: 57.1662678, Test loss: 59.2407173
Epoch 21900 @ 4, LR: [0.001]: Train loss: 56.9187391, Test loss: 58.8049064 (new best train)
Epoch 22000 @ 4, LR: [0.001]: Train loss: 56.9311656, Test loss: 58.5783662
Epoch 22100 @ 4, LR: [0.001]: Train loss: 56.8478277, Test loss: 58.2049164 (new best train)
Epoch 22200 @ 4, LR: [0.001]: Train loss: 56.8064443, Test loss: 58.4081034 (new best train)
Epoch 22300 @ 4, LR: [0.001]: Train loss: 56.7050054, Test loss: 59.9489289 (new best train)
Epoch 22400 @ 4, LR: [0.001]: Train loss: 56.6893883, Test loss: 57.7067736 (new best train)
Epoch 22500 @ 4, LR: [0.001]: Train loss: 56.4976491, Test loss: 58.1175143 (new best train)
Epoch 22600 @ 4, LR: [0.001]: Train loss: 56.3875938, Test loss: 58.0629741 (new best train)
Epoch 22700 @ 4, LR: [0.001]: Train loss: 56.3190200, Test loss: 58.6951790 (new best train)
Epoch 22800 @ 4, LR: [0.001]: Train loss: 56.2586548, Test loss: 58.3622261 (new best train)
Epoch 22900 @ 4, LR: [0.001]: Train loss: 56.1513440, Test loss: 57.9989767 (new best train)
Epoch 23000 @ 4, LR: [0.001]: Train loss: 56.0855751, Test loss: 57.7891504 (new best train)
Epoch 23100 @ 4, LR: [0.001]: Train loss: 56.0045640, Test loss: 57.7787358 (new best train)
Epoch 23200 @ 4, LR: [0.001]: Train loss: 56.0638687, Test loss: 63.6211147
Epoch 23300 @ 4, LR: [0.001]: Train loss: 55.9384134, Test loss: 61.2803301 (new best train)
Epoch 23400 @ 4, LR: [0.001]: Train loss: 55.8791956, Test loss: 57.7134565 (new best train)
Epoch 23500 @ 4, LR: [0.001]: Train loss: 55.7720855, Test loss: 59.0753260 (new best train)
Epoch 23600 @ 4, LR: [0.001]: Train loss: 55.7611786, Test loss: 57.2507470 (new best train)
Epoch 23700 @ 4, LR: [0.001]: Train loss: 55.6745764, Test loss: 57.9285107 (new best train)
Epoch 23800 @ 4, LR: [0.001]: Train loss: 55.5868355, Test loss: 58.2414962 (new best train)
Epoch 23900 @ 4, LR: [0.001]: Train loss: 55.6142635, Test loss: 56.8403278
Epoch 24000 @ 4, LR: [0.001]: Train loss: 55.6097874, Test loss: 56.9257712
Epoch 24100 @ 4, LR: [0.001]: Train loss: 55.4114667, Test loss: 58.0325861 (new best train)
Epoch 24200 @ 4, LR: [0.001]: Train loss: 55.4820263, Test loss: 56.9031247
Epoch 24300 @ 4, LR: [0.001]: Train loss: 55.2742258, Test loss: 56.9093721 (new best train)
Epoch 24400 @ 4, LR: [0.001]: Train loss: 55.2659561, Test loss: 58.1249371 (new best train)
Epoch 24500 @ 4, LR: [0.001]: Train loss: 55.3242007, Test loss: 57.0123814
Epoch 24600 @ 4, LR: [0.001]: Train loss: 55.2216942, Test loss: 56.6205720 (new best train)
Epoch 24700 @ 4, LR: [0.001]: Train loss: 55.1410246, Test loss: 57.0272859 (new best train)
Epoch 24800 @ 4, LR: [0.001]: Train loss: 55.1569541, Test loss: 60.8396153
Epoch 24900 @ 4, LR: [0.001]: Train loss: 55.0650288, Test loss: 57.2827879 (new best train)
Epoch 25000 @ 4, LR: [0.001]: Train loss: 55.0538865, Test loss: 57.5527234 (new best train)
Epoch 25100 @ 4, LR: [0.001]: Train loss: 54.9285110, Test loss: 56.7865005 (new best train)
Epoch 25200 @ 4, LR: [0.001]: Train loss: 54.9692989, Test loss: 58.0178502
Epoch 25300 @ 4, LR: [0.001]: Train loss: 55.0206071, Test loss: 58.0120950
Epoch 25400 @ 4, LR: [0.001]: Train loss: 54.7916961, Test loss: 57.2028729 (new best train)
Epoch 25500 @ 4, LR: [0.001]: Train loss: 54.8656572, Test loss: 57.4372300
Epoch 25600 @ 4, LR: [0.001]: Train loss: 54.7499374, Test loss: 56.6829538 (new best train)
Epoch 25700 @ 4, LR: [0.001]: Train loss: 54.7382544, Test loss: 56.8480330 (new best train)
Epoch 25800 @ 4, LR: [0.001]: Train loss: 54.6673363, Test loss: 57.4265737 (new best train)
Epoch 25900 @ 4, LR: [0.001]: Train loss: 54.6421290, Test loss: 61.6484674 (new best train)
Epoch 26000 @ 4, LR: [0.001]: Train loss: 54.6408771, Test loss: 56.3200503 (new best train)
Epoch 26100 @ 4, LR: [0.001]: Train loss: 54.6662263, Test loss: 57.3298445
Epoch 26200 @ 4, LR: [0.001]: Train loss: 54.4967234, Test loss: 57.4618817 (new best train)
Epoch 26300 @ 4, LR: [0.001]: Train loss: 54.5375618, Test loss: 56.9066588
Epoch 26400 @ 4, LR: [0.001]: Train loss: 54.4426985, Test loss: 57.9611218 (new best train)
Epoch 26500 @ 4, LR: [0.001]: Train loss: 54.4576308, Test loss: 56.3020798
Epoch 26600 @ 4, LR: [0.001]: Train loss: 54.3570272, Test loss: 56.7170593 (new best train)
Epoch 26700 @ 4, LR: [0.001]: Train loss: 54.2660377, Test loss: 56.0302683 (new best train)
Epoch 26800 @ 4, LR: [0.001]: Train loss: 54.3208275, Test loss: 56.4587347
Epoch 26900 @ 4, LR: [0.001]: Train loss: 54.1943055, Test loss: 59.4344134 (new best train)
Epoch 27000 @ 4, LR: [0.001]: Train loss: 54.1543378, Test loss: 55.9543150 (new best train)
Epoch 27100 @ 4, LR: [0.001]: Train loss: 54.1969135, Test loss: 56.3216957
Epoch 27200 @ 4, LR: [0.001]: Train loss: 54.1324449, Test loss: 56.8646773 (new best train)
Epoch 27300 @ 4, LR: [0.001]: Train loss: 54.2272429, Test loss: 55.6409635
Epoch 27400 @ 4, LR: [0.001]: Train loss: 54.0251255, Test loss: 55.6806719 (new best train)
Epoch 27500 @ 4, LR: [0.001]: Train loss: 53.9755080, Test loss: 56.0896036 (new best train)
Epoch 27600 @ 4, LR: [0.001]: Train loss: 54.0629669, Test loss: 57.7373573
Epoch 27700 @ 4, LR: [0.001]: Train loss: 53.9706952, Test loss: 57.7486993 (new best train)
Epoch 27800 @ 4, LR: [0.001]: Train loss: 53.8468787, Test loss: 56.6774523 (new best train)
Epoch 27900 @ 4, LR: [0.001]: Train loss: 53.9072243, Test loss: 57.2088333
Epoch 28000 @ 4, LR: [0.001]: Train loss: 53.8897245, Test loss: 56.3578747
Epoch 28100 @ 4, LR: [0.001]: Train loss: 53.8393694, Test loss: 57.2374288 (new best train)
Epoch 28200 @ 4, LR: [0.001]: Train loss: 53.8312857, Test loss: 56.9846614 (new best train)
Epoch 28300 @ 4, LR: [0.001]: Train loss: 53.8416414, Test loss: 56.7775521
Epoch 28400 @ 4, LR: [0.001]: Train loss: 53.7525414, Test loss: 56.4612404 (new best train)
Epoch 28500 @ 4, LR: [0.001]: Train loss: 53.7286783, Test loss: 55.4858403 (new best train)
Epoch 28600 @ 4, LR: [0.001]: Train loss: 53.6741989, Test loss: 55.7609234 (new best train)
Epoch 28700 @ 4, LR: [0.001]: Train loss: 53.6818473, Test loss: 58.7596949
Epoch 28800 @ 4, LR: [0.001]: Train loss: 53.5759654, Test loss: 55.6358501 (new best train)
Epoch 28900 @ 4, LR: [0.001]: Train loss: 53.5935028, Test loss: 56.3980555
Epoch 29000 @ 4, LR: [0.001]: Train loss: 53.6521766, Test loss: 55.6750384
Epoch 29100 @ 4, LR: [0.001]: Train loss: 53.5603167, Test loss: 56.5028650 (new best train)
Epoch 29200 @ 4, LR: [0.001]: Train loss: 53.5710241, Test loss: 56.9072968
Epoch 29300 @ 4, LR: [0.001]: Train loss: 53.4793980, Test loss: 55.6537200 (new best train)
Epoch 29400 @ 4, LR: [0.001]: Train loss: 53.4689997, Test loss: 55.9718205 (new best train)
Epoch 29500 @ 4, LR: [0.001]: Train loss: 53.4633185, Test loss: 57.9008407 (new best train)
Epoch 29600 @ 4, LR: [0.001]: Train loss: 53.4582123, Test loss: 55.6811393 (new best train)
Epoch 29700 @ 4, LR: [0.001]: Train loss: 53.3347148, Test loss: 56.1147432 (new best train)
Epoch 29800 @ 4, LR: [0.001]: Train loss: 53.3489840, Test loss: 56.8178808
Epoch 29900 @ 4, LR: [0.001]: Train loss: 53.2607101, Test loss: 56.9321105 (new best train)
Epoch 30000 @ 4, LR: [0.001]: Train loss: 53.2311708, Test loss: 55.3200404 (new best train)
Best train perf: 53.231170805466256, epoch: 30000
Fold 4 completed
Epoch 100 @ 5, LR: [0.001]: Train loss: 1423.1713272, Test loss: 157.0814785 (new best train)
Epoch 200 @ 5, LR: [0.001]: Train loss: 140.6857296, Test loss: 105.0234144 (new best train)
Epoch 300 @ 5, LR: [0.001]: Train loss: 92.8556017, Test loss: 82.7683229 (new best train)
Epoch 400 @ 5, LR: [0.001]: Train loss: 83.8141291, Test loss: 77.2187791 (new best train)
Epoch 500 @ 5, LR: [0.001]: Train loss: 80.2453048, Test loss: 80.2726026 (new best train)
Epoch 600 @ 5, LR: [0.001]: Train loss: 78.3830306, Test loss: 78.6007028 (new best train)
Epoch 700 @ 5, LR: [0.001]: Train loss: 77.1062713, Test loss: 74.9680243 (new best train)
Epoch 800 @ 5, LR: [0.001]: Train loss: 76.1268344, Test loss: 72.2992280 (new best train)
Epoch 900 @ 5, LR: [0.001]: Train loss: 75.2420409, Test loss: 71.1146510 (new best train)
Epoch 1000 @ 5, LR: [0.001]: Train loss: 74.4263767, Test loss: 70.3188336 (new best train)
Epoch 1100 @ 5, LR: [0.001]: Train loss: 73.7194142, Test loss: 72.4803315 (new best train)
Epoch 1200 @ 5, LR: [0.001]: Train loss: 73.2092314, Test loss: 71.4213082 (new best train)
Epoch 1300 @ 5, LR: [0.001]: Train loss: 72.8076645, Test loss: 70.5764014 (new best train)
Epoch 1400 @ 5, LR: [0.001]: Train loss: 72.1851259, Test loss: 68.7171550 (new best train)
Epoch 1500 @ 5, LR: [0.001]: Train loss: 71.8447742, Test loss: 68.1974935 (new best train)
Epoch 1600 @ 5, LR: [0.001]: Train loss: 71.2971713, Test loss: 70.6515136 (new best train)
Epoch 1700 @ 5, LR: [0.001]: Train loss: 71.0102307, Test loss: 69.4672704 (new best train)
Epoch 1800 @ 5, LR: [0.001]: Train loss: 70.6099633, Test loss: 67.6656416 (new best train)
Epoch 1900 @ 5, LR: [0.001]: Train loss: 70.3594045, Test loss: 69.1940856 (new best train)
Epoch 2000 @ 5, LR: [0.001]: Train loss: 70.0725147, Test loss: 67.6914604 (new best train)
Epoch 2100 @ 5, LR: [0.001]: Train loss: 69.9662495, Test loss: 66.7533332 (new best train)
Epoch 2200 @ 5, LR: [0.001]: Train loss: 69.6662100, Test loss: 69.2289977 (new best train)
Epoch 2300 @ 5, LR: [0.001]: Train loss: 69.5853469, Test loss: 66.2103635 (new best train)
Epoch 2400 @ 5, LR: [0.001]: Train loss: 69.4207450, Test loss: 66.8493918 (new best train)
Epoch 2500 @ 5, LR: [0.001]: Train loss: 69.0679902, Test loss: 68.8247625 (new best train)
Epoch 2600 @ 5, LR: [0.001]: Train loss: 68.9420996, Test loss: 68.0874051 (new best train)
Epoch 2700 @ 5, LR: [0.001]: Train loss: 68.8180561, Test loss: 66.5723022 (new best train)
Epoch 2800 @ 5, LR: [0.001]: Train loss: 68.6001665, Test loss: 68.7097880 (new best train)
Epoch 2900 @ 5, LR: [0.001]: Train loss: 68.4095775, Test loss: 67.1604423 (new best train)
Epoch 3000 @ 5, LR: [0.001]: Train loss: 68.3373115, Test loss: 67.6211346 (new best train)
Epoch 3100 @ 5, LR: [0.001]: Train loss: 68.2446308, Test loss: 67.4126584 (new best train)
Epoch 3200 @ 5, LR: [0.001]: Train loss: 68.0932662, Test loss: 65.4498990 (new best train)
Epoch 3300 @ 5, LR: [0.001]: Train loss: 67.9113811, Test loss: 72.3600878 (new best train)
Epoch 3400 @ 5, LR: [0.001]: Train loss: 67.8072554, Test loss: 65.3413216 (new best train)
Epoch 3500 @ 5, LR: [0.001]: Train loss: 67.7693990, Test loss: 66.8328478 (new best train)
Epoch 3600 @ 5, LR: [0.001]: Train loss: 67.5618127, Test loss: 64.9343782 (new best train)
Epoch 3700 @ 5, LR: [0.001]: Train loss: 67.5237289, Test loss: 65.1276337 (new best train)
Epoch 3800 @ 5, LR: [0.001]: Train loss: 67.4688293, Test loss: 64.9359215 (new best train)
Epoch 3900 @ 5, LR: [0.001]: Train loss: 67.3485013, Test loss: 64.4556353 (new best train)
Epoch 4000 @ 5, LR: [0.001]: Train loss: 67.2584309, Test loss: 64.5454204 (new best train)
Epoch 4100 @ 5, LR: [0.001]: Train loss: 67.1813682, Test loss: 64.6108122 (new best train)
Epoch 4200 @ 5, LR: [0.001]: Train loss: 67.0173065, Test loss: 64.6471768 (new best train)
Epoch 4300 @ 5, LR: [0.001]: Train loss: 67.0450745, Test loss: 64.1466153
Epoch 4400 @ 5, LR: [0.001]: Train loss: 66.9445790, Test loss: 66.0331282 (new best train)
Epoch 4500 @ 5, LR: [0.001]: Train loss: 66.9088839, Test loss: 64.8033423 (new best train)
Epoch 4600 @ 5, LR: [0.001]: Train loss: 66.7354857, Test loss: 65.2116418 (new best train)
Epoch 4700 @ 5, LR: [0.001]: Train loss: 66.7048439, Test loss: 64.4261783 (new best train)
Epoch 4800 @ 5, LR: [0.001]: Train loss: 66.5629722, Test loss: 64.0490994 (new best train)
Epoch 4900 @ 5, LR: [0.001]: Train loss: 66.5622585, Test loss: 71.5201249 (new best train)
Epoch 5000 @ 5, LR: [0.001]: Train loss: 66.5183323, Test loss: 63.8824103 (new best train)
Epoch 5100 @ 5, LR: [0.001]: Train loss: 66.4237948, Test loss: 66.6349447 (new best train)
Epoch 5200 @ 5, LR: [0.001]: Train loss: 66.3762145, Test loss: 63.8826427 (new best train)
Epoch 5300 @ 5, LR: [0.001]: Train loss: 66.2982628, Test loss: 63.9235226 (new best train)
Epoch 5400 @ 5, LR: [0.001]: Train loss: 66.2673582, Test loss: 63.6498091 (new best train)
Epoch 5500 @ 5, LR: [0.001]: Train loss: 66.1597545, Test loss: 63.6459747 (new best train)
Epoch 5600 @ 5, LR: [0.001]: Train loss: 66.0934608, Test loss: 64.5624693 (new best train)
Epoch 5700 @ 5, LR: [0.001]: Train loss: 66.0457467, Test loss: 63.7296305 (new best train)
Epoch 5800 @ 5, LR: [0.001]: Train loss: 66.0032257, Test loss: 64.4529518 (new best train)
Epoch 5900 @ 5, LR: [0.001]: Train loss: 65.9373167, Test loss: 63.5026295 (new best train)
Epoch 6000 @ 5, LR: [0.001]: Train loss: 65.9002433, Test loss: 63.4169186 (new best train)
Epoch 6100 @ 5, LR: [0.001]: Train loss: 65.7941579, Test loss: 63.6071483 (new best train)
Epoch 6200 @ 5, LR: [0.001]: Train loss: 65.7927619, Test loss: 64.4718117 (new best train)
Epoch 6300 @ 5, LR: [0.001]: Train loss: 65.7286807, Test loss: 64.2658695 (new best train)
Epoch 6400 @ 5, LR: [0.001]: Train loss: 65.6327577, Test loss: 66.0482941 (new best train)
Epoch 6500 @ 5, LR: [0.001]: Train loss: 65.6222271, Test loss: 63.1279000 (new best train)
Epoch 6600 @ 5, LR: [0.001]: Train loss: 65.5913247, Test loss: 65.0256954 (new best train)
Epoch 6700 @ 5, LR: [0.001]: Train loss: 65.5238913, Test loss: 63.9394679 (new best train)
Epoch 6800 @ 5, LR: [0.001]: Train loss: 65.4364013, Test loss: 63.4884640 (new best train)
Epoch 6900 @ 5, LR: [0.001]: Train loss: 65.4282037, Test loss: 63.6515907 (new best train)
Epoch 7000 @ 5, LR: [0.001]: Train loss: 65.3318081, Test loss: 63.1353406 (new best train)
Epoch 7100 @ 5, LR: [0.001]: Train loss: 65.2975908, Test loss: 63.4535628 (new best train)
Epoch 7200 @ 5, LR: [0.001]: Train loss: 65.2057300, Test loss: 65.0718576 (new best train)
Epoch 7300 @ 5, LR: [0.001]: Train loss: 65.1771616, Test loss: 63.1427315 (new best train)
Epoch 7400 @ 5, LR: [0.001]: Train loss: 65.1608162, Test loss: 63.0471288 (new best train)
Epoch 7500 @ 5, LR: [0.001]: Train loss: 65.1083451, Test loss: 63.4070490 (new best train)
Epoch 7600 @ 5, LR: [0.001]: Train loss: 65.0620249, Test loss: 64.8308594 (new best train)
Epoch 7700 @ 5, LR: [0.001]: Train loss: 65.0154185, Test loss: 63.1615617 (new best train)
Epoch 7800 @ 5, LR: [0.001]: Train loss: 64.9564000, Test loss: 63.1361505 (new best train)
Epoch 7900 @ 5, LR: [0.001]: Train loss: 64.8844631, Test loss: 63.8512639 (new best train)
Epoch 8000 @ 5, LR: [0.001]: Train loss: 64.9056732, Test loss: 63.4292382
Epoch 8100 @ 5, LR: [0.001]: Train loss: 64.8078544, Test loss: 62.6191840 (new best train)
Epoch 8200 @ 5, LR: [0.001]: Train loss: 64.7662803, Test loss: 64.6105253 (new best train)
Epoch 8300 @ 5, LR: [0.001]: Train loss: 64.7372559, Test loss: 62.4188952 (new best train)
Epoch 8400 @ 5, LR: [0.001]: Train loss: 64.7008466, Test loss: 63.4566835 (new best train)
Epoch 8500 @ 5, LR: [0.001]: Train loss: 64.6726632, Test loss: 62.6445800 (new best train)
Epoch 8600 @ 5, LR: [0.001]: Train loss: 64.6165336, Test loss: 62.6016234 (new best train)
Epoch 8700 @ 5, LR: [0.001]: Train loss: 64.5804297, Test loss: 62.7722489 (new best train)
Epoch 8800 @ 5, LR: [0.001]: Train loss: 64.5527673, Test loss: 62.7300322 (new best train)
Epoch 8900 @ 5, LR: [0.001]: Train loss: 64.4927440, Test loss: 62.7123276 (new best train)
Epoch 9000 @ 5, LR: [0.001]: Train loss: 64.4936710, Test loss: 62.2612492
Epoch 9100 @ 5, LR: [0.001]: Train loss: 64.4426574, Test loss: 62.4836068 (new best train)
Epoch 9200 @ 5, LR: [0.001]: Train loss: 64.4238389, Test loss: 62.3216486 (new best train)
Epoch 9300 @ 5, LR: [0.001]: Train loss: 64.3781766, Test loss: 62.0503086 (new best train)
Epoch 9400 @ 5, LR: [0.001]: Train loss: 64.3406240, Test loss: 62.8404275 (new best train)
Epoch 9500 @ 5, LR: [0.001]: Train loss: 64.3257716, Test loss: 62.5399918 (new best train)
Epoch 9600 @ 5, LR: [0.001]: Train loss: 64.2702682, Test loss: 62.0519759 (new best train)
Epoch 9700 @ 5, LR: [0.001]: Train loss: 64.2232245, Test loss: 62.1659733 (new best train)
Epoch 9800 @ 5, LR: [0.001]: Train loss: 64.2131283, Test loss: 62.4537388 (new best train)
Epoch 9900 @ 5, LR: [0.001]: Train loss: 64.1745981, Test loss: 62.2581617 (new best train)
Epoch 10000 @ 5, LR: [0.001]: Train loss: 64.1160954, Test loss: 62.2795659 (new best train)
Epoch 10100 @ 5, LR: [0.001]: Train loss: 64.0626758, Test loss: 62.2689621 (new best train)
Epoch 10200 @ 5, LR: [0.001]: Train loss: 64.1017875, Test loss: 61.8427153
Epoch 10300 @ 5, LR: [0.001]: Train loss: 64.0314860, Test loss: 61.9978276 (new best train)
Epoch 10400 @ 5, LR: [0.001]: Train loss: 63.9424406, Test loss: 61.6845381 (new best train)
Epoch 10500 @ 5, LR: [0.001]: Train loss: 63.9870473, Test loss: 61.7927374
Epoch 10600 @ 5, LR: [0.001]: Train loss: 63.9167363, Test loss: 61.6609431 (new best train)
Epoch 10700 @ 5, LR: [0.001]: Train loss: 63.9035181, Test loss: 61.6200934 (new best train)
Epoch 10800 @ 5, LR: [0.001]: Train loss: 63.9024957, Test loss: 61.5552250 (new best train)
Epoch 10900 @ 5, LR: [0.001]: Train loss: 63.8362342, Test loss: 62.8280409 (new best train)
Epoch 11000 @ 5, LR: [0.001]: Train loss: 63.8211042, Test loss: 62.2045938 (new best train)
Epoch 11100 @ 5, LR: [0.001]: Train loss: 63.7473631, Test loss: 61.5791809 (new best train)
Epoch 11200 @ 5, LR: [0.001]: Train loss: 63.7629714, Test loss: 65.5625016
Epoch 11300 @ 5, LR: [0.001]: Train loss: 63.7170502, Test loss: 61.6363043 (new best train)
Epoch 11400 @ 5, LR: [0.001]: Train loss: 63.6553407, Test loss: 61.6665918 (new best train)
Epoch 11500 @ 5, LR: [0.001]: Train loss: 63.6374901, Test loss: 61.9977058 (new best train)
Epoch 11600 @ 5, LR: [0.001]: Train loss: 63.5989992, Test loss: 61.8541889 (new best train)
Epoch 11700 @ 5, LR: [0.001]: Train loss: 63.5962560, Test loss: 62.3590831 (new best train)
Epoch 11800 @ 5, LR: [0.001]: Train loss: 63.5453790, Test loss: 61.8690008 (new best train)
Epoch 11900 @ 5, LR: [0.001]: Train loss: 63.5243438, Test loss: 62.0761807 (new best train)
Epoch 12000 @ 5, LR: [0.001]: Train loss: 63.5193204, Test loss: 61.6920143 (new best train)
Epoch 12100 @ 5, LR: [0.001]: Train loss: 63.4323236, Test loss: 61.4746237 (new best train)
Epoch 12200 @ 5, LR: [0.001]: Train loss: 63.4666952, Test loss: 61.5172914
Epoch 12300 @ 5, LR: [0.001]: Train loss: 63.4039622, Test loss: 63.7233936 (new best train)
Epoch 12400 @ 5, LR: [0.001]: Train loss: 63.3962839, Test loss: 61.2423880 (new best train)
Epoch 12500 @ 5, LR: [0.001]: Train loss: 63.3678283, Test loss: 61.3273080 (new best train)
Epoch 12600 @ 5, LR: [0.001]: Train loss: 63.3365484, Test loss: 61.2497688 (new best train)
Epoch 12700 @ 5, LR: [0.001]: Train loss: 63.3270000, Test loss: 61.2918072 (new best train)
Epoch 12800 @ 5, LR: [0.001]: Train loss: 63.3132657, Test loss: 61.7802731 (new best train)
Epoch 12900 @ 5, LR: [0.001]: Train loss: 63.2545107, Test loss: 61.3854281 (new best train)
Epoch 13000 @ 5, LR: [0.001]: Train loss: 63.2412746, Test loss: 62.8287175 (new best train)
Epoch 13100 @ 5, LR: [0.001]: Train loss: 63.2161674, Test loss: 61.7456741 (new best train)
Epoch 13200 @ 5, LR: [0.001]: Train loss: 63.2072796, Test loss: 61.0799664 (new best train)
Epoch 13300 @ 5, LR: [0.001]: Train loss: 63.1540614, Test loss: 61.2020429 (new best train)
Epoch 13400 @ 5, LR: [0.001]: Train loss: 63.1579506, Test loss: 61.8878974
Epoch 13500 @ 5, LR: [0.001]: Train loss: 63.1139126, Test loss: 62.9684808 (new best train)
Epoch 13600 @ 5, LR: [0.001]: Train loss: 63.0776047, Test loss: 62.3919390 (new best train)
Epoch 13700 @ 5, LR: [0.001]: Train loss: 63.0512449, Test loss: 62.7558176 (new best train)
Epoch 13800 @ 5, LR: [0.001]: Train loss: 63.0737432, Test loss: 61.2126119
Epoch 13900 @ 5, LR: [0.001]: Train loss: 63.0188149, Test loss: 61.4547920 (new best train)
Epoch 14000 @ 5, LR: [0.001]: Train loss: 62.9958561, Test loss: 60.8769162 (new best train)
Epoch 14100 @ 5, LR: [0.001]: Train loss: 62.9885312, Test loss: 60.8926777 (new best train)
Epoch 14200 @ 5, LR: [0.001]: Train loss: 62.9511861, Test loss: 60.9423739 (new best train)
Epoch 14300 @ 5, LR: [0.001]: Train loss: 62.9380674, Test loss: 61.0668116 (new best train)
Epoch 14400 @ 5, LR: [0.001]: Train loss: 62.8892360, Test loss: 61.1299899 (new best train)
Epoch 14500 @ 5, LR: [0.001]: Train loss: 62.8724943, Test loss: 60.9434632 (new best train)
Epoch 14600 @ 5, LR: [0.001]: Train loss: 62.8485605, Test loss: 60.9070284 (new best train)
Epoch 14700 @ 5, LR: [0.001]: Train loss: 62.8320744, Test loss: 61.0266576 (new best train)
Epoch 14800 @ 5, LR: [0.001]: Train loss: 62.7819007, Test loss: 60.7864858 (new best train)
Epoch 14900 @ 5, LR: [0.001]: Train loss: 62.7767558, Test loss: 62.1493104 (new best train)
Epoch 15000 @ 5, LR: [0.001]: Train loss: 62.7774180, Test loss: 61.4905716
Epoch 15100 @ 5, LR: [0.001]: Train loss: 62.7132437, Test loss: 61.3182118 (new best train)
Epoch 15200 @ 5, LR: [0.001]: Train loss: 62.7104420, Test loss: 60.9230078 (new best train)
Epoch 15300 @ 5, LR: [0.001]: Train loss: 62.6784383, Test loss: 60.6205354 (new best train)
Epoch 15400 @ 5, LR: [0.001]: Train loss: 62.6496143, Test loss: 60.8102135 (new best train)
Epoch 15500 @ 5, LR: [0.001]: Train loss: 62.6249003, Test loss: 61.3404916 (new best train)
Epoch 15600 @ 5, LR: [0.001]: Train loss: 62.5880836, Test loss: 60.7608904 (new best train)
Epoch 15700 @ 5, LR: [0.001]: Train loss: 62.5962132, Test loss: 60.5501107
Epoch 15800 @ 5, LR: [0.001]: Train loss: 62.5566389, Test loss: 60.4566975 (new best train)
Epoch 15900 @ 5, LR: [0.001]: Train loss: 62.4898608, Test loss: 60.5159127 (new best train)
Epoch 16000 @ 5, LR: [0.001]: Train loss: 62.4871445, Test loss: 62.2726847 (new best train)
Epoch 16100 @ 5, LR: [0.001]: Train loss: 62.4857757, Test loss: 61.3121375 (new best train)
Epoch 16200 @ 5, LR: [0.001]: Train loss: 62.4497501, Test loss: 60.7248697 (new best train)
Epoch 16300 @ 5, LR: [0.001]: Train loss: 62.4354411, Test loss: 60.7028866 (new best train)
Epoch 16400 @ 5, LR: [0.001]: Train loss: 62.4021698, Test loss: 60.2748469 (new best train)
Epoch 16500 @ 5, LR: [0.001]: Train loss: 62.3527843, Test loss: 60.3391411 (new best train)
Epoch 16600 @ 5, LR: [0.001]: Train loss: 62.3608477, Test loss: 60.2423626
Epoch 16700 @ 5, LR: [0.001]: Train loss: 62.3342167, Test loss: 60.2863442 (new best train)
Epoch 16800 @ 5, LR: [0.001]: Train loss: 62.2931748, Test loss: 62.6420184 (new best train)
Epoch 16900 @ 5, LR: [0.001]: Train loss: 62.2675311, Test loss: 60.3990079 (new best train)
Epoch 17000 @ 5, LR: [0.001]: Train loss: 62.2593380, Test loss: 61.0962343 (new best train)
Epoch 17100 @ 5, LR: [0.001]: Train loss: 62.2113533, Test loss: 60.4103276 (new best train)
Epoch 17200 @ 5, LR: [0.001]: Train loss: 62.1832214, Test loss: 61.1206364 (new best train)
Epoch 17300 @ 5, LR: [0.001]: Train loss: 62.1495240, Test loss: 60.2155723 (new best train)
Epoch 17400 @ 5, LR: [0.001]: Train loss: 62.1358109, Test loss: 60.4231521 (new best train)
Epoch 17500 @ 5, LR: [0.001]: Train loss: 62.0942423, Test loss: 60.1251940 (new best train)
Epoch 17600 @ 5, LR: [0.001]: Train loss: 62.0818396, Test loss: 60.6184308 (new best train)
Epoch 17700 @ 5, LR: [0.001]: Train loss: 62.0202281, Test loss: 61.0930904 (new best train)
Epoch 17800 @ 5, LR: [0.001]: Train loss: 62.0063792, Test loss: 61.0245530 (new best train)
Epoch 17900 @ 5, LR: [0.001]: Train loss: 61.9948488, Test loss: 60.7121374 (new best train)
Epoch 18000 @ 5, LR: [0.001]: Train loss: 61.9549439, Test loss: 60.2464701 (new best train)
Epoch 18100 @ 5, LR: [0.001]: Train loss: 61.9233231, Test loss: 60.7549963 (new best train)
Epoch 18200 @ 5, LR: [0.001]: Train loss: 61.9191618, Test loss: 59.8351023 (new best train)
Epoch 18300 @ 5, LR: [0.001]: Train loss: 61.8462454, Test loss: 59.8189164 (new best train)
Epoch 18400 @ 5, LR: [0.001]: Train loss: 61.8415949, Test loss: 60.3040262 (new best train)
Epoch 18500 @ 5, LR: [0.001]: Train loss: 61.7915521, Test loss: 59.9722396 (new best train)
Epoch 18600 @ 5, LR: [0.001]: Train loss: 61.7794340, Test loss: 60.6477644 (new best train)
Epoch 18700 @ 5, LR: [0.001]: Train loss: 61.7138352, Test loss: 60.5456664 (new best train)
Epoch 18800 @ 5, LR: [0.001]: Train loss: 61.6991252, Test loss: 62.7832515 (new best train)
Epoch 18900 @ 5, LR: [0.001]: Train loss: 61.6612853, Test loss: 60.0962928 (new best train)
Epoch 19000 @ 5, LR: [0.001]: Train loss: 61.6243699, Test loss: 59.6396465 (new best train)
Epoch 19100 @ 5, LR: [0.001]: Train loss: 61.6204928, Test loss: 60.6670882 (new best train)
Epoch 19200 @ 5, LR: [0.001]: Train loss: 61.5648963, Test loss: 60.1359491 (new best train)
Epoch 19300 @ 5, LR: [0.001]: Train loss: 61.5418745, Test loss: 61.6492570 (new best train)
Epoch 19400 @ 5, LR: [0.001]: Train loss: 61.5000605, Test loss: 60.0649359 (new best train)
Epoch 19500 @ 5, LR: [0.001]: Train loss: 61.4661953, Test loss: 59.5080419 (new best train)
Epoch 19600 @ 5, LR: [0.001]: Train loss: 61.4011189, Test loss: 60.9514470 (new best train)
Epoch 19700 @ 5, LR: [0.001]: Train loss: 61.3851525, Test loss: 59.6539920 (new best train)
Epoch 19800 @ 5, LR: [0.001]: Train loss: 61.3408188, Test loss: 59.8116885 (new best train)
Epoch 19900 @ 5, LR: [0.001]: Train loss: 61.3273998, Test loss: 59.8040763 (new best train)
Epoch 20000 @ 5, LR: [0.001]: Train loss: 61.2861490, Test loss: 59.9724211 (new best train)
Epoch 20100 @ 5, LR: [0.001]: Train loss: 61.2372138, Test loss: 59.3707073 (new best train)
Epoch 20200 @ 5, LR: [0.001]: Train loss: 61.1991887, Test loss: 60.1851419 (new best train)
Epoch 20300 @ 5, LR: [0.001]: Train loss: 61.1554990, Test loss: 59.6046895 (new best train)
Epoch 20400 @ 5, LR: [0.001]: Train loss: 61.1279129, Test loss: 60.8877388 (new best train)
Epoch 20500 @ 5, LR: [0.001]: Train loss: 61.0952545, Test loss: 60.4017496 (new best train)
Epoch 20600 @ 5, LR: [0.001]: Train loss: 61.0267934, Test loss: 59.1922007 (new best train)
Epoch 20700 @ 5, LR: [0.001]: Train loss: 61.0039097, Test loss: 59.2348484 (new best train)
Epoch 20800 @ 5, LR: [0.001]: Train loss: 60.9433822, Test loss: 59.1234814 (new best train)
Epoch 20900 @ 5, LR: [0.001]: Train loss: 60.9142711, Test loss: 59.0943012 (new best train)
Epoch 21000 @ 5, LR: [0.001]: Train loss: 60.8412946, Test loss: 58.9126094 (new best train)
Epoch 21100 @ 5, LR: [0.001]: Train loss: 60.7850777, Test loss: 59.9099555 (new best train)
Epoch 21200 @ 5, LR: [0.001]: Train loss: 60.6702979, Test loss: 58.7391495 (new best train)
Epoch 21300 @ 5, LR: [0.001]: Train loss: 60.5669671, Test loss: 60.7288288 (new best train)
Epoch 21400 @ 5, LR: [0.001]: Train loss: 60.3997548, Test loss: 58.4441054 (new best train)
Epoch 21500 @ 5, LR: [0.001]: Train loss: 60.1867170, Test loss: 60.0401116 (new best train)
Epoch 21600 @ 5, LR: [0.001]: Train loss: 59.9975339, Test loss: 58.0098194 (new best train)
Epoch 21700 @ 5, LR: [0.001]: Train loss: 59.7665604, Test loss: 57.9650334 (new best train)
Epoch 21800 @ 5, LR: [0.001]: Train loss: 59.5221396, Test loss: 57.7297203 (new best train)
Epoch 21900 @ 5, LR: [0.001]: Train loss: 59.2727303, Test loss: 57.1529792 (new best train)
Epoch 22000 @ 5, LR: [0.001]: Train loss: 59.0542886, Test loss: 57.1005804 (new best train)
Epoch 22100 @ 5, LR: [0.001]: Train loss: 58.8393482, Test loss: 57.7287870 (new best train)
Epoch 22200 @ 5, LR: [0.001]: Train loss: 58.5432288, Test loss: 56.6531990 (new best train)
Epoch 22300 @ 5, LR: [0.001]: Train loss: 58.3701953, Test loss: 58.2427817 (new best train)
Epoch 22400 @ 5, LR: [0.001]: Train loss: 58.1810562, Test loss: 56.1977574 (new best train)
Epoch 22500 @ 5, LR: [0.001]: Train loss: 57.9357246, Test loss: 56.8967156 (new best train)
Epoch 22600 @ 5, LR: [0.001]: Train loss: 57.7704324, Test loss: 56.7712942 (new best train)
Epoch 22700 @ 5, LR: [0.001]: Train loss: 57.6159971, Test loss: 56.1211981 (new best train)
Epoch 22800 @ 5, LR: [0.001]: Train loss: 57.4469021, Test loss: 56.6430066 (new best train)
Epoch 22900 @ 5, LR: [0.001]: Train loss: 57.3184790, Test loss: 55.7559543 (new best train)
Epoch 23000 @ 5, LR: [0.001]: Train loss: 57.1458702, Test loss: 56.0841893 (new best train)
Epoch 23100 @ 5, LR: [0.001]: Train loss: 56.9962891, Test loss: 55.3708573 (new best train)
Epoch 23200 @ 5, LR: [0.001]: Train loss: 56.8648977, Test loss: 55.3208291 (new best train)
Epoch 23300 @ 5, LR: [0.001]: Train loss: 56.7082512, Test loss: 55.2822555 (new best train)
Epoch 23400 @ 5, LR: [0.001]: Train loss: 56.6928784, Test loss: 55.8842140 (new best train)
Epoch 23500 @ 5, LR: [0.001]: Train loss: 56.6937476, Test loss: 55.6316054
Epoch 23600 @ 5, LR: [0.001]: Train loss: 56.4610428, Test loss: 55.5594908 (new best train)
Epoch 23700 @ 5, LR: [0.001]: Train loss: 56.3865093, Test loss: 55.5863024 (new best train)
Epoch 23800 @ 5, LR: [0.001]: Train loss: 56.2669438, Test loss: 54.2661148 (new best train)
Epoch 23900 @ 5, LR: [0.001]: Train loss: 56.1796228, Test loss: 54.5969509 (new best train)
Epoch 24000 @ 5, LR: [0.001]: Train loss: 56.0880195, Test loss: 54.8561025 (new best train)
Epoch 24100 @ 5, LR: [0.001]: Train loss: 56.0160960, Test loss: 55.4056871 (new best train)
Epoch 24200 @ 5, LR: [0.001]: Train loss: 55.9020975, Test loss: 54.5947942 (new best train)
Epoch 24300 @ 5, LR: [0.001]: Train loss: 55.8362828, Test loss: 55.2470558 (new best train)
Epoch 24400 @ 5, LR: [0.001]: Train loss: 55.7738767, Test loss: 54.8101746 (new best train)
Epoch 24500 @ 5, LR: [0.001]: Train loss: 55.7084442, Test loss: 55.8594966 (new best train)
Epoch 24600 @ 5, LR: [0.001]: Train loss: 55.6523150, Test loss: 54.2725578 (new best train)
Epoch 24700 @ 5, LR: [0.001]: Train loss: 55.5350188, Test loss: 54.8533865 (new best train)
Epoch 24800 @ 5, LR: [0.001]: Train loss: 55.4560977, Test loss: 56.1194786 (new best train)
Epoch 24900 @ 5, LR: [0.001]: Train loss: 55.4661752, Test loss: 56.1222681
Epoch 25000 @ 5, LR: [0.001]: Train loss: 55.3120400, Test loss: 54.2619454 (new best train)
Epoch 25100 @ 5, LR: [0.001]: Train loss: 55.2579409, Test loss: 53.8060643 (new best train)
Epoch 25200 @ 5, LR: [0.001]: Train loss: 55.2324378, Test loss: 55.6847258 (new best train)
Epoch 25300 @ 5, LR: [0.001]: Train loss: 55.1336945, Test loss: 53.7286574 (new best train)
Epoch 25400 @ 5, LR: [0.001]: Train loss: 55.1034473, Test loss: 55.9143211 (new best train)
Epoch 25500 @ 5, LR: [0.001]: Train loss: 55.0116728, Test loss: 53.4154153 (new best train)
Epoch 25600 @ 5, LR: [0.001]: Train loss: 54.9793570, Test loss: 53.4741843 (new best train)
Epoch 25700 @ 5, LR: [0.001]: Train loss: 54.9344964, Test loss: 54.4457005 (new best train)
Epoch 25800 @ 5, LR: [0.001]: Train loss: 54.8761107, Test loss: 54.0459001 (new best train)
Epoch 25900 @ 5, LR: [0.001]: Train loss: 54.7763147, Test loss: 53.6159654 (new best train)
Epoch 26000 @ 5, LR: [0.001]: Train loss: 54.7457204, Test loss: 54.1357048 (new best train)
Epoch 26100 @ 5, LR: [0.001]: Train loss: 54.7206806, Test loss: 53.4061475 (new best train)
Epoch 26200 @ 5, LR: [0.001]: Train loss: 54.6024001, Test loss: 55.2634075 (new best train)
Epoch 26300 @ 5, LR: [0.001]: Train loss: 54.5434205, Test loss: 53.6503989 (new best train)
Epoch 26400 @ 5, LR: [0.001]: Train loss: 54.5007819, Test loss: 54.0635031 (new best train)
Epoch 26500 @ 5, LR: [0.001]: Train loss: 54.4393658, Test loss: 53.5724285 (new best train)
Epoch 26600 @ 5, LR: [0.001]: Train loss: 54.4809375, Test loss: 53.4831345
Epoch 26700 @ 5, LR: [0.001]: Train loss: 54.3790364, Test loss: 53.5750600 (new best train)
Epoch 26800 @ 5, LR: [0.001]: Train loss: 54.2825905, Test loss: 57.6051025 (new best train)
Epoch 26900 @ 5, LR: [0.001]: Train loss: 54.3131463, Test loss: 53.6831619
Epoch 27000 @ 5, LR: [0.001]: Train loss: 54.2034307, Test loss: 53.7800872 (new best train)
Epoch 27100 @ 5, LR: [0.001]: Train loss: 54.1406735, Test loss: 53.1791903 (new best train)
Epoch 27200 @ 5, LR: [0.001]: Train loss: 54.0960396, Test loss: 53.2456414 (new best train)
Epoch 27300 @ 5, LR: [0.001]: Train loss: 54.0635807, Test loss: 52.9683594 (new best train)
Epoch 27400 @ 5, LR: [0.001]: Train loss: 53.9744665, Test loss: 52.5403030 (new best train)
Epoch 27500 @ 5, LR: [0.001]: Train loss: 54.0398575, Test loss: 54.0516432
Epoch 27600 @ 5, LR: [0.001]: Train loss: 53.9158472, Test loss: 52.6283051 (new best train)
Epoch 27700 @ 5, LR: [0.001]: Train loss: 53.8653305, Test loss: 53.8630426 (new best train)
Epoch 27800 @ 5, LR: [0.001]: Train loss: 53.8310747, Test loss: 52.9051303 (new best train)
Epoch 27900 @ 5, LR: [0.001]: Train loss: 53.7712737, Test loss: 52.6017622 (new best train)
Epoch 28000 @ 5, LR: [0.001]: Train loss: 53.7670526, Test loss: 55.6283036 (new best train)
Epoch 28100 @ 5, LR: [0.001]: Train loss: 53.6681887, Test loss: 53.1044719 (new best train)
Epoch 28200 @ 5, LR: [0.001]: Train loss: 53.6159919, Test loss: 52.2598237 (new best train)
Epoch 28300 @ 5, LR: [0.001]: Train loss: 53.5861072, Test loss: 53.0134045 (new best train)
Epoch 28400 @ 5, LR: [0.001]: Train loss: 53.5260095, Test loss: 52.7853178 (new best train)
Epoch 28500 @ 5, LR: [0.001]: Train loss: 53.4602619, Test loss: 52.3666255 (new best train)
Epoch 28600 @ 5, LR: [0.001]: Train loss: 53.3997001, Test loss: 51.8876639 (new best train)
Epoch 28700 @ 5, LR: [0.001]: Train loss: 53.3173352, Test loss: 52.0300223 (new best train)
Epoch 28800 @ 5, LR: [0.001]: Train loss: 53.3349862, Test loss: 52.5294995
Epoch 28900 @ 5, LR: [0.001]: Train loss: 53.2472318, Test loss: 51.8334400 (new best train)
Epoch 29000 @ 5, LR: [0.001]: Train loss: 53.2323405, Test loss: 53.1861261 (new best train)
Epoch 29100 @ 5, LR: [0.001]: Train loss: 53.1836374, Test loss: 51.8875964 (new best train)
Epoch 29200 @ 5, LR: [0.001]: Train loss: 53.1739476, Test loss: 51.8633766 (new best train)
Epoch 29300 @ 5, LR: [0.001]: Train loss: 53.0684619, Test loss: 51.6871607 (new best train)
Epoch 29400 @ 5, LR: [0.001]: Train loss: 53.0483123, Test loss: 51.9134596 (new best train)
Epoch 29500 @ 5, LR: [0.001]: Train loss: 53.0349165, Test loss: 52.1268457 (new best train)
Epoch 29600 @ 5, LR: [0.001]: Train loss: 53.0127417, Test loss: 52.2617987 (new best train)
Epoch 29700 @ 5, LR: [0.001]: Train loss: 52.9290824, Test loss: 52.8093458 (new best train)
Epoch 29800 @ 5, LR: [0.001]: Train loss: 52.8875158, Test loss: 52.8088242 (new best train)
Epoch 29900 @ 5, LR: [0.001]: Train loss: 52.8678403, Test loss: 52.6360391 (new best train)
Epoch 30000 @ 5, LR: [0.001]: Train loss: 52.7728837, Test loss: 52.8669609 (new best train)
Best train perf: 52.77288374958194, epoch: 30000
Fold 5 completed
Average train perf: 52.616901963161595 +/- 2.2848379119898676
Average test perf: 53.9351112469819 +/- 1.919299469443011
Average epoch: 30000.0 +/- 0.0
Total time: 607127.7822797298
